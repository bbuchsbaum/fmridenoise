This file is a merged representation of a subset of the codebase, containing specifically included files, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Only files matching these patterns are included: R/**/*.R, R/**/*.r, *.Rmd, *.rmd, DESCRIPTION, tests/**/*.R, tests/**/*.r
- Files matching patterns in .gitignore are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
R/
  ndx_data_structures.R
  ndx_design_modular.R
  ndx_hrf.R
  ndx_initial_glm.R
  ndx_ridge.R
  ndx_rpca.R
  ndx_spectral.R
  ndx_utils.R
  ndx_whitening.R
  ndx_workflow.R
tests/
  testthat/
    test-design_matrix.R
    test-initial_glm.R
    test-ridge.R
    test-rpca.R
    test-spectral.R
    test-utils.R
    test-whitening.R
    test-workflow.R
DESCRIPTION
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="R/ndx_data_structures.R">
# ND-X Core Data Structures
# This file will define S3/R6 classes for:
# - fMRI data objects (wrapping NIfTI images, metadata)
# - Design matrix objects
# - ND-X parameter objects

# Placeholder for now
</file>

<file path="R/ndx_design_modular.R">
#' Build a Full Design Matrix from Modular Components
#'
#' This is a refactored, cleaner implementation of `ndx_build_design_matrix` that
#' delegates the heavy lifting to a set of small internal helper functions.  The
#' public interface (arguments and return value) is identical to the original
#' monolithic version, so existing code and tests do not need to change.
#'
#' @param estimated_hrfs Tibble of HRF estimates; see old docs.
#' @param events Data frame of experimental events.
#' @param motion_params Optional matrix of motion parameters.
#' @param rpca_components Optional matrix of RPCA regressors.
#' @param spectral_sines Optional matrix of spectral sine/cosine regressors.
#' @param run_idx Integer vector indicating run membership for each time-point.
#' @param TR Repetition time, in seconds.
#' @param poly_degree_val Degree of Legendre polynomial baseline (per run).
#' @param verbose Logical flag for verbose console output.
#'
#' @return Numeric matrix with one column per regressor (or `NULL` on failure).
#' @importFrom fmrireg sampling_frame event_model design_matrix baseline_model
#' @importFrom tibble is_tibble
#' @export ndx_build_design_matrix
ndx_build_design_matrix <- function(estimated_hrfs,
                                    events,
                                    motion_params,
                                    rpca_components,
                                    spectral_sines,
                                    run_idx,
                                    TR,
                                    poly_degree_val = NULL,
                                    verbose = TRUE) {

  if (verbose) message("[ndx_build_design_matrix] Top level entry.")
  # 1. Basic validation ----------------------------------------------------
  info <- .ndx_validate_design_inputs(run_idx, motion_params, rpca_components, spectral_sines)
  if (verbose) message(sprintf("[ndx_build_design_matrix] Validation done. Total TP: %d", info$total_tp))
  sf   <- fmrireg::sampling_frame(blocklens = info$run_lengths, TR = TR)

  # 2. Task regressors -----------------------------------------------------
  if (verbose) message("[ndx_build_design_matrix] Calling .ndx_generate_task_regressors...")
  task_mat <- .ndx_generate_task_regressors(estimated_hrfs, events, sf, TR, verbose)
  if (verbose) {
    message("[ndx_build_design_matrix] Received task_mat:")
    if (is.null(task_mat)) message("  task_mat is NULL")
    else message(sprintf("  dim(task_mat): %s, colnames: %s", paste(dim(task_mat), collapse="x"), paste(colnames(task_mat), collapse=", ")))
  }

  # 3. Nuisance regressors -------------------------------------------------
  if (verbose) message("[ndx_build_design_matrix] Calling .ndx_generate_nuisance_regressors...")
  nuisance_list_components <- .ndx_generate_nuisance_regressors(motion_params, rpca_components, spectral_sines, verbose)
  if (verbose) {
    message("[ndx_build_design_matrix] Received nuisance_list_components:")
    if (length(nuisance_list_components) == 0) message("  nuisance_list_components is empty.")
    else for (n_name in names(nuisance_list_components)) {
      if (is.null(nuisance_list_components[[n_name]])) message(sprintf("  nuisance_list_components$%s is NULL", n_name))
      else message(sprintf("  nuisance_list_components$%s: dim: %s, colnames: %s", n_name, paste(dim(nuisance_list_components[[n_name]]), collapse="x"), paste(colnames(nuisance_list_components[[n_name]]), collapse=", ")))
    }
  }
  
  # 4. Baseline regressors -------------------------------------------------
  if (verbose) message("[ndx_build_design_matrix] Calling .ndx_generate_baseline_regressors...")
  baseline_mat <- .ndx_generate_baseline_regressors(run_idx, sf, poly_degree_val, verbose)
   if (verbose) {
    message("[ndx_build_design_matrix] Received baseline_mat:")
    if (is.null(baseline_mat)) message("  baseline_mat is NULL")
    else message(sprintf("  dim(baseline_mat): %s, colnames: %s", paste(dim(baseline_mat), collapse="x"), paste(colnames(baseline_mat), collapse=", ")))
  }

  # 5. Combine -------------------------------------------------------------
  regressor_list <- c(list(task = task_mat), nuisance_list_components, list(baseline = baseline_mat))
  if (verbose) {
    message("[ndx_build_design_matrix] Assembled regressor_list for combination:")
    if (length(regressor_list) == 0) message("  regressor_list is empty.")
    else for (r_name in names(regressor_list)) {
      if (is.null(regressor_list[[r_name]])) message(sprintf("  regressor_list$%s is NULL", r_name))
      else message(sprintf("  regressor_list$%s: dim: %s, colnames: %s", r_name, paste(dim(regressor_list[[r_name]]), collapse="x"), paste(colnames(regressor_list[[r_name]]), collapse=", ")))
    }
  }
  
  if (verbose) message("[ndx_build_design_matrix] Calling .ndx_combine_regressors...")
  X_full <- .ndx_combine_regressors(regressor_list, info$total_tp, verbose)

  if (verbose && !is.null(X_full)) {
    message(sprintf("[ndx_build_design_matrix] Final X_full: dim: %s, colnames: %s", 
                    paste(dim(X_full), collapse="x"), paste(colnames(X_full), collapse=", ")))
  } else if (verbose && is.null(X_full)) {
    message("[ndx_build_design_matrix] Final X_full is NULL.")
  }
  X_full
}

# -------------------------------------------------------------------------
# Internal helper functions ------------------------------------------------
# -------------------------------------------------------------------------

#' @keywords internal
.ndx_validate_design_inputs <- function(run_idx,
                                        motion_params,
                                        rpca_components,
                                        spectral_sines) {
  # message("[.ndx_validate_design_inputs] Entry.") # Optional: too noisy if called often
  unique_runs <- sort(unique(run_idx))
  run_lengths <- as.numeric(table(factor(run_idx, levels = unique_runs)))

  # Added check for empty/zero-sum run_lengths to match test expectation
  if (length(run_lengths) == 0 || sum(run_lengths) == 0) {
    stop("run_idx implies one or more runs have zero or negative length.")
  }

  if (any(run_lengths <= 0)) {
    stop("run_idx implies one or more runs have zero or negative length.")
  }
  total_tp <- sum(run_lengths)

  check_rows <- function(mat, name) {
    if (!is.null(mat) && nrow(mat) != total_tp) {
      stop(sprintf("Row mismatch: %s has %d rows, expected %d based on run_idx.",
                   name, nrow(mat), total_tp))
    }
  }
  check_rows(motion_params,   "motion_params")
  check_rows(rpca_components, "rpca_components")
  check_rows(spectral_sines,  "spectral_sines")

  list(unique_runs   = unique_runs,
       run_lengths   = run_lengths,
       total_tp      = total_tp)
}

#' @keywords internal
.ndx_generate_task_regressors <- function(estimated_hrfs,
                                          events,
                                          sf,
                                          TR,
                                          verbose = TRUE) {
  if (verbose) message("[.ndx_generate_task_regressors] Entry.")
  if (is.null(estimated_hrfs) || !tibble::is_tibble(estimated_hrfs) || nrow(estimated_hrfs) == 0) {
    if (verbose) message("  No estimated_hrfs provided; skipping task regressor generation.")
    return(NULL)
  }
  if (!all(c("condition", "hrf_estimate") %in% names(estimated_hrfs))) {
    stop("estimated_hrfs tibble must contain 'condition' and 'hrf_estimate' columns.")
  }

  task_list <- list()
  if (verbose) message(sprintf("  Generating task regressors for %d conditions using estimated HRFs...", nrow(estimated_hrfs)))

  for (i in seq_len(nrow(estimated_hrfs))) {
    cond_name  <- estimated_hrfs$condition[i]
    hrf_coeffs <- estimated_hrfs$hrf_estimate[[i]]
    if (is.null(hrf_coeffs) || length(hrf_coeffs) == 0) {
      if (verbose) message(sprintf("    Skipping '%s' due to NULL/empty HRF coefficients.", cond_name))
      next
    }

    num_fir    <- length(hrf_coeffs)
    fir_span   <- num_fir * TR

    ev_df <- events[events$condition == cond_name, , drop = FALSE]
    if (nrow(ev_df) == 0) {
      if (verbose) message(sprintf("    No events found for '%s'; skipping.", cond_name))
      next
    }
    ev_df$fir_event_type <- factor("event_for_fir")

    X_fir <- tryCatch({
      ev_model <- fmrireg::event_model(
        formula = onsets ~ fmrireg::hrf(fir_event_type, basis = "tent", nbasis = num_fir, span = fir_span, name_suffix = "_firbase"),
        data    = ev_df,
        block   = ev_df$blockids,
        sampling_frame = sf,
        drop_empty     = FALSE
      )
      fmrireg::design_matrix(ev_model)
    }, error = function(e) {
      if (verbose) message(sprintf("    Error building FIR for '%s': %s", cond_name, e$message))
      NULL
    })

    if (!is.null(X_fir) && ncol(X_fir) == num_fir) {
      reg <- X_fir %*% hrf_coeffs
      colnames(reg) <- paste0("task_", make.names(cond_name))
      task_list[[cond_name]] <- reg
      if (verbose) message(sprintf("      Generated task regressor for '%s'.", cond_name))
    } else if (!is.null(X_fir)) {
      if (verbose) message(sprintf("    FIR basis for '%s' had unexpected column count (got %d, expected %d).", cond_name, ncol(X_fir), num_fir))
    }
  }

  if (verbose) message(sprintf("  [.ndx_generate_task_regressors] task_list has %d elements before cbind.", length(task_list)))
  
  if (length(task_list) > 0) {
    final_task_matrix <- do.call(cbind, task_list)
    if (verbose) {
        message(sprintf("  [.ndx_generate_task_regressors] Returning task matrix. dim: %s, colnames: %s", 
                        paste(dim(final_task_matrix), collapse="x"), paste(colnames(final_task_matrix), collapse=", ")))
    }
    return(final_task_matrix)
  } else {
    if (verbose) message("  [.ndx_generate_task_regressors] Returning NULL as no task regressors generated.")
    return(NULL)
  }
}

#' @keywords internal
.ndx_generate_nuisance_regressors <- function(motion_params,
                                              rpca_components,
                                              spectral_sines,
                                              verbose = TRUE) {
  if (verbose) message("[.ndx_generate_nuisance_regressors] Entry.")
  nuis <- list()

  if (!is.null(motion_params) && ncol(motion_params) > 0) {
    nuis$motion <- as.matrix(motion_params)
    if (is.null(colnames(nuis$motion))) {
      colnames(nuis$motion) <- paste0("motion_param_", seq_len(ncol(nuis$motion)))
    }
    if (verbose) message(sprintf("  Added motion_params. dim: %s, colnames: %s", paste(dim(nuis$motion), collapse="x"), paste(colnames(nuis$motion), collapse=", ")))
  } else if (verbose && !is.null(motion_params)) {
    message("  motion_params provided but has 0 columns or is NULL.")
  }
  
  if (!is.null(rpca_components) && ncol(rpca_components) > 0) {
    nuis$rpca <- as.matrix(rpca_components)
    colnames(nuis$rpca) <- paste0("rpca_comp_", seq_len(ncol(nuis$rpca)))
    if (verbose) message(sprintf("  Added rpca_components. dim: %s, colnames: %s", paste(dim(nuis$rpca), collapse="x"), paste(colnames(nuis$rpca), collapse=", ")))
  } else if (verbose && !is.null(rpca_components)) {
    message("  rpca_components provided but has 0 columns or is NULL.")
  }

  if (!is.null(spectral_sines) && ncol(spectral_sines) > 0) {
    nuis$spectral <- as.matrix(spectral_sines)
    if (is.null(colnames(nuis$spectral))) { 
        colnames(nuis$spectral) <- paste0("spectral_comp_", seq_len(ncol(nuis$spectral)))
    }
    if (verbose) message(sprintf("  Added spectral_sines. dim: %s, colnames: %s", paste(dim(nuis$spectral), collapse="x"), paste(colnames(nuis$spectral), collapse=", ")))
  } else if (verbose && !is.null(spectral_sines)) {
      message("  spectral_sines provided but has 0 columns or is NULL.")
  }
  
  if (verbose) message(sprintf("[.ndx_generate_nuisance_regressors] Returning nuisance list with %d elements. Names: %s", length(nuis), paste(names(nuis),collapse=", ")))
  nuis
}

#' @keywords internal
.ndx_generate_baseline_regressors <- function(run_idx,
                                             sf,
                                             poly_degree_val,
                                             verbose = TRUE) {
  if (verbose) message(sprintf("[.ndx_generate_baseline_regressors] Entry. poly_degree_val: %s", ifelse(is.null(poly_degree_val), "NULL", poly_degree_val)))
  unique_runs <- sort(unique(run_idx))
  total_tp    <- length(run_idx)
  baseline    <- list()
  has_poly0   <- FALSE

  # Legendre polynomials ---------------------------------------------------
  if (!is.null(poly_degree_val) && is.numeric(poly_degree_val) && !is.na(poly_degree_val) && poly_degree_val >= 0) {
    if (poly_degree_val == 0) {
      # Handle intercept-only case (poly0) using basis = "constant"
      if (verbose) message(sprintf("  Adding Legendre polynomial degree %d (intercept only).", poly_degree_val))
      bm_poly <- fmrireg::baseline_model(basis = "constant", intercept = "global", sframe = sf)
      X_poly  <- fmrireg::design_matrix(bm_poly)
      if (!is.null(X_poly) && ncol(X_poly) == 1) { # Expect 1 column for intercept
        colnames(X_poly) <- "poly0"
        baseline$poly    <- X_poly
        has_poly0        <- TRUE
        if (verbose) message(sprintf("    Added 1 polynomial baseline regressor (poly0)."))
      } else if (verbose) {
          message(sprintf("    Warning: Expected 1 column for poly0 (intercept), got %s. Not adding poly0.", if(is.null(X_poly)) "NULL" else as.character(ncol(X_poly))))
      }
    } else { # poly_degree_val > 0
      if (verbose) message(sprintf("  Adding Legendre polynomials up to degree %d per run.", poly_degree_val))
      bm_poly <- fmrireg::baseline_model(basis = "poly", degree = poly_degree_val,
                                         intercept = "global", sframe = sf)
      X_poly  <- fmrireg::design_matrix(bm_poly)
      # For degree > 0, fmrireg::baseline_model with "poly" and intercept="global"
      # includes the intercept (poly0) and higher order terms.
      # So, ncol(X_poly) should be poly_degree_val + 1.
      if (!is.null(X_poly) && ncol(X_poly) == (poly_degree_val + 1)) {
        colnames(X_poly) <- paste0("poly", 0:poly_degree_val)
        baseline$poly    <- X_poly
        has_poly0        <- TRUE # Since poly0 is included
        if (verbose) message(sprintf("    Added %d polynomial baseline regressors (poly0 to poly%d).", ncol(X_poly), poly_degree_val))
      } else if (verbose) {
          message(sprintf("    Warning: Expected %d poly columns (degree %d + intercept), got %s. Not adding polynomials.",
                          poly_degree_val + 1, poly_degree_val, if(is.null(X_poly)) "NULL" else as.character(ncol(X_poly))))
      }
    }
  }

  # Run intercepts ---------------------------------------------------------
  if (length(unique_runs) > 1) {
    bm_run <- fmrireg::baseline_model(basis = "constant", degree = 0,
                                      intercept = "runwise", sframe = sf)
    X_run  <- fmrireg::design_matrix(bm_run)
    if (!is.null(X_run) && ncol(X_run) > 0) {
      if (has_poly0) {
        # Drop the first column to avoid redundant intercept
        X_run <- X_run[, -1, drop = FALSE]
        unique_runs <- unique_runs[-1]
      }
      if (ncol(X_run) > 0) {
        colnames(X_run) <- paste0("run_intercept_", unique_runs)
        baseline$run_intercepts <- X_run
        if (verbose) message(sprintf("  Added %d run intercept regressors.", ncol(X_run)))
      }
    }
  } else if (length(unique_runs) == 1 && !has_poly0) {
    baseline$intercept <- matrix(1, nrow = total_tp, ncol = 1,
                                 dimnames = list(NULL, "intercept"))
    if (verbose) message("  Added global intercept.")
  }

  if (verbose) message(sprintf("  [.ndx_generate_baseline_regressors] baseline list has %d elements before cbind. Names: %s", length(baseline), paste(names(baseline),collapse=", ")))

  if (length(baseline) > 0) {
    final_baseline_matrix <- do.call(cbind, baseline)
    if (verbose) {
        message(sprintf("  [.ndx_generate_baseline_regressors] Returning baseline matrix. dim: %s, colnames: %s", 
                        paste(dim(final_baseline_matrix), collapse="x"), paste(colnames(final_baseline_matrix), collapse=", ")))
    }
    return(final_baseline_matrix)
  } else {
    if (verbose) message("  [.ndx_generate_baseline_regressors] Returning NULL as no baseline regressors generated.")
    return(NULL)
  }
}

#' @keywords internal
.ndx_combine_regressors <- function(reg_list,
                                   total_tp,
                                   verbose = TRUE) {
  if (verbose) {
      message("[.ndx_combine_regressors] Entry. Input reg_list:")
      if (length(reg_list) == 0) message("  Input reg_list is empty.")
      else for (r_name in names(reg_list)) {
        if (is.null(reg_list[[r_name]])) message(sprintf("  Input reg_list$%s is NULL", r_name))
        else message(sprintf("  Input reg_list$%s: dim: %s, colnames: %s", r_name, paste(dim(reg_list[[r_name]]), collapse="x"), paste(colnames(reg_list[[r_name]]), collapse=", ")))
      }
  }
  valid_components <- list()

  for (name in names(reg_list)) {
    comp <- reg_list[[name]]
    if (!is.null(comp) && is.matrix(comp) && ncol(comp) > 0) {
      if (nrow(comp) != total_tp) {
        stop(sprintf("Component '%s' has %d rows, expected %d.", name, nrow(comp), total_tp))
      }
      valid_components[[name]] <- comp 
      if (verbose) message(sprintf("  Added valid component: %s. dim: %s", name, paste(dim(comp),collapse="x")))
    } else if (verbose) {
        message(sprintf("  Skipping component \'%s\' (NULL, not matrix, or 0 cols).", name))
    }
  }

  if (verbose) {
    message("[.ndx_combine_regressors] valid_components collected:")
    if (length(valid_components) == 0) message("  valid_components is empty.")
    else for (v_name in names(valid_components)) {
        message(sprintf("  valid_components$%s: dim: %s, colnames: %s", v_name, paste(dim(valid_components[[v_name]]), collapse="x"), paste(colnames(valid_components[[v_name]]), collapse=", ")))
    }
  }
  
  if (length(valid_components) == 0) {
    if (verbose) message("  No valid regressor components found to combine. Returning NULL.")
    return(NULL)
  }

  X_combined <- do.call(cbind, valid_components) 

  if (is.null(X_combined)) { 
      if (verbose) message("  Result of do.call(cbind,...) was NULL. Returning NULL.")
      return(NULL)
  }
  if (verbose) message(sprintf("  X_combined after cbind: dim: %s, initial colnames: %s", paste(dim(X_combined),collapse="x"), paste(colnames(X_combined),collapse=", ")))
  
  final_colnames <- unlist(lapply(valid_components, colnames))
  if (verbose) message(sprintf("  final_colnames from valid_components: %s", paste(final_colnames,collapse=", ")))
  
  if (length(final_colnames) != ncol(X_combined)) {
      warning("Mismatch between expected number of colnames and actual columns after cbind. Using default names.")
      colnames(X_combined) <- make.names(paste0("col", seq_len(ncol(X_combined))), unique = TRUE)
  } else {
      colnames(X_combined) <- make.names(final_colnames, unique = TRUE)
  }
  if (verbose) message(sprintf("  X_combined after make.names: dim: %s, final colnames: %s", paste(dim(X_combined),collapse="x"), paste(colnames(X_combined),collapse=", ")))
  
   if (nrow(X_combined) != total_tp) {
     warning(sprintf("Combined design matrix has %d rows, expected %d. Critical error. Setting to NULL.",
                     nrow(X_combined), total_tp))
     return(NULL)
   }

  if (verbose) message("[.ndx_combine_regressors] Returning X_combined.")
  return(X_combined)
}
</file>

<file path="R/ndx_hrf.R">
#' Estimate Initial FIR HRFs using Fused Lasso
#'
#' Estimates a single "global" or "good-voxel-average" FIR HRF per condition
#' using `glmgen::fusedlasso`. The HRF is estimated from the robust mean time course
#' of "good" voxels, identified by R-squared from Pass 0 residuals.
#' Lambda parameters for fusedlasso are chosen via block-wise k-fold cross-validation.
#'
#' @param Y_fmri Matrix of fMRI data (timepoints x voxels), concatenated across runs.
#' @param pass0_residuals Matrix of residuals from `ndx_initial_glm` (timepoints x voxels).
#' @param events A data frame describing experimental events. Must contain columns:
#'   `onsets`, `durations`, `condition`, `blockids`.
#' @param run_idx Numeric vector indicating run membership for each timepoint in `Y_fmri`.
#' @param TR Numeric, repetition time in seconds.
#' @param spike_TR_mask Optional. A logical vector of length `nrow(Y_fmri)` where TRUE
#'   indicates a TR to be excluded from HRF estimation (e.g., due to spikes).
#'   If NULL, all TRs are considered valid.
#' @param user_options A list of user-configurable options:
#'   - `hrf_fir_taps` (integer): Number of FIR basis functions (e.g., 20).
#'   - `hrf_fir_span_seconds` (numeric): Total duration the FIR model covers (e.g., 24s).
#'   - `good_voxel_R2_threshold` (numeric): R-squared threshold for selecting good voxels (e.g., 0.02-0.06).
#'   - `cv_folds` (integer): Number of folds for K-fold cross-validation (e.g., 5).
#'   - `lambda1_grid` (numeric vector): Grid of values for fused penalty `lambda` (L1 on differences).
#'   - `lambda2_grid` (numeric vector): Grid of values for ridge penalty `gamma` (L2 on coefficients).
#'   - `hrf_min_good_voxels` (integer): Minimum number of good voxels required to proceed (e.g., 100).
#'   - `return_full_model` (logical): If TRUE, include the full glmgen model object in the output. Defaults to FALSE.
#' @return A tibble with columns: `condition` (character), `hrf_estimate` (list of numeric vectors),
#'   `taps` (list of integer vectors). If `user_options$return_full_model` is TRUE, an additional
#'   list-column `glmgen_fit` is included. Returns NULL if critical errors occur.
#' @examples
#' \dontrun{
#' # --- Setup from ndx_initial_glm example --- 
#' n_time_per_run <- 100; n_runs <- 2; n_voxels <- 200; TR <- 2.0
#' total_timepoints <- n_time_per_run * n_runs
#' Y_fmri_example <- matrix(rnorm(total_timepoints * n_voxels), 
#'                          nrow = total_timepoints, ncol = n_voxels)
#' run_idx_example <- rep(1:n_runs, each = n_time_per_run)
#' motion_params_example <- matrix(rnorm(total_timepoints * 6), 
#'                                 nrow = total_timepoints, ncol = 6)
#' events_example <- data.frame(
#'   onsets = c(10, 30, 50, 10, 30, 50),
#'   durations = c(5, 5, 5, 5, 5, 5),
#'   condition = rep(c("TaskA", "TaskB"), each = 3),
#'   blockids = c(1, 1, 1, 2, 2, 2)
#' )
#' # Generate some real signal for TaskA in first 50 voxels
#' sf_hrf <- fmrireg::sampling_frame(blocklens = as.numeric(table(run_idx_example)), TR=TR)
#' design_taskA <- fmrireg::event_model(~ fmrireg::hrf(TaskA, basis="spmg1"), 
#'                                      data=events_example[events_example$condition == "TaskA",], 
#'                                      block=events_example$blockids[events_example$condition == "TaskA"],
#'                                      sampling_frame=sf_hrf)
#' X_taskA_signal <- fmrireg::design_matrix(design_taskA)
#' if (ncol(X_taskA_signal) > 0) { 
#'    Y_fmri_example[,1:50] <- Y_fmri_example[,1:50] + X_taskA_signal %*% matrix(rnorm(ncol(X_taskA_signal)*50, mean=3, sd=1), ncol=50)
#' }
#' 
#' pass0_out <- ndx_initial_glm(Y_fmri_example, events_example, 
#'                                  motion_params_example, run_idx_example, TR)
#' 
#' # --- Now for ndx_estimate_initial_hrfs --- 
#' user_opts_hrf <- list(
#'   hrf_fir_taps = 12,            
#'   hrf_fir_span_seconds = 24,  
#'   good_voxel_R2_threshold = 0.01,
#'   cv_folds = 2, 
#'   lambda1_grid = 10^seq(-2, 1, length.out = 3),
#'   lambda2_grid = 10^seq(-3, 0, length.out = 3),
#'   hrf_min_good_voxels = 10,
#'   return_full_model = FALSE
#' )
#' 
#' estimated_hrfs_tbl <- ndx_estimate_initial_hrfs(
#'   Y_fmri = Y_fmri_example,
#'   pass0_residuals = pass0_out$Y_residuals_current,
#'   events = events_example,
#'   run_idx = run_idx_example,
#'   TR = TR,
#'   spike_TR_mask = NULL,
#'   user_options = user_opts_hrf
#' )
#' 
#' if (!is.null(estimated_hrfs_tbl)) {
#'   print(estimated_hrfs_tbl)
#'   # Example of unnesting for plotting (requires tidyr and ggplot2)
#'   # if (requireNamespace("tidyr", quietly = TRUE) && requireNamespace("ggplot2", quietly = TRUE)) {
#'   #   plot_df <- tidyr::unnest(estimated_hrfs_tbl, cols = c(hrf_estimate, taps))
#'   #   print(ggplot2::ggplot(plot_df, ggplot2::aes(x = taps * TR, y = hrf_estimate)) +
#'   #         ggplot2::geom_line() + ggplot2::geom_point() +
#'   #         ggplot2::facet_wrap(~condition) + ggplot2::labs(x="Time (s)", y="Amplitude"))
#'   # }
#' }
#' }
#' @import fmrireg
#' @import glmgen
#' @importFrom genlasso fusedlasso
#' @import stats
#' @import matrixStats
#' @import tibble
#' @export
ndx_estimate_initial_hrfs <- function(Y_fmri, pass0_residuals, events,
                                        run_idx, TR,
                                        spike_TR_mask = NULL,
                                        user_options) {

  validated_inputs <- validate_hrf_inputs(Y_fmri, pass0_residuals, events, run_idx, TR, 
                                            spike_TR_mask, user_options)
  user_options <- validated_inputs$user_options
  # n_timepoints <- validated_inputs$n_timepoints 
  # spike_TR_mask in this scope is the validated one from validated_inputs

  response_data <- prepare_hrf_response_data(Y_fmri, pass0_residuals, run_idx, 
                                             validated_inputs$validated_spike_TR_mask, 
                                             user_options)
  
  if (is.null(response_data)) {
    return(NULL) 
  }
  
  ybar_clean <- response_data$ybar_clean
  block_ids_for_cv <- response_data$block_ids_for_cv
  valid_TRs_for_hrf_estimation_mask <- response_data$valid_TRs_for_hrf_estimation_mask
  
  results_list_collector <- list() # Changed name to avoid clash with internal var name
  conditions <- unique(as.character(events$condition))
  
  unique_runs_overall <- unique(run_idx)
  run_lengths_overall <- as.numeric(table(factor(run_idx, levels = unique_runs_overall)))
  sf_overall <- fmrireg::sampling_frame(blocklens = run_lengths_overall, TR = TR)
  
  for (cond_name_iter in conditions) { # Renamed loop variable
    message(paste("Processing HRF for condition:", cond_name_iter))
    events_for_this_condition <- events[events$condition == cond_name_iter, , drop = FALSE]
    
    # Call the new per-condition estimation function
    condition_hrf_result <- estimate_hrf_for_condition(
      condition_name = cond_name_iter,
      events_for_condition = events_for_this_condition,
      ybar_clean = ybar_clean,
      block_ids_for_cv = block_ids_for_cv,
      overall_sampling_frame = sf_overall,
      valid_TRs_mask = valid_TRs_for_hrf_estimation_mask, # pass the mask directly
      TR = TR,
      user_options = user_options
    )
    results_list_collector[[cond_name_iter]] <- condition_hrf_result
  }
  
  if (length(results_list_collector) == 0) return(NULL) # Should be caught if conditions is empty
  
  # Convert list of lists to a tibble
  # Filter out any top-level NULLs if a condition somehow failed to even produce a list structure (unlikely with current setup)
  valid_results <- Filter(Negate(is.null), results_list_collector)
  if(length(valid_results) == 0 && length(conditions) > 0) {
      warning("No valid HRF results were generated for any condition.")
      return(NULL)
  }
  if(length(valid_results) == 0 && length(conditions) == 0) {
      message("No conditions found in event data to estimate HRFs for.")
      return(NULL)
  }

  # Reconstruct based on the structure returned by estimate_hrf_for_condition
  conditions_out <- sapply(valid_results, function(x) x$condition)
  hrf_estimates_out <- lapply(valid_results, function(x) x$hrf_estimate)
  taps_out <- lapply(valid_results, function(x) x$taps)
  
  output_tbl <- tibble::tibble(
      condition = conditions_out,
      hrf_estimate = hrf_estimates_out,
      taps = taps_out
  )
  
  if (user_options$return_full_model) {
      glmgen_fits_out <- lapply(valid_results, function(x) x$glmgen_fit)
      # Ensure this column is added only if there are valid results
      if (nrow(output_tbl) > 0) {
        output_tbl$glmgen_fit <- glmgen_fits_out
      } else if (length(glmgen_fits_out) > 0) {
        # This case (no rows in output_tbl but fits exist) should not happen if logic is correct
        # but as a fallback, create a tibble for fits if conditions_out was empty but fits were somehow produced
        output_tbl <- tibble::tibble(condition=NA_character_, hrf_estimate=list(NULL), taps=list(NULL), glmgen_fit = glmgen_fits_out)[-1,]
        warning("HRF fitting produced glmgen_fits but no primary HRF data; check for inconsistencies.")
      }
  }
  
  if (nrow(output_tbl) == 0 && length(conditions) > 0) {
      warning("HRF estimation resulted in an empty table despite conditions being present. Check warnings for individual conditions.")
      return(NULL)
  }

  return(output_tbl)
}

#' Generate FIR Design Matrix for a Specific Condition
#' @keywords internal
get_fir_design_matrix_for_condition <- function(condition_name, events_df,
                                                sampling_frame, fir_taps, TR) {
  if (nrow(events_df) == 0) {
    return(matrix(0, nrow = sampling_frame$total_samples, ncol = fir_taps))
  }
  
  safe_cond_name <- make.names(condition_name, unique = FALSE)
  fir_span <- fir_taps * TR 
  
  if (safe_cond_name != condition_name) {
    formula_term <- sprintf("fmrireg::hrf(`%s`, basis=\"tent\", nbasis=%d, span=%.2f)", 
                            condition_name, fir_taps, fir_span)
  } else {
    formula_term <- sprintf("fmrireg::hrf(%s, basis=\"tent\", nbasis=%d, span=%.2f)", 
                            condition_name, fir_taps, fir_span)
  }
  
  model_formula_str <- paste("~", formula_term)
  model_formula <- as.formula(model_formula_str)
  
  ev_model <- fmrireg::event_model(model_formula,
                                 data = events_df, 
                                 block = events_df$blockids,
                                 sampling_frame = sampling_frame,
                                 drop_empty = FALSE) 
  
  X_fir <- fmrireg::design_matrix(ev_model)
  
  if (ncol(X_fir) != fir_taps) {
      if (ncol(X_fir) == fir_taps + 1 && all(X_fir[,1] == 1)) { 
          warning(sprintf("FIR design for %s included an intercept; removing it.", condition_name))
          X_fir <- X_fir[, -1, drop=FALSE]
      } else if (ncol(X_fir) == 0 && fir_taps > 0 && nrow(events_df) > 0) {
          warning(sprintf("FIR design for %s (with %d events) resulted in 0 columns. Expected %d. Check event timings relative to scan length and FIR span. Returning zeros.", 
                          condition_name, nrow(events_df), fir_taps))
          return(matrix(0, nrow = sampling_frame$total_samples, ncol = fir_taps))
      } else if (ncol(X_fir) != fir_taps && nrow(events_df) > 0) {
        stop(sprintf("FIR design for %s has %d columns, expected %d. FIR span %.2f. Events: %d. Check event data relative to FIR parameters and scan times.", 
                     condition_name, ncol(X_fir), fir_taps, fir_span, nrow(events_df)))
      } else if (ncol(X_fir) == 0 && fir_taps > 0 && nrow(events_df) == 0) {
         return(matrix(0, nrow = sampling_frame$total_samples, ncol = fir_taps))
      }
  }
  
  return(X_fir)
}

#' Basic Cone Projection Heuristic for FIR Coefficients
#' @keywords internal
project_cone_heuristic <- function(fir_coeffs) {
  if (length(fir_coeffs) == 0) return(numeric(0))
  
  coeffs_adj <- fir_coeffs
  if (length(coeffs_adj) > 0) { 
    coeffs_adj <- coeffs_adj - coeffs_adj[1]
  }
  
  if (length(coeffs_adj) >= 2 && coeffs_adj[2] < 0) {
    coeffs_adj[2] <- 0
  }
  
  # If HRF became flat (all zeros) after initial adjustment, give it a small bump.
  if (sum(abs(coeffs_adj)) < 1e-9 && length(coeffs_adj) > 0) {
      # Place a small positive value at a plausible early peak (e.g., 1/3rd of the way through taps)
      peak_tap_idx <- max(1, floor(length(coeffs_adj) / 3))
      coeffs_adj[peak_tap_idx] <- 1e-6
  }
  
  return(coeffs_adj)
}

#' Block-wise K-fold Cross-Validation for Fused Lasso (glmgen)
#' @keywords internal
cv_fusedlasso <- function(y, X, lambda_grid, gamma_grid, k_folds, block_ids) {
  if (nrow(X) != length(y)) stop("nrow(X) must equal length(y) for CV.")
  if (length(block_ids) != length(y)) stop("Length of block_ids must match length(y).")
  
  p_coeffs <- ncol(X)
  D_1d <- NULL
  if (p_coeffs > 1) {
    D_1d <- diff(diag(p_coeffs), differences = 1)
  } else if (p_coeffs == 1) {
    D_1d <- diff(diag(1), differences = 1) # 0-row matrix, results in no fusion penalty
  }

  unique_blocks <- unique(block_ids)
  n_unique_blocks <- length(unique_blocks)
  
  if (n_unique_blocks == 0) stop("No blocks provided for CV.")
  if (n_unique_blocks < 2 && k_folds > 1) {
      warning("Only 1 unique block for CV. Cannot perform k-fold CV with k > 1. Setting k_folds = 1 (no CV, using first lambda/gamma).")
      k_folds <- 1 
  }
  if (k_folds > n_unique_blocks) {
    warning(paste("k_folds (", k_folds, ") is greater than the number of unique blocks (", n_unique_blocks,
                  "). Setting k_folds to ", n_unique_blocks, " (leave-one-block-out CV).", sep=""))
    k_folds <- n_unique_blocks
  }
  if (nrow(X) < k_folds && k_folds > 1) { 
      warning(paste("Number of observations (", nrow(X), ") is less than k_folds (", k_folds, ") after block considerations. Adjusting k_folds."))
      k_folds <- max(1, min(k_folds, nrow(X))) 
  }

  fold_assignment_for_blocks <- sample(rep(1:k_folds, length.out = n_unique_blocks))
  observation_fold_indices <- fold_assignment_for_blocks[match(block_ids, unique_blocks)]
  
  cv_errors <- array(NA, dim = c(length(lambda_grid), length(gamma_grid)))
  dimnames(cv_errors) <- list(lambda = signif(lambda_grid,3), gamma = signif(gamma_grid,3))

  for (i_g in seq_along(gamma_grid)) { # Outer loop for gamma (L2 penalty)
    gamma_val <- gamma_grid[i_g]
    fold_mse_for_gamma <- matrix(NA, nrow = k_folds, ncol = length(lambda_grid))

    # Pre-calculate the fusedlasso path for this gamma_val if k_folds > 1
    # For k_folds = 1, we do it inside the lambda loop as it's just one fit.

    for (k in 1:k_folds) {
      test_idx <- which(observation_fold_indices == k)
      train_idx <- which(observation_fold_indices != k)

      if (k_folds == 1) { # Special case: no actual CV, fit on full data for each lambda/gamma
          # This logic might need refinement if k_folds=1 means predict on same data
          # For now, assume it means fit on y, X and then evaluate for each lambda
          y_train <- y; X_train <- X
          y_test <- y; X_test <- X # Evaluate on same data if k_folds = 1
      } else {
          if (length(train_idx) == 0 || length(test_idx) == 0) {
              fold_mse_for_gamma[k, ] <- Inf 
              next
          }
          y_train <- y[train_idx]
          X_train <- X[train_idx, , drop = FALSE]
          y_test <- y[test_idx]
          X_test <- X[test_idx, , drop = FALSE]
      }
      
      if (nrow(X_train) < ncol(X_train) || nrow(X_train) < 2) { 
          fold_mse_for_gamma[k, ] <- Inf
          next
      }

      fit_path <- tryCatch({
        genlasso::fusedlasso(y = y_train, X = X_train, D = D_1d, gamma = gamma_val)
      }, error = function(e) {
        warning(sprintf("genlasso::fusedlasso failed for gamma=%.4f on fold %d: %s. Skipping.", gamma_val, k, e$message))
        return(NULL)
      })

      if (is.null(fit_path) || !inherits(fit_path, "genlasso")) {
        fold_mse_for_gamma[k, ] <- Inf
        next
      }

      for (i_l in seq_along(lambda_grid)) {
        lambda_val <- lambda_grid[i_l]
        beta_coeffs <- tryCatch({
          stats::coef(fit_path, lambda = lambda_val)$beta
        }, error = function(e) { NULL })

        if (is.null(beta_coeffs) || length(beta_coeffs) != ncol(X_test)) {
          fold_mse_for_gamma[k, i_l] <- Inf
        } else {
          preds <- X_test %*% beta_coeffs
          fold_mse_for_gamma[k, i_l] <- mean((y_test - preds)^2, na.rm = TRUE)
        }
      }
    } # end k_folds loop
    
    # Average MSE across folds for each lambda, for the current gamma
    for (i_l in seq_along(lambda_grid)) {
        current_lambda_mses <- fold_mse_for_gamma[, i_l]
        mean_mse <- mean(current_lambda_mses[is.finite(current_lambda_mses)], na.rm = TRUE)
        if (!is.finite(mean_mse)) mean_mse <- Inf
        cv_errors[i_l, i_g] <- mean_mse
    }
  } # end gamma_grid loop
  
  if (all(!is.finite(cv_errors))) {
      warning("All CV folds resulted in errors or non-finite MSE for all lambda/gamma combinations. Cannot select optimal parameters.")
      best_l <- lambda_grid[1] 
      best_g <- gamma_grid[1]  
  } else {
      min_error_idx <- arrayInd(which.min(cv_errors), dim(cv_errors))
      best_l <- lambda_grid[min_error_idx[1]]
      best_g <- gamma_grid[min_error_idx[2]]
  }
  
  return(list(best_lambda = best_l, 
              best_gamma = best_g, 
              cv_error_matrix = cv_errors))
}

#' Validate Inputs for HRF Estimation
#'
#' Helper function to validate inputs for `ndx_estimate_initial_hrfs`.
#' Also merges user_options with defaults.
#'
#' @param Y_fmri Matrix of fMRI data.
#' @param pass0_residuals Matrix of residuals.
#' @param events Data frame of experimental events.
#' @param run_idx Numeric vector of run membership.
#' @param TR Numeric, repetition time.
#' @param spike_TR_mask Optional logical vector for spike TRs.
#' @param user_options A list of user-configurable options.
#' @return A list containing validated and potentially augmented `user_options`,
#'   and `n_timepoints` and `validated_spike_TR_mask`.
#' @keywords internal
validate_hrf_inputs <- function(Y_fmri, pass0_residuals, events, run_idx, TR, spike_TR_mask, user_options) {
  if (missing(user_options)) stop("user_options are required for HRF estimation.")
  
  default_opts <- list(return_full_model = FALSE) # Add other defaults if any arise
  user_options <- utils::modifyList(default_opts, user_options)

  expected_opts_names <- c("hrf_fir_taps", "hrf_fir_span_seconds", "good_voxel_R2_threshold",
                           "cv_folds", "lambda1_grid", "lambda2_grid", "hrf_min_good_voxels", "return_full_model")
  if(!all(expected_opts_names %in% names(user_options))) {
    stop(paste("Missing one or more user_options for HRF estimation:", 
               paste(expected_opts_names[!expected_opts_names %in% names(user_options)], collapse=", ")))
  }

  if (!is.matrix(Y_fmri) || !is.numeric(Y_fmri)) stop("Y_fmri must be a numeric matrix.")
  n_timepoints <- nrow(Y_fmri)
  if (n_timepoints == 0) stop("Y_fmri has zero timepoints.")
  if (ncol(Y_fmri) == 0) stop("Y_fmri has zero voxels.")

  if (!is.matrix(pass0_residuals) || !is.numeric(pass0_residuals) || 
      nrow(pass0_residuals) != n_timepoints || ncol(pass0_residuals) != ncol(Y_fmri)) {
    stop("pass0_residuals must be a numeric matrix with dimensions matching Y_fmri.")
  }

  if (!is.data.frame(events)) stop("events must be a data frame.")
  required_event_cols <- c("onsets", "durations", "condition", "blockids")
  if (!all(required_event_cols %in% names(events))) {
    stop(paste("events data frame must contain columns:", paste(required_event_cols, collapse=", ")))
  }
  if(!is.numeric(events$onsets) || !is.numeric(events$durations) || !is.numeric(events$blockids)) {
      stop("Event columns 'onsets', 'durations', and 'blockids' must be numeric.")
  }

  if (!is.numeric(run_idx) || length(run_idx) != n_timepoints) {
    stop("run_idx must be a numeric vector with length matching nrow(Y_fmri).")
  }
  if (!is.numeric(TR) || length(TR) != 1 || TR <= 0) {
    stop("TR must be a single positive number.")
  }

  validated_spike_TR_mask <- spike_TR_mask
  if (is.null(validated_spike_TR_mask)) {
    validated_spike_TR_mask <- rep(FALSE, n_timepoints)
  }
  if (length(validated_spike_TR_mask) != n_timepoints || !is.logical(validated_spike_TR_mask)) {
      stop("spike_TR_mask must be a logical vector with length matching n_timepoints in Y_fmri.")
  }
  
  # Validate specific user_options types and values
  if(!is.numeric(user_options$hrf_fir_taps) || user_options$hrf_fir_taps <=0) stop("hrf_fir_taps must be a positive integer.")
  if(!is.numeric(user_options$hrf_fir_span_seconds) || user_options$hrf_fir_span_seconds <=0) stop("hrf_fir_span_seconds must be a positive number.")
  if(!is.numeric(user_options$good_voxel_R2_threshold) || user_options$good_voxel_R2_threshold < 0 || user_options$good_voxel_R2_threshold > 1) stop("good_voxel_R2_threshold must be between 0 and 1.")
  if(!is.numeric(user_options$cv_folds) || user_options$cv_folds <=0) stop("cv_folds must be a positive integer.")
  if(!is.numeric(user_options$lambda1_grid) || length(user_options$lambda1_grid)==0) stop("lambda1_grid must be a non-empty numeric vector.")
  if(!is.numeric(user_options$lambda2_grid) || length(user_options$lambda2_grid)==0) stop("lambda2_grid must be a non-empty numeric vector.")
  if(!is.numeric(user_options$hrf_min_good_voxels) || user_options$hrf_min_good_voxels <0) stop("hrf_min_good_voxels must be a non-negative integer.")
  if(!is.logical(user_options$return_full_model) || length(user_options$return_full_model)!=1) stop("return_full_model must be a single logical value.")

  return(list(user_options = user_options, 
              n_timepoints = n_timepoints, 
              validated_spike_TR_mask = validated_spike_TR_mask))
}

#' Prepare Response Data for HRF Estimation
#'
#' Calculates R2, selects good voxels, and prepares the robust mean time course (`ybar_clean`)
#' from these good voxels, along with associated masks and block IDs for cross-validation.
#'
#' @param Y_fmri Validated fMRI data matrix.
#' @param pass0_residuals Validated Pass 0 residuals matrix.
#' @param run_idx Validated run index vector.
#' @param validated_spike_TR_mask Validated logical mask for spike TRs.
#' @param user_options Validated list of user options, must include 
#'   `good_voxel_R2_threshold` and `hrf_min_good_voxels`.
#' @return A list containing:
#'   - `ybar_clean`: Numeric vector, the robust mean of good voxels on valid TRs.
#'   - `block_ids_for_cv`: Numeric vector, run/block IDs for `ybar_clean`.
#'   - `valid_TRs_for_hrf_estimation_mask`: Logical mask for all original TRs indicating validity for HRF estimation.
#'   - `n_good_voxels`: Integer, count of selected good voxels.
#'   Returns NULL if insufficient good voxels or no valid TRs for estimation.
#' @keywords internal
prepare_hrf_response_data <- function(Y_fmri, pass0_residuals, run_idx, validated_spike_TR_mask, user_options) {
  R2_pass0_vox <- calculate_R2_voxelwise(Y_fmri, pass0_residuals)
  good_voxels_idx <- which(R2_pass0_vox >= user_options$good_voxel_R2_threshold)
  n_good_voxels <- length(good_voxels_idx)

  if (n_good_voxels < user_options$hrf_min_good_voxels) {
    warning(sprintf("Insufficient good voxels found (%d) based on R2 threshold (%.2f). Minimum required: %d. Skipping HRF estimation.",
                    n_good_voxels, user_options$good_voxel_R2_threshold, user_options$hrf_min_good_voxels))
    return(NULL)
  }
  
  Y_good_voxels <- Y_fmri[, good_voxels_idx, drop = FALSE]
  if (ncol(Y_good_voxels) == 0) { 
      warning("No good voxels selected (ncol=0) despite passing minimum count. Check R2 threshold or data. Skipping HRF estimation.")
      return(NULL)
  }

  valid_TRs_for_hrf_estimation_mask <- !validated_spike_TR_mask
  if (sum(valid_TRs_for_hrf_estimation_mask) == 0) {
      warning("No valid TRs available for HRF estimation after applying spike_TR_mask. Skipping HRF estimation.")
      return(NULL)
  }
  
  # Calculate rowMedians on the subset of good voxels, for all original timepoints
  ybar_all_trs <- matrixStats::rowMedians(Y_good_voxels, na.rm = TRUE) 
  # Then select only the valid (non-spike) TRs for ybar_clean
  ybar_clean <- ybar_all_trs[valid_TRs_for_hrf_estimation_mask]
  # Corresponding block IDs for these valid TRs
  block_ids_for_cv <- run_idx[valid_TRs_for_hrf_estimation_mask]
  
  return(list(
    ybar_clean = ybar_clean,
    block_ids_for_cv = block_ids_for_cv,
    valid_TRs_for_hrf_estimation_mask = valid_TRs_for_hrf_estimation_mask,
    n_good_voxels = n_good_voxels
  ))
}

#' Estimate FIR HRF for a Single Condition
#'
#' Performs FIR design matrix generation, cross-validation for fused lasso parameters,
#' final model fitting, and post-processing for a single experimental condition.
#'
#' @param condition_name Character, the name of the condition.
#' @param events_for_condition Data frame of events, already filtered for this specific condition.
#' @param ybar_clean Numeric vector, the robust mean time course of good voxels on valid TRs.
#' @param block_ids_for_cv Numeric vector, run/block IDs for `ybar_clean`.
#' @param overall_sampling_frame An `fmri_sampling_frame` object for all original TRs.
#' @param valid_TRs_mask Logical mask for all original TRs indicating validity for HRF estimation.
#' @param TR Numeric, repetition time.
#' @param user_options List of user options, including `hrf_fir_taps`, `lambda1_grid`, 
#'   `lambda2_grid`, `cv_folds`, and `return_full_model`.
#' @return A list containing:
#'   - `condition`: Character, the condition name.
#'   - `hrf_estimate`: Numeric vector of estimated FIR coefficients, or NULL if estimation fails.
#'   - `taps`: Integer vector of tap indices, or NULL.
#'   - `glmgen_fit`: The `glmgen::fusedlasso` model object if `user_options$return_full_model` is TRUE, else NULL.
#' @keywords internal
estimate_hrf_for_condition <- function(condition_name, events_for_condition,
                                       ybar_clean, block_ids_for_cv,
                                       overall_sampling_frame, valid_TRs_mask, TR,
                                       user_options) {
  
  current_result <- list(condition = condition_name, hrf_estimate = NULL, taps = NULL)
  if (user_options$return_full_model) current_result$glmgen_fit <- NULL

  if (nrow(events_for_condition) == 0) {
      warning(paste("No events found for condition (passed to estimate_hrf_for_condition):", condition_name)) # Should be caught earlier
      return(current_result)
  }
  
  X_fir_cond_all_trs <- tryCatch({
       get_fir_design_matrix_for_condition(
          condition_name = condition_name,
          events_df = events_for_condition, 
          sampling_frame = overall_sampling_frame, 
          fir_taps = user_options$hrf_fir_taps,
          TR = TR 
      )
  }, error = function(e) {
      warning(paste("Error generating FIR design for condition", condition_name, "in estimate_hrf_for_condition:", e$message))
      return(NULL)
  })

  if (is.null(X_fir_cond_all_trs) || ncol(X_fir_cond_all_trs) == 0) {
    warning(paste("FIR design matrix for condition", condition_name, "is empty or NULL in estimate_hrf_for_condition."))
    return(current_result)
  }
  
  # Subset the design matrix to include only non-spike TRs (valid for estimation)
  X_fir_cond_clean <- X_fir_cond_all_trs[valid_TRs_mask, , drop = FALSE]
  
  if (nrow(X_fir_cond_clean) != length(ybar_clean)){
      stop(sprintf("Critical internal error (estimate_hrf_for_condition): Mismatch in length of ybar_clean (%d) and rows of X_fir_cond_clean (%d) for condition: %s",
                 length(ybar_clean), nrow(X_fir_cond_clean), condition_name))
  }
  
  if (sum(abs(X_fir_cond_clean)) < 1e-6 ) { 
      warning(sprintf("No effective stimulus events for condition '%s' fall within non-spike TRs for FIR estimation (in estimate_hrf_for_condition).", condition_name))
      return(current_result)
  }

  min_trs_needed <- max(user_options$hrf_fir_taps * 2, user_options$cv_folds + 1) 
  if (nrow(X_fir_cond_clean) < min_trs_needed) { 
      warning(sprintf("Not enough valid TRs (%d, need ~%d) to estimate FIR for condition: %s (in estimate_hrf_for_condition).", 
                      nrow(X_fir_cond_clean), min_trs_needed, condition_name))
      return(current_result)
  }
  
  cv_results <- cv_fusedlasso(y = ybar_clean, X = X_fir_cond_clean,
                                lambda_grid = user_options$lambda1_grid, 
                                gamma_grid = user_options$lambda2_grid,  
                                k_folds = user_options$cv_folds,
                                block_ids = block_ids_for_cv)
  
  best_lambda1 <- cv_results$best_lambda
  best_lambda2 <- cv_results$best_gamma
  
  message(sprintf("  Condition '%s': Best lambda1 (L1 diff): %.4f, Best lambda2 (L2 coeff): %.4f", 
                  condition_name, best_lambda1, best_lambda2))
  
  X_mat <- X_fir_cond_clean
  p_coeffs_final <- ncol(X_mat)
  D_1d_final <- NULL
  if (p_coeffs_final > 1) {
    D_1d_final <- diff(diag(p_coeffs_final), differences = 1)
  } else if (p_coeffs_final == 1) {
    D_1d_final <- diff(diag(1), differences = 1)
  }
  
  final_fit_path <- tryCatch({
    genlasso::fusedlasso(y = ybar_clean, X = X_mat, D = D_1d_final, gamma = best_lambda2)
  }, error = function(e) {
    warning(sprintf("Final genlasso::fusedlasso fit failed for condition '%s' with gamma=%.4f: %s", 
                    condition_name, best_lambda2, e$message))
    return(NULL)
  })
  
  if (is.null(final_fit_path) || !inherits(final_fit_path, "genlasso")) {
    warning(sprintf("Final genlasso::fusedlasso fit for condition '%s' is NULL or not a genlasso object. Check warnings.", condition_name))
    return(current_result)
  }
  
  fir_coeffs <- tryCatch({
    stats::coef(final_fit_path, lambda = best_lambda1)$beta
  }, error = function(e) {
    warning(sprintf("Failed to extract coefficients for condition '%s' with lambda=%.4f from genlasso fit: %s", 
                    condition_name, best_lambda1, e$message))
    return(NULL)
  })
  
  if (is.null(fir_coeffs)) {
    return(current_result) # Return NULL hrf_estimate as fir_coeffs extraction failed
  }
  
  if (length(fir_coeffs) != user_options$hrf_fir_taps) {
    warning(sprintf("Coefficient length mismatch for condition %s. Expected: %d, Got: %d. Padding/truncating.",
                    condition_name, user_options$hrf_fir_taps, length(fir_coeffs)))
    temp_coeffs <- rep(0, user_options$hrf_fir_taps)
    len_to_copy <- min(length(fir_coeffs), user_options$hrf_fir_taps)
    if (len_to_copy > 0) temp_coeffs[1:len_to_copy] <- fir_coeffs[1:len_to_copy]
    fir_coeffs <- temp_coeffs
  }
  
  current_result$hrf_estimate <- project_cone_heuristic(fir_coeffs)
  current_result$taps <- seq_len(user_options$hrf_fir_taps)
  if (user_options$return_full_model) {
      current_result$glmgen_fit <- final_fit_path
  }
  return(current_result)
}
</file>

<file path="R/ndx_initial_glm.R">
#' Perform an Initial GLM to Generate Residuals and Baseline Variance
#'
#' This function performs an initial GLM fit to the fMRI data to obtain
#' residuals that will serve as input for subsequent denoising steps (e.g., RPCA).
#' It also calculates the variance of residuals from a simpler task-only model,
#' which is used as the denominator in the Denoising Efficacy Score (DES).
#'
#' @param Y_fmri Matrix of fMRI data (timepoints x voxels). Assumed to be
#'   concatenated across runs if multiple runs are present.
#' @param events A data frame describing experimental events. Must contain columns:
#'   - `onsets`: Numeric, onset time of the event in seconds, relative to the start of its run.
#'   - `durations`: Numeric, duration of the event in seconds.
#'   - `condition`: Character or factor, identifying the event type/condition.
#'   - `blockids`: Numeric, 1-indexed, identifying the run/block each event belongs to.
#'                 This must correspond to the runs in `run_idx` and `Y_fmri`.
#' @param motion_params Matrix or data frame of motion parameters (timepoints x n_regressors).
#'   Must have the same number of rows as `Y_fmri`.
#' @param run_idx Numeric vector indicating run membership for each timepoint in `Y_fmri`.
#'   (e.g., c(rep(1,100), rep(2,100)) for two runs of 100 timepoints each).
#' @param TR Numeric, repetition time in seconds.
#' @return A list containing:
#'   - `Y_residuals_current`: Matrix of residuals after the full initial GLM (task + motion + polynomials).
#'   - `VAR_BASELINE_FOR_DES`: Numeric, variance of residuals from a task-only GLM (task + run intercepts).
#' @examples
#' \dontrun{
#' # Example Usage (requires fmrireg and appropriate data)
#' # Define some hypothetical data
#' n_time_per_run <- 100
#' n_runs <- 2
#' n_voxels <- 10
#' TR <- 2.0
#' total_timepoints <- n_time_per_run * n_runs
#'
#' Y_fmri_example <- matrix(rnorm(total_timepoints * n_voxels), nrow = total_timepoints, ncol = n_voxels)
#' run_idx_example <- rep(1:n_runs, each = n_time_per_run)
#' motion_params_example <- matrix(rnorm(total_timepoints * 6), nrow = total_timepoints, ncol = 6)
#'
#' # Simple events table
#' events_example <- data.frame(
#'   onsets = c(10, 30, 10, 30),
#'   durations = c(5, 5, 5, 5),
#'   condition = rep(c("TaskA", "TaskB"), 2),
#'   blockids = c(1, 1, 2, 2)
#' )
#'
#' initial_glm_output <- ndx_initial_glm(Y_fmri_example, events_example,
#'                                     motion_params_example, run_idx_example, TR)
#' head(initial_glm_output$Y_residuals_current)
#' print(initial_glm_output$VAR_BASELINE_FOR_DES)
#' }
#' @import fmrireg
#' @import stats
#' @export
ndx_initial_glm <- function(Y_fmri, events, motion_params, run_idx, TR) {

  # Validate inputs
  if (!is.matrix(Y_fmri)) {
    stop("Y_fmri must be a matrix (timepoints x voxels).")
  }
  n_timepoints <- nrow(Y_fmri)
  if (n_timepoints == 0) stop("Y_fmri has zero timepoints.")
  if (ncol(Y_fmri) == 0) stop("Y_fmri has zero voxels.")

  if (!is.data.frame(events)) stop("events must be a data frame.")
  required_event_cols <- c("onsets", "durations", "condition", "blockids")
  if (!all(required_event_cols %in% names(events))) {
    stop(paste("events data frame must contain columns:", paste(required_event_cols, collapse=", ")))
  }

  if (!is.matrix(motion_params) && !is.data.frame(motion_params)) {
    stop("motion_params must be a matrix or data frame.")
  }
  if (nrow(motion_params) != n_timepoints) {
    stop("Number of rows in motion_params must match Y_fmri.")
  }

  if (!is.numeric(run_idx) || length(run_idx) != n_timepoints) {
    stop("run_idx must be a numeric vector with length matching nrow(Y_fmri).")
  }
  if (!is.numeric(TR) || length(TR) != 1 || TR <= 0) {
    stop("TR must be a single positive number.")
  }

  # 1. Create Sampling Frame
  # table() on run_idx gives counts per run, which are the blocklens
  # Ensure runs are ordered if run_idx is not already e.g. 1,1,1,2,2,2
  unique_runs <- unique(run_idx)
  if (any(diff(unique_runs) < 0) && length(unique_runs) >1 ) { # check if not sorted if multiple runs
      # This ensures blocklens are in the order of appearance of runs
      run_lengths <- as.numeric(table(factor(run_idx, levels=unique(run_idx))))
  } else {
      run_lengths <- as.numeric(table(run_idx))
  }
  
  if(any(run_lengths == 0)) stop("Some runs specified in run_idx have zero length.")

  sf <- fmrireg::sampling_frame(blocklens = run_lengths, TR = TR)

  # 2. Task-Only Model (for VAR_BASELINE_FOR_DES)
  task_conditions <- unique(as.character(events$condition))
  
  # Create a copy of events to modify for the model
  events_for_model_wide <- events
  if (!is.factor(events_for_model_wide$condition)) {
    events_for_model_wide$condition <- factor(events_for_model_wide$condition)
  }

  if (length(task_conditions) == 0) {
    warning("No task conditions found in 'events$condition'. VAR_BASELINE_FOR_DES will be based on a baseline-only model.")
    task_formula_str <- "~ 0" 
  } else {
    formula_terms <- character(length(task_conditions))
    for (i in seq_along(task_conditions)) {
      cond_name <- task_conditions[i]
      # Create a syntactically valid column name for the dummy variable
      dummy_col_name <- make.names(cond_name) 
      
      # Add a dummy coded column for the current condition to the events data frame
      # This column will be TRUE/1 for rows matching the current condition, FALSE/0 otherwise.
      # This is NOT what fmrireg::hrf expects. hrf(var) expects 'var' to define onsets for that event type.
      # The original 'events' table is long format. fmrireg should use onsets/durations from it, filtered by condition.

      # Let's revert to the idea that hrf(condition_factor_column_name, ...) should work if fmrireg is robust.
      # The previous errors might have been due to something else if this structure is standard for fmrireg.
      # The most standard fmrireg usage for multiple conditions from a single factor column in `data`
      # when onsets/durations are also columns in `data` is indeed `~ hrf(condition_factor_column_name, ...)`
      # where `condition_factor_column_name` is the actual name of the column in the `data` data.frame.
    }
    # This simplified approach should be the one fmrireg handles if it supports long-format event tables well.
    task_formula_str <- "onsets ~ fmrireg::hrf(condition, basis=\"spmg1\")"
  }
  
  task_formula <- as.formula(task_formula_str)

  # Pass the events table (with condition as factor).
  # fmrireg::event_model will use the 'onsets' column from LHS of formula,
  # and 'condition' for grouping from RHS, all from the 'data' argument.
  # The 'block' argument aligns these to runs in the sampling_frame.
  em_task_only <- fmrireg::event_model(task_formula, 
                                     data = events_for_model_wide, 
                                     block = events_for_model_wide$blockids, 
                                     sampling_frame = sf)
  bm_task_only <- fmrireg::baseline_model(basis = "constant", intercept = "runwise", sframe = sf)
  model_task_only <- fmrireg::fmri_model(event_model = em_task_only, baseline_model = bm_task_only)
  
  X_task_only <- tryCatch({
    fmrireg::design_matrix(model_task_only)
  }, error = function(e) {
    stop(paste("Error creating task-only design matrix:", e$message))
  })
  
  if (ncol(X_task_only) == 0 && length(task_conditions) > 0) {
      warning("Task-only design matrix has zero columns despite conditions being present. Check event timings and model spec.")
  } else if (ncol(X_task_only) == 0 && length(task_conditions) == 0) {
      warning("Task-only design matrix (baseline only) has zero columns. This is unexpected.")
  }

  resid_task_only <- calculate_residuals_ols(Y_fmri, as.matrix(X_task_only))
  VAR_BASELINE_FOR_DES <- stats::var(as.vector(resid_task_only))

  # 3. Pass 0 Model (for Y_residuals_current)
  # Event model (em_task_only) is the same.
  # Baseline model includes motion and polynomials.
  # Ensure motion_params is a matrix for nuisance_list
  mat_motion_params <- as.matrix(motion_params)
  # Column names for motion parameters are tricky if they are to be split into a list for nuisance_list.
  # fmrireg might expect consistent naming or just a list of matrices.
  # For now, we'll name the concatenated matrix, then split.
  if (ncol(mat_motion_params) > 0) {
      colnames(mat_motion_params) <- paste0("motion_col_", 1:ncol(mat_motion_params))
  }

  # Prepare nuisance_list based on number of runs
  n_runs_from_sf <- length(sf$blocklens) # Get number of runs from sampling_frame
  nuisance_arg_for_bm_pass0 <- NULL
  if (ncol(mat_motion_params) > 0) { # Only add nuisance if there are motion params
    if (n_runs_from_sf > 1) {
      # Split mat_motion_params by run_idx into a list of matrices
      # Each element of the list will be the motion regressors for that run
      split_motion_params <- split.data.frame(mat_motion_params, run_idx)
      # Convert data frames in list to matrices
      nuisance_arg_for_bm_pass0 <- lapply(split_motion_params, as.matrix)
      # fmrireg might expect this to be a named list if multiple nuisance types, 
      # or an unnamed list if it's just one type of nuisance split by block.
      # The error message suggests the *number* of elements in nuisance_list must match blocks.
      # If nuisance_list itself should contain one element per block for a *given* nuisance type,
      # then this structure (a list of matrices) is what fmrireg expects for `list(motion_effects=LIST_OF_MATRICES_PER_RUN)`.
      # Or, does it expect nuisance_list = list(run1_motion=mat1, run2_motion=mat2)?
      # Let's try making nuisance_list a list where each element is a nuisance matrix for a run.
      # The error says "number of `nuisance_list` elements must match number of blocks"
      # This implies nuisance_list = list(run1_nuis, run2_nuis, ...)
      # where each run_i_nuis is a matrix. Let's test this interpretation.
      # The elements of this list should probably be matrices of nuisance for each run.
      # So, if `mat_motion_params` is the only nuisance, we pass a list of these split matrices.
    } else { 
      # Single run, nuisance_list has one element which is the full (single-run) motion matrix
      nuisance_arg_for_bm_pass0 <- list(motion_effects_run1 = mat_motion_params)
    }
  }

  bm_pass0 <- fmrireg::baseline_model(basis = "poly", degree = 1L, intercept = "runwise",
                                      sframe = sf, nuisance_list = nuisance_arg_for_bm_pass0)

  model_pass0 <- fmrireg::fmri_model(event_model = em_task_only, baseline_model = bm_pass0)
  
  X_pass0 <- tryCatch({
    fmrireg::design_matrix(model_pass0)
  }, error = function(e) {
    stop(paste("Error creating Pass-0 design matrix:", e$message))
  })

  if (ncol(X_pass0) == 0) {
      stop("Pass-0 design matrix has zero columns. This indicates a serious issue with model specification.")
  }
  
  Y_residuals_current <- calculate_residuals_ols(Y_fmri, as.matrix(X_pass0))

  return(list(
    Y_residuals_current = Y_residuals_current,
    VAR_BASELINE_FOR_DES = VAR_BASELINE_FOR_DES
  ))
}
</file>

<file path="R/ndx_ridge.R">
#' Solve Ridge Regression for fMRI Data
#'
#' Solves the ridge regression problem for whitened fMRI data and a whitened design matrix.
#' For Sprint 1, this implements a basic isotropic ridge regression.
#'
#' @param Y_whitened A numeric matrix (timepoints x voxels) of whitened fMRI data.
#'   The first `order` rows (from AR pre-whitening) might be NA and should be handled (e.g. by removing them
#'   along with corresponding rows in X_whitened before solving).
#' @param X_whitened A numeric matrix (timepoints x regressors) of the whitened design matrix.
#'   Corresponding rows to NAs in Y_whitened should also be handled/removed.
#' @param lambda_ridge A single numeric value for the ridge penalty (lambda). For Sprint 1,
#'   this is a fixed value. GCV selection can be added later.
#' @param na_mask An optional logical vector indicating rows to remove from Y_whitened and X_whitened
#'   due to NA values (e.g., from AR filter initialization). If NULL (default), the function will
#'   attempt to identify and remove rows with any NAs in Y_whitened.
#'
#' @return A matrix (regressors x voxels) of estimated beta coefficients (betas_whitened).
#'
#' @details
#' The ridge regression solution is `beta = (X'X + lambda * I)^(-1) X'Y`.
#' This function assumes `Y_whitened` and `X_whitened` have had initial NA rows
#' (e.g., from AR pre-whitening) removed or properly handled if `na_mask` is provided.
#' If `na_mask` is not provided, any row in `Y_whitened` containing at least one NA will lead to that row (and the
#' corresponding row in `X_whitened`) being removed before model fitting.
#'
#' @export
ndx_solve_ridge <- function(Y_whitened, X_whitened, lambda_ridge, na_mask = NULL) {

  # Input validation
  if (!is.matrix(Y_whitened) || !is.numeric(Y_whitened)) {
    stop("Y_whitened must be a numeric matrix.")
  }
  if (!is.matrix(X_whitened) || !is.numeric(X_whitened)) {
    stop("X_whitened must be a numeric matrix.")
  }
  if (nrow(Y_whitened) != nrow(X_whitened)) {
    stop("Y_whitened and X_whitened must have the same number of rows (timepoints).")
  }
  if (!is.numeric(lambda_ridge) || length(lambda_ridge) != 1 || lambda_ridge < 0) {
    stop("lambda_ridge must be a single non-negative numeric value.")
  }

  n_timepoints_orig <- nrow(Y_whitened)
  n_voxels <- ncol(Y_whitened)
  n_regressors <- ncol(X_whitened)

  if (n_regressors == 0) {
    warning("X_whitened has 0 regressors. Returning empty beta matrix.")
    return(matrix(NA_real_, nrow = 0, ncol = n_voxels))
  }
  if (n_voxels == 0) {
    warning("Y_whitened has 0 voxels. Returning empty beta matrix.")
    return(matrix(NA_real_, nrow = n_regressors, ncol = 0))
  }

  # Handle NA rows from AR pre-whitening
  if (!is.null(na_mask)) {
    if (!is.logical(na_mask) || length(na_mask) != n_timepoints_orig) {
      stop("Provided na_mask must be a logical vector of length equal to nrows of Y_whitened.")
    }
    Y_clean <- Y_whitened[!na_mask, , drop = FALSE]
    X_clean <- X_whitened[!na_mask, , drop = FALSE]
  } else {
    # Default: remove rows with any NAs in Y_whitened (more robust if na_mask not passed)
    complete_y_rows <- stats::complete.cases(Y_whitened)
    if (!all(complete_y_rows)) {
        message(sprintf("Removing %d rows with NAs in Y_whitened prior to ridge regression.", sum(!complete_y_rows)))
    }
    Y_clean <- Y_whitened[complete_y_rows, , drop = FALSE]
    X_clean <- X_whitened[complete_y_rows, , drop = FALSE]
  }
  
  n_timepoints_clean <- nrow(X_clean)

  if (n_timepoints_clean == 0) {
    warning("No timepoints remaining after NA removal. Returning NA betas.")
    return(matrix(NA_real_, nrow = n_regressors, ncol = n_voxels))
  }
  if (n_timepoints_clean < n_regressors) {
    warning(sprintf("Number of timepoints after NA removal (%d) is less than number of regressors (%d). Ridge solution might be unstable or fail. Returning NA betas.", 
                    n_timepoints_clean, n_regressors))
    return(matrix(NA_real_, nrow = n_regressors, ncol = n_voxels))
  }

  # Ridge regression calculation: beta = (X'X + lambda * I)^-1 X'Y
  # More stable computation: solve((X'X + lambda*I) beta = X'Y)
  XtX <- crossprod(X_clean) # t(X_clean) %*% X_clean
  # Identity matrix of size n_regressors x n_regressors
  I <- diag(n_regressors) 
  
  # Ensure I has the same dimensions as XtX if n_regressors is 1
  if (n_regressors == 1 && !is.matrix(I)) {
    I <- matrix(I, 1, 1)
  }
  
  # LHS = (X'X + lambda * I)
  lhs <- XtX + lambda_ridge * I
  # RHS = X'Y
  XtY <- crossprod(X_clean, Y_clean) # t(X_clean) %*% Y_clean

  betas_whitened <- tryCatch({
    solve(lhs, XtY)
  }, error = function(e) {
    warning(paste("Solving ridge regression failed:", e$message, "Returning NA betas."))
    matrix(NA_real_, nrow = n_regressors, ncol = n_voxels)
  })
  
  return(betas_whitened)
}

#' Extract Task-Related Beta Coefficients
#'
#' Extracts beta coefficients corresponding to specified task regressors from the full
#' set of beta coefficients. For Sprint 1, this function primarily handles extraction.
#' The "unwhitening" aspect is a placeholder for future refinement.
#'
#' @param betas_whitened A matrix (total_regressors x voxels) of whitened beta coefficients,
#'   typically the output of `ndx_solve_ridge`.
#' @param X_whitened_colnames A character vector of column names for the whitened design matrix (`X_whitened`)
#'   that was used to estimate `betas_whitened`. This is used to identify task regressors by name.
#' @param task_regressor_names A character vector containing the names of the task regressors
#'   to be extracted.
#' @param ar_coeffs_global Optional. The global AR coefficients (vector of length `order`) that were used
#'   to whiten the design matrix `X`. If provided, a conceptual note about unwhitening can be considered.
#'   (Currently not used for actual unwhitening in Sprint 1).
#'
#' @return A matrix (num_task_regressors x voxels) of the extracted task-related beta coefficients.
#'   Row names will correspond to `task_regressor_names`.
#'   If no task regressors are found or an error occurs, returns NULL or an empty matrix with a warning.
#'
#' @details
#' Unwhitening beta coefficients is complex when different whitening strategies are applied
#' to Y and X (e.g., voxel-wise AR for Y, global AR for X). For Sprint 1, this function
#' focuses on the reliable extraction of beta coefficients based on their names.
#' A full unwhitening procedure that transforms betas back to the scale of an unwhitened model
#' (Y ~ X) may require further methodological development and is deferred.
#'
#' @export
ndx_extract_task_betas <- function(betas_whitened, X_whitened_colnames, task_regressor_names, ar_coeffs_global = NULL) {

  # Input validation
  if (!is.matrix(betas_whitened) || !is.numeric(betas_whitened)) {
    stop("betas_whitened must be a numeric matrix.")
  }
  if (nrow(betas_whitened) != length(X_whitened_colnames)) {
    stop("Number of rows in betas_whitened must match the length of X_whitened_colnames.")
  }
  if (!is.character(X_whitened_colnames)) {
    stop("X_whitened_colnames must be a character vector.")
  }
  if (!is.character(task_regressor_names) || length(task_regressor_names) == 0) {
    stop("task_regressor_names must be a non-empty character vector.")
  }

  n_total_regressors <- nrow(betas_whitened)
  n_voxels <- ncol(betas_whitened)

  if (n_total_regressors == 0) {
    warning("Input betas_whitened has 0 regressors. Returning NULL.")
    return(NULL)
  }
  
  # Match task_regressor_names to X_whitened_colnames
  # Ensure rownames of betas_whitened match X_whitened_colnames if they exist, otherwise use indices
  if (!is.null(rownames(betas_whitened)) && !identical(rownames(betas_whitened), X_whitened_colnames)) {
      # This case should ideally not happen if betas_whitened comes from a solve with X_whitened
      warning("Rownames of betas_whitened do not match X_whitened_colnames. Using X_whitened_colnames for indexing.")
  }
  
  # Find indices of task regressors
  task_indices <- match(task_regressor_names, X_whitened_colnames)
  
  if (any(is.na(task_indices))) {
    warning(sprintf("The following task regressors were not found in X_whitened_colnames: %s", 
                    paste(task_regressor_names[is.na(task_indices)], collapse=", ")))
    task_indices <- task_indices[!is.na(task_indices)] # Keep only found indices
  }

  if (length(task_indices) == 0) {
    warning("No specified task regressors were found in X_whitened_colnames. Returning NULL.")
    return(NULL)
  }
  
  extracted_betas <- betas_whitened[task_indices, , drop = FALSE]
  
  # Set rownames of extracted betas to the found task regressor names
  found_task_names <- X_whitened_colnames[task_indices]
  rownames(extracted_betas) <- found_task_names
  
  # Placeholder for unwhitening logic (Sprint 2+)
  if (!is.null(ar_coeffs_global)) {
    # message("Note: Unwhitening of betas is not implemented in Sprint 1. Betas are on the whitened scale.")
    # Conceptual: If X* = WX and Y* = WY (assume same W for simplicity for a moment)
    # Beta* from Y* = X*Beta* + e*
    # If W is invertible, Y = W^-1 Y*, X = W^-1 X*
    # How Beta* relates to Beta from Y = X Beta + e is complicated if W differs or is voxel-specific for Y.
  }
  
  return(extracted_betas)
}
</file>

<file path="R/ndx_rpca.R">
#' Perform Multi-Run Robust PCA and Extract Temporal Nuisance Components
#'
#' This function implements a multi-run RPCA strategy. It performs RPCA on each
#' run's transposed residuals (voxels x time) to obtain voxel-space principal components (Vr).
#' These Vr components are then merged across runs using Grassmann averaging to find a
#' global voxel-space nuisance basis (V_global). Finally, per-run residuals are
#' projected onto V_global to get run-specific temporal nuisance regressors (Cr),
#' which are then concatenated.
#' This approach is designed to be memory-efficient and respect fMRI geometry.
#'
#' @param Y_residuals_cat A numeric matrix of concatenated residuals from all runs
#'   (total_timepoints x voxels).
#' @param run_idx A numeric vector indicating run membership for each row (timepoint)
#'   in `Y_residuals_cat`.
#' @param k_global_target Integer, the target number of global temporal nuisance
#'   components to be returned (columns in the output matrix).
#' @param user_options A list of user-configurable options:
#'   - `k_per_run_target` (integer): Target rank for the L component in per-run RPCA. 
#'     Defaults to `k_global_target` if not specified or if larger.
#'     It's the `k` passed to `rpca::rpca` for each run.
#'   - `rpca_term_delta` (numeric): Convergence tolerance for rpca (passed as `term.delta`). Default: 1e-6.
#'   - `rpca_max_iter` (integer): Maximum iterations for rpca (passed as `max.iter`). Default: 2000.
#'   - `rpca_trace` (logical): If TRUE, rpca will print progress messages. Default: FALSE.
#'   - `rpca_mu` (numeric): Mu parameter for rpca. Default: NULL (auto by rpca package).
#'   - `rpca_lambda_auto` (logical): If TRUE (default), calculate lambda for each run as 
#'     `1/sqrt(max(dim(Er_t)))`. If FALSE, use `rpca_lambda_fixed`.
#'   - `rpca_lambda_fixed` (numeric): Fixed lambda value if `rpca_lambda_auto` is FALSE.
#'   - `rpca_merge_strategy` (character): Strategy for merging voxel-space components.
#'     Options are "concat_svd" or "iterative". Default: "concat_svd".
#' @return A matrix containing the concatenated temporal nuisance components `C_r`
#'   (total_timepoints x k_global_target). Returns NULL if errors occur or no components generated.
#' @examples
#' \dontrun{
#' # --- Simulate multi-run data ---
#' T_run <- 50; V <- 30; N_runs <- 2
#' total_T <- T_run * N_runs
#' Y_res_cat <- matrix(rnorm(total_T * V), total_T, V)
#' run_idx_vec <- rep(1:N_runs, each = T_run)
#' 
#' # Add some shared low-rank structure (voxel-space pattern, different temporal expression)
#' true_V_pattern <- matrix(rnorm(V*2), V, 2) # 2 global voxel patterns
#' for (r in 1:N_runs) {
#'   run_rows <- which(run_idx_vec == r)
#'   # Run-specific temporal modulation of these voxel patterns
#'   C_r_signal_run1 <- sin((1:T_run)/5 + r) * 3 + cos((1:T_run)/10 - r/2) * 2
#'   C_r_signal_run2 <- cos((1:T_run)/3 - r) * 2.5 + sin((1:T_run/8) + r/3) * 3
#'   Y_res_cat[run_rows, ] <- Y_res_cat[run_rows, ] + 
#'                            cbind(C_r_signal_run1, C_r_signal_run2) %*% t(true_V_pattern)
#' }
#' 
#' k_target_final <- 3
#' user_opts_mrpca <- list(
#'   k_per_run_target = 5, # Keep a bit more per run initially
#'   rpca_term_delta = 1e-4, # Relax tolerance for example speed
#'   rpca_max_iter = 50, # Reduced for example speed
#'   rpca_lambda_auto = TRUE
#' )
#' 
#' C_components <- ndx_rpca_temporal_components_multirun(
#'   Y_residuals_cat = Y_res_cat, 
#'   run_idx = run_idx_vec, 
#'   k_global_target = k_target_final, 
#'   user_options = user_opts_mrpca
#' )
#' 
#' if (!is.null(C_components)) {
#'   print(paste("Dimensions of concatenated C components:", 
#'               paste(dim(C_components), collapse="x")))
#'   # plot(C_components[,1], type='l', main="First Global RPCA Temporal Component")
#' }
#' }
#' @importFrom rpca rpca
#' @import stats
#' @export
ndx_rpca_temporal_components_multirun <- function(Y_residuals_cat, run_idx, 
                                                k_global_target, user_options = list()) {

  # --- 1. Input Validation & Options --- 
  if (!is.matrix(Y_residuals_cat) || !is.numeric(Y_residuals_cat)) {
    stop("Y_residuals_cat must be a numeric matrix (total_timepoints x voxels).")
  }
  if (!is.numeric(run_idx) || length(run_idx) != nrow(Y_residuals_cat)) {
    stop("run_idx length must match nrow(Y_residuals_cat).")
  }
  if (k_global_target < 0) {
    stop("k_global_target must be non-negative.")
  }
  if (k_global_target == 0) {
    message("k_global_target is 0, returning NULL as no components requested.")
    return(NULL)
  }

  default_opts <- list(
    k_per_run_target = k_global_target, 
    rpca_term_delta = 1e-6, 
    rpca_max_iter = 2000,
    rpca_mu = NULL, 
    rpca_lambda_auto = TRUE,
    rpca_lambda_fixed = NULL,
    rpca_trace = FALSE,
    rpca_merge_strategy = "concat_svd" # "concat_svd" or "iterative"
  )
  current_opts <- utils::modifyList(default_opts, user_options)
  
  # Ensure k_per_run_target is reasonable
  if (current_opts$k_per_run_target < k_global_target && current_opts$k_per_run_target > 0) {
      message(sprintf("k_per_run_target (%d) is less than k_global_target (%d). Will use k_per_run_target=%d for per-run RPCA.",
                      current_opts$k_per_run_target, k_global_target, current_opts$k_per_run_target))
  } else if (current_opts$k_per_run_target <= 0) {
       message(sprintf("k_per_run_target (%d) is <=0. Setting to k_global_target (%d) for per-run RPCA.",
                      current_opts$k_per_run_target, k_global_target))
      current_opts$k_per_run_target <- k_global_target
  }
  
  # Split concatenated residuals into a list of per-run matrices
  unique_runs <- sort(unique(run_idx))
  if (length(unique_runs) == 0) {
    stop("No runs found in run_idx.")
  }
  
  Y_residuals_list <- lapply(unique_runs, function(r_id) {
    Y_residuals_cat[run_idx == r_id, , drop = FALSE]
  })
  names(Y_residuals_list) <- paste0("run_", unique_runs)

  if (length(Y_residuals_list) == 0) {
      warning("Splitting Y_residuals_cat by run_idx resulted in an empty list.")
      return(NULL)
  }
  
  # --- 2. Per-Run RPCA (on E_r^T) --- 
  V_list <- list() # To store V_r (voxel-space components from each run)
  glitch_ratios_per_run <- numeric(length(Y_residuals_list))
  names(glitch_ratios_per_run) <- names(Y_residuals_list)

  message(sprintf("Starting per-run RPCA for %d runs...", length(Y_residuals_list)))
  for (r_idx in seq_along(Y_residuals_list)) {
    run_name <- names(Y_residuals_list)[r_idx]
    Er <- Y_residuals_list[[r_idx]] # Time_r x Voxels
    
    if (nrow(Er) == 0 || ncol(Er) == 0) {
        warning(sprintf("Residuals for run %s are empty (dims: %s). Skipping RPCA for this run.", 
                        run_name, paste(dim(Er), collapse="x")))
        V_list[[run_name]] <- NULL # Placeholder for potential later filtering
        glitch_ratios_per_run[run_name] <- NA
        next
    }
    
    Er_t <- t(Er) # Voxels x Time_r
    
    # Lambda for this run's RPCA
    lambda_r <- if (current_opts$rpca_lambda_auto) {
      1 / sqrt(max(dim(Er_t))) 
    } else {
      if (is.null(current_opts$rpca_lambda_fixed)) stop("rpca_lambda_fixed must be provided if rpca_lambda_auto is FALSE.")
      current_opts$rpca_lambda_fixed
    }
    
    # Prepare arguments for rpca::rpca
    # We will only pass 'mu' if current_opts$rpca_mu is not NULL,
    # allowing rpca::rpca to use its internal default and auto-tuning otherwise.
    rpca_call_args <- list(
      M = Er_t,
      lambda = lambda_r,
      term.delta = current_opts$rpca_term_delta,
      max.iter = current_opts$rpca_max_iter,
      trace = current_opts$rpca_trace
    )
    
    if (!is.null(current_opts$rpca_mu)) {
      # Only add mu to the call if it's specified by the user
      # Otherwise, rpca package will use its own default: prod(dim(A))/(4*sum(abs(A))) and may auto-tune.
      # Explicitly calculating mu like: mu_r <- prod(dim(Er_t)) / (4 * sum(abs(Er_t)))
      # and passing it seemed to cause issues in tests, possibly overriding internal tuning.
      rpca_call_args$mu <- current_opts$rpca_mu
      message(sprintf("  Run %s: Using user-specified mu = %f for rpca.", run_name, current_opts$rpca_mu))
    } else {
      # Calculate our 'default' mu for logging/messaging if needed, but don't pass it to rpca()
      # This way, we rely on rpca's internal default mu handling.
      temp_mu_for_logging <- NA
      if (sum(abs(Er_t)) > 1e-9) {
        temp_mu_for_logging <- prod(dim(Er_t)) / (4 * sum(abs(Er_t)))
      } else {
        temp_mu_for_logging <- 1.0 # Fallback for logging if Er_t is zero
      }
      message(sprintf("  Run %s: rpca_mu is NULL, rpca::rpca will use its internal default mu (approx for logging: %.2e).", 
                      run_name, temp_mu_for_logging))
    }
    
    # k for this run's RPCA (target rank of L component of Er_t)
    # Should not exceed min(dim(Er_t))
    k_this_run <- min(current_opts$k_per_run_target, min(dim(Er_t)))
    if (k_this_run <= 0) {
        warning(sprintf("Cannot perform RPCA for run %s: k_this_run (%d) is not positive after adjustment. Skipping.", run_name, k_this_run))
        V_list[[run_name]] <- NULL
        glitch_ratios_per_run[run_name] <- NA
        next
    }
    
    message(sprintf("  Processing run %s (data: %d voxels x %d TRs, target k: %d, lambda: %.2e)", 
                    run_name, nrow(Er_t), ncol(Er_t), k_this_run, lambda_r))
    
    rpca_res_r <- NULL
    tryCatch({
      rpca_res_r <- do.call(rpca, rpca_call_args)
    }, error = function(e) {
      warning(sprintf("rpca::rpca failed for run %s: %s", run_name, e$message))
      rpca_res_r <<- NULL
    })

    if (is.null(rpca_res_r) || is.null(rpca_res_r$L)) {
      warning(sprintf("Robust PCA failed to produce L for run %s (or rpca_res_r is NULL).", run_name))
      V_list[[run_name]] <- NULL
      glitch_ratios_per_run[run_name] <- NA
      next
    }
    
    # As per proposal addendum: Vr <- rp$U (where rp = rpca(Er_t, ...))
    # This was based on a generic rpca call. The rpca package might return L and S,
    # and we need to SVD L to get the voxel-space components (U of L if L is Voxels x Time_r).
    # If L_r_t = rpca_res_r$L (Voxels x Time_r), then its left singular vectors are V_r.
    L_r_t <- rpca_res_r$L # Voxels x Time_r
    
    if (is.null(L_r_t) || min(dim(L_r_t)) == 0 || sum(abs(L_r_t)) < 1e-9) {
        warning(sprintf("RPCA for run %s yielded an empty or zero L component.", run_name))
        V_list[[run_name]] <- NULL
        glitch_ratios_per_run[run_name] <- NA
        next
    }

    # Perform SVD on L_r_t to get V_r (left singular vectors of L_r_t)
    # k_this_run is the target number of components from this L_r_t
    svd_L_r_t <- NULL
    k_eff_svd_L <- min(k_this_run, nrow(L_r_t), ncol(L_r_t))
    if (k_eff_svd_L < k_this_run) {
        message(sprintf("  Run %s: Effective k for SVD of L_r_t (%d) is less than k_this_run (%d) due to matrix dimensions.", 
                        run_name, k_eff_svd_L, k_this_run))
    }
    
    tryCatch({
        # nu = k_this_run means we want up to k_this_run left singular vectors
        svd_L_r_t <- svd(L_r_t, nu = k_eff_svd_L, nv = 0) 
    }, error = function(e) {
        warning(sprintf("SVD on L_r_t for run %s failed: %s", run_name, e$message))
        svd_L_r_t <<- NULL
    })
    
    if (is.null(svd_L_r_t) || is.null(svd_L_r_t$u) || ncol(svd_L_r_t$u) == 0) {
      warning(sprintf("SVD of L_r_t for run %s yielded no U components for V_r.", run_name))
      V_list[[run_name]] <- NULL
      glitch_ratios_per_run[run_name] <- NA
      next
    }
    V_r <- svd_L_r_t$u # Voxels x (up to) k_this_run
    
    # The original proposal note Vr <- rp$U might refer to an rpca implementation where $U 
    # directly gives the left singular vectors of L if L is the primary low-rank matrix of interest.
    # With rpca::rpca, we get L and S, then SVD L.
    
    if (is.null(V_r) || ncol(V_r) == 0) {
        warning(sprintf("RPCA for run %s yielded no voxel-space components (V_r is NULL or empty).", run_name))
        V_list[[run_name]] <- NULL
        glitch_ratios_per_run[run_name] <- NA
        next
    }
    
    V_list[[run_name]] <- V_r
    
    # Glitch ratio for this run
    S_r_t <- rpca_res_r$S
    L_r_t <- rpca_res_r$L
    energy_S_r <- sum(S_r_t^2)
    energy_L_r <- sum(L_r_t^2)
    if (energy_L_r > 1e-9) {
      glitch_ratios_per_run[run_name] <- energy_S_r / energy_L_r
    } else {
      glitch_ratios_per_run[run_name] <- NA
    }
  } # End per-run RPCA loop
  
  # Filter out NULLs from V_list (runs that failed RPCA)
  V_list_valid <- Filter(Negate(is.null), V_list)
  if (length(V_list_valid) == 0) {
    warning("RPCA failed for all runs, or no components were extracted. Cannot proceed.")
    return(NULL)
  }
  message(sprintf("Successfully extracted initial voxel components (V_r) from %d runs.", length(V_list_valid)))

  # --- 3. Merge Voxel-Space Components (V_r) to get V_global --- 
  V_global <- NULL
  k_actual_global_components <- 0

  if (current_opts$rpca_merge_strategy == "iterative") {
    message("Using Iterative Grassmann Averaging for V_global...")
    V_global <- .grassmann_merge_iterative(V_list_valid, k_global_target)
    if (!is.null(V_global)) {
      k_actual_global_components <- ncol(V_global)
    } else {
      warning("Iterative Grassmann Averaging failed to produce V_global.")
      return(NULL) # Or fallback to concat_svd if desired as a robust measure?
    }
  } else if (current_opts$rpca_merge_strategy == "concat_svd") {
    message("Using Concatenate & SVD method for V_global...")
    V_all_concat_list <- Filter(function(x) !is.null(x) && ncol(x) > 0, V_list_valid)
    if (length(V_all_concat_list) == 0) {
        warning("No valid V_r components to concatenate for SVD V_global step.")
        return(NULL)
    }
    V_all_concat <- do.call(cbind, V_all_concat_list)
    
    if (is.null(V_all_concat) || ncol(V_all_concat) == 0) {
        warning("Concatenation of V_r components for SVD V_global resulted in an empty matrix.")
        return(NULL)
    }
    
    message(sprintf("Performing SVD on concatenated V_r matrix (dims: %s) to find V_global (%d components)", 
                    paste(dim(V_all_concat), collapse="x"), k_global_target))
    
    k_for_svd_V_all <- min(k_global_target, ncol(V_all_concat), nrow(V_all_concat)) 
    if (k_for_svd_V_all <= 0) {
        warning(sprintf("Cannot perform SVD on concatenated V_r: k_for_svd_V_all (%d) is not positive.", k_for_svd_V_all))
        return(NULL)
    }
    
    svd_V_all <- NULL
    tryCatch({
        svd_V_all <- svd(V_all_concat, nu = k_for_svd_V_all, nv = 0)
    }, error = function(e){
        warning(paste("SVD on concatenated V_r components for V_global failed:", e$message))
        return(NULL)
    })
    
    if(is.null(svd_V_all) || is.null(svd_V_all$u) || ncol(svd_V_all$u) == 0) {
        warning("SVD on concatenated V_r for V_global failed to produce U vectors.")
        return(NULL)
    }
    V_global <- svd_V_all$u 
    k_actual_global_components <- ncol(V_global)
    message(sprintf("  V_global (concat_svd) obtained with %d components.", k_actual_global_components))
  } else {
    stop(sprintf("Invalid rpca_merge_strategy: '%s'. Choose 'concat_svd' or 'iterative'.", current_opts$rpca_merge_strategy))
  }

  if (is.null(V_global) || k_actual_global_components == 0) {
      warning("V_global is NULL or has zero components after merging. Cannot proceed.")
      return(NULL)
  }

  # --- 4. Form Run-Specific Low-Rank Nuisance Time Courses (Cr) --- 
  C_r_list <- list()
  message("Forming run-specific temporal components C_r...")
  for (r_idx in seq_along(Y_residuals_list)) {
    run_name <- names(Y_residuals_list)[r_idx]
    Er <- Y_residuals_list[[r_idx]] 
    
    if (is.null(Er) || nrow(Er) == 0) {
        # Ensure C_r contributes zero rows but maintains correct ncol for rbind
        original_run_TRs <- ifelse(is.null(Y_residuals_list[[run_name]]), 0, nrow(Y_residuals_list[[run_name]]))
        C_r_list[[run_name]] <- matrix(0, nrow = original_run_TRs, ncol = k_actual_global_components) 
        next
    }
    
    C_r <- Er %*% V_global 
    C_r_list[[run_name]] <- C_r
  }
  
  C_components_cat <- do.call(rbind, C_r_list[paste0("run_", unique_runs)])
  
  if (is.null(C_components_cat) || nrow(C_components_cat) != nrow(Y_residuals_cat) || ncol(C_components_cat) != k_actual_global_components) {
      warning("Final concatenated C_components matrix dimensions are incorrect or matrix is NULL. Check C_r formation.")
      return(NULL)
  }
  
  # --- 5. Glitch Ratio Summary --- 
  message("Per-run Glitch Ratios (Energy_S / Energy_L from RPCA on Er_t):")
  print(glitch_ratios_per_run[!is.na(glitch_ratios_per_run)])
  message(sprintf("Mean Glitch Ratio across valid runs: %.3f", mean(glitch_ratios_per_run, na.rm=TRUE)))
  
  message(sprintf("Multi-run RPCA: Returning %d concatenated temporal components.", ncol(C_components_cat)))
  return(C_components_cat)
}

#' Iterative Grassmann Averaging of Voxel-Space Components
#'
#' Merges a list of voxel-space component matrices (V_r from each run/bag)
#' using an iterative Grassmann averaging approach to find a global V basis.
#'
#' @param V_list_valid A list of valid V_r matrices (Voxels x k_r). Each matrix should have the same number of rows (Voxels).
#' @param k_target_global Integer, the desired number of dimensions (columns) for the final V_global.
#' @return A matrix V_global (Voxels x k_target_global), or NULL if merging fails or k_target_global is 0.
#' @keywords internal
.grassmann_merge_iterative <- function(V_list_valid, k_target_global) {
  if (length(V_list_valid) == 0) {
    warning(".grassmann_merge_iterative: V_list_valid is empty.")
    return(NULL)
  }
  if (k_target_global <= 0) {
    warning(".grassmann_merge_iterative: k_target_global must be positive.")
    return(NULL)
  }

  # Initialize V_global with the first valid V_r, ensuring it has k_target_global or fewer columns
  V_global <- V_list_valid[[1]]
  if (ncol(V_global) > k_target_global) {
    V_global <- V_global[, 1:k_target_global, drop = FALSE]
  } else if (ncol(V_global) < k_target_global) {
    # This means the first run had fewer components than desired globally.
    # k_target_global might need to be adjusted, or this run might not be ideal for init.
    # For now, we proceed, the SVD later will be limited by ncol(M_proj)
    message(sprintf("Iterative merge init: First V_r has %d components, less than k_target_global %d.", ncol(V_global), k_target_global))
  }
  if (ncol(V_global) == 0) { # check if after truncation V_global is empty
      warning("Iterative merge init: V_global became empty after initial truncation/selection from first V_r.")
      return(NULL)
  }
  
  num_voxels <- nrow(V_global)

  if (length(V_list_valid) > 1) {
    for (r_idx in 2:length(V_list_valid)) {
      Vr <- V_list_valid[[r_idx]]
      if (is.null(Vr) || ncol(Vr) == 0 || nrow(Vr) != num_voxels) {
        warning(sprintf("Iterative merge: Skipping V_r for run/item %d due to NULL, 0 columns, or mismatched voxel dim (%d vs %d).", 
                        r_idx, ifelse(is.null(Vr), NA, nrow(Vr)), num_voxels))
        next
      }
      
      # Form a basis for the union of the two subspaces V_global and Vr
      # P_union will have at most rank(V_global) + rank(Vr) columns
      # Ensure V_global and Vr passed to cbind are not empty
      if (ncol(V_global) == 0) { # If V_global somehow became empty, re-initialize with current Vr
          V_global <- Vr
          if (ncol(V_global) > k_target_global) V_global <- V_global[, 1:k_target_global, drop=FALSE]
          if (ncol(V_global) == 0) { warning("Iterative merge: V_global re-init failed."); return(NULL); }
          next # Continue to next Vr if any
      }
      
      P_union_qr <- qr(cbind(V_global, Vr))
      # Check rank to avoid issues with qr.Q if matrix is all zeros or rank is tiny
      if (P_union_qr$rank == 0) {
          warning(sprintf("Iterative merge: cbind(V_global, Vr) for item %d is rank 0. Skipping merge step.", r_idx))
          next
      }
      P_union <- qr.Q(P_union_qr)
      
      if (ncol(P_union) == 0) {
           warning(sprintf("Iterative merge: P_union for item %d has 0 columns. Skipping merge step.", r_idx))
           next
      }

      # Average projection operator in the union basis
      M_proj <- t(P_union) %*% (V_global %*% t(V_global) + Vr %*% t(Vr)) %*% P_union
      
      # Number of components to extract from this merge step's SVD
      # Should be k_target_global, but not more than available from M_proj
      k_for_this_svd <- min(k_target_global, ncol(M_proj), nrow(M_proj)) 
      
      if (k_for_this_svd <= 0) {
        warning(sprintf("Iterative merge: k_for_this_svd is %d for item %d. Cannot perform SVD. Retaining previous V_global.", k_for_this_svd, r_idx))
        # V_global remains as it was before this problematic Vr
      } else {
        svd_M <- svd(M_proj, nu = k_for_this_svd, nv = 0)
        if (is.null(svd_M$u) || ncol(svd_M$u) == 0) {
            warning(sprintf("Iterative merge: SVD of M_proj for item %d yielded no U components. Retaining previous V_global.", r_idx))
        } else {
            V_global <- P_union %*% svd_M$u
        }
      }
    }
  }
  
  # Final check on V_global dimensions
  if (is.null(V_global) || ncol(V_global) == 0) {
      warning("Iterative merge: Final V_global is NULL or has 0 columns.")
      return(NULL)
  }
  
  # Ensure V_global has exactly k_target_global columns if possible, or fewer if rank was deficient
  if (ncol(V_global) > k_target_global) {
    V_global <- V_global[, 1:k_target_global, drop = FALSE]
  } else if (ncol(V_global) < k_target_global) {
    message(sprintf("Iterative merge: Final V_global has %d components, less than target %d.", ncol(V_global), k_target_global))
  }
  
  message(sprintf("Iterative Grassmann Merge: Final V_global obtained with %d components.", ncol(V_global)))
  return(V_global)
}

# Placeholder for the actual Grassmann iterative merge if needed later
# .grassmann_average_subspaces <- function(V_list, k_target) { ... }
</file>

<file path="R/ndx_spectral.R">
#' Identify Sinusoidal Nuisance Regressors from a Spectrum
#'
#' This function uses multi-taper spectral estimation to identify prominent
#' sinusoidal components in a residual time series (typically a mean residual).
#' It then generates pairs of sine and cosine regressors at the frequencies
#' of the identified spectral peaks.
#'
#' @param mean_residual_for_spectrum A numeric vector representing the time series
#'   (e.g., mean residuals across voxels) from which to estimate the spectrum.
#' @param TR Numeric, the repetition time of the fMRI data in seconds.
#' @param n_sine_candidates Integer, the maximum number of peak frequencies to
#'   convert into sine/cosine regressors. Defaults to 6.
#' @param nyquist_guard_factor Numeric, a factor (0 to 1) to limit peak searching
#'   to frequencies below this fraction of the Nyquist frequency. Helps avoid
#'   aliasing or unstable estimates near Nyquist. Defaults to 0.9.
#' @param k_tapers Integer, the number of tapers to use in `multitaper::spec.mtm`.
#'   Defaults to 5.
#' @param nw Numeric, the time-bandwidth product for `multitaper::spec.mtm`.
#'   Defaults to 3.
#'
#' @return A matrix with `2 * n_selected_peaks` columns and `length(mean_residual_for_spectrum)`
#'   rows. Each pair of columns represents sine and cosine regressors for an
#'   identified peak frequency. The attribute "freq" contains the frequencies
#'   (in Hz) of the selected peaks. Returns NULL if no peaks are found or if
#'   input is unsuitable.
#'
#' @examples
#' \dontrun{
#'   set.seed(42)
#'   TR_val <- 2.0
#'   n_timepoints <- 200
#'   time_points <- seq(0, (n_timepoints - 1) * TR_val, by = TR_val)
#'
#'   # Create a synthetic residual with a 0.05 Hz sine wave + noise
#'   freq_of_interest <- 0.05 # Hz
#'   synthetic_signal <- sin(2 * pi * freq_of_interest * time_points)
#'   noise <- rnorm(n_timepoints, sd = 0.5)
#'   mean_resid <- synthetic_signal + noise
#'
#'   U_sines <- ndx_spectral_sines(mean_resid, TR = TR_val, n_sine_candidates = 3)
#'   if (!is.null(U_sines)) {
#'     print(paste("Generated", ncol(U_sines) / 2, "sine/cosine pairs."))
#'     print("Identified frequencies (Hz):")
#'     print(attr(U_sines, "freq"))
#'     # plot(time_points, U_sines[,1], type='l', main="First Sine Regressor")
#'   }
#' }
#'
#' @importFrom multitaper spec.mtm
#' @importFrom pracma findpeaks
#' @export
ndx_spectral_sines <- function(mean_residual_for_spectrum, TR,
                               n_sine_candidates = 6,
                               nyquist_guard_factor = 0.9,
                               k_tapers = 5, nw = 3) {

  if (!is.numeric(mean_residual_for_spectrum) || length(mean_residual_for_spectrum) == 0) {
    warning("mean_residual_for_spectrum must be a non-empty numeric vector.")
    return(NULL)
  }
  if (!is.numeric(TR) || TR <= 0) {
    warning("TR must be a positive numeric value.")
    return(NULL)
  }

  # Adjust k_tapers based on nw and series length
  # Ensure k_tapers is at least 1 and respects multitaper constraints.
  # length(mean_residual_for_spectrum) - 1 is to ensure k_tapers is strictly less than N for some spec.mtm internals or typical usage.
  # 2*nw - 1 is a constraint from the multitaper theory.
  k_tapers <- min(k_tapers, 2 * nw - 1, length(mean_residual_for_spectrum) - 1)
  if (k_tapers < 1) {
    warning(sprintf("k_tapers became %d after adjustment (nw=%s, series_length=%d). Must be >= 1. Aborting spectral step.", 
                    as.integer(k_tapers), nw, length(mean_residual_for_spectrum)))
    return(NULL)
  }

  mt_res <- NULL
  tryCatch({
    mt_res <- multitaper::spec.mtm(mean_residual_for_spectrum,
                                   k       = k_tapers,
                                   nw      = nw,
                                   deltat  = TR,
                                   jackknife = FALSE,
                                   returnInternals = FALSE,
                                   plot    = FALSE)
  }, error = function(e) {
    warning(paste("multitaper::spec.mtm failed:", e$message))
    mt_res <<- NULL
  })

  if (is.null(mt_res) || is.null(mt_res$spec) || is.null(mt_res$freq) || length(mt_res$spec) == 0) {
    warning("Spectrum estimation via spec.mtm did not yield valid spec or freq.")
    return(NULL)
  }

  nyquist_freq  <- 1 / (2 * TR)
  # Ensure guard factor is within reasonable bounds
  guard_factor <- max(0, min(1, nyquist_guard_factor)) 
  
  freq_upper_bound <- guard_factor * nyquist_freq
  keep_indices <- mt_res$freq > 0 & mt_res$freq <= freq_upper_bound # Exclude DC, respect guard

  if (sum(keep_indices) == 0) {
    warning("No frequencies to search for peaks after applying guard factor and excluding DC.")
    return(NULL)
  }

  spec_to_search <- mt_res$spec[keep_indices]
  freq_to_search <- mt_res$freq[keep_indices]

  # findpeaks returns a matrix: col1=amplitude, col2=peak_index, col3=start_index, col4=end_index
  # We need indices relative to spec_to_search
  peak_info_all <- pracma::findpeaks(spec_to_search, nups = 1, ndowns = 1, sortstr = TRUE)

  if (is.null(peak_info_all) || nrow(peak_info_all) == 0) {
    message("No initial peaks found in the spectrum by pracma::findpeaks.")
    return(NULL)
  }
  
  # Peak prominence filter
  prom_thresh <- median(spec_to_search, na.rm = TRUE) + 3 * mad(spec_to_search, na.rm = TRUE)
  # Ensure threshold is a single finite number, if mad is 0 or spec_to_search is flat, this could be tricky
  if (!is.finite(prom_thresh)) {
    prom_thresh <- -Inf # Effectively disable filter if MAD is zero or issues
    warning("Prominence threshold for peak picking was not finite (e.g. MAD was zero). Filter effectively disabled.")
  }
  
  # Keep peaks with amplitude (col 1) > prom_thresh
  # peak_info_all is already sorted by amplitude (col 1) due to sortstr=TRUE
  peak_info <- peak_info_all[peak_info_all[,1] > prom_thresh, , drop = FALSE]

  if (is.null(peak_info) || nrow(peak_info) == 0) {
    message(sprintf("No significant peaks found after prominence filter (threshold: %.4g).", prom_thresh))
    return(NULL)
  }
  
  # Select top n_sine_candidates peaks based on their amplitude (peak_info already sorted by findpeaks with sortstr=TRUE)
  num_peaks_to_select <- min(n_sine_candidates, nrow(peak_info))
  selected_peak_indices_in_searched_spec <- peak_info[1:num_peaks_to_select, 2]

  # Frequencies corresponding to these selected peaks
  selected_frequencies_hz <- freq_to_search[selected_peak_indices_in_searched_spec]
  
  if (length(selected_frequencies_hz) == 0) {
    message("No peaks selected after filtering.")
    return(NULL)
  }

  omega_rad_s <- 2 * pi * selected_frequencies_hz # Convert Hz to radians/sec
  time_vector_sec <- (seq_along(mean_residual_for_spectrum) - 1) * TR # Time vector in seconds, starting at 0

  U_sin_raw <- sapply(omega_rad_s, function(w) sin(w * time_vector_sec))
  U_cos_raw <- sapply(omega_rad_s, function(w) cos(w * time_vector_sec))
  
  # Ensure matrix even if only one frequency
  if (is.vector(U_sin_raw)) U_sin_raw <- matrix(U_sin_raw, ncol = 1)
  if (is.vector(U_cos_raw)) U_cos_raw <- matrix(U_cos_raw, ncol = 1)
  
  # Normalize columns to have unit norm (for exact orthogonality)
  # center = FALSE because we don't want to de-mean sines/cosines
  # scale = sqrt(colSums(X^2)) to divide by L2 norm
  U_sin <- apply(U_sin_raw, 2, function(col) {
    norm_val <- sqrt(sum(col^2))
    if (norm_val > .Machine$double.eps) col / norm_val else col
  })
  U_cos <- apply(U_cos_raw, 2, function(col) {
    norm_val <- sqrt(sum(col^2))
    if (norm_val > .Machine$double.eps) col / norm_val else col
  })
  
  # Ensure matrix structure is preserved after apply if only one column
  if (is.vector(U_sin)) U_sin <- matrix(U_sin, ncol = 1)
  if (is.vector(U_cos)) U_cos <- matrix(U_cos, ncol = 1)

  # Ensure column names are unique if multiple frequencies are identical (should be rare with findpeaks)
  colnames(U_sin) <- paste0("sin_f", sprintf("%.4f", selected_frequencies_hz))
  colnames(U_cos) <- paste0("cos_f", sprintf("%.4f", selected_frequencies_hz))
  
  U_spectral_sines <- cbind(U_sin, U_cos)

  attr(U_spectral_sines, "freq_hz") <- selected_frequencies_hz
  attr(U_spectral_sines, "freq_rad_s") <- omega_rad_s
  
  message(sprintf("Generated %d sine/cosine pairs from %d spectral peaks.", 
                  ncol(U_spectral_sines) / 2, length(selected_frequencies_hz)))
  return(U_spectral_sines)
}
</file>

<file path="R/ndx_utils.R">
# ND-X Utility Functions
# This file will contain helper functions for:
# - Loading fMRI data (NIfTI)
# - Basic preprocessing (demeaning, detrending if not part of Pass 0)
# - Other miscellaneous utilities

#' @import Rcpp neuroim2 oro.nifti psd rsvd
#' @importFrom stats convolve
#' @importFrom oro.nifti origin reorient slice
NULL

# Placeholder for actual utility functions

#' Calculate OLS residuals using lm.fit
#'
#' @param Y Dependent variable matrix (timepoints x variables/voxels).
#' @param X Design matrix (timepoints x regressors).
#' @return Matrix of residuals (timepoints x variables/voxels).
#' @importFrom stats lm.fit
#' @keywords internal
#' @export
calculate_residuals_ols <- function(Y, X) {
  if (nrow(Y) != nrow(X)) {
    stop("Number of rows in Y and X must match for OLS.")
  }
  
  # If X has no columns (e.g. model with only intercept removed, or empty model)
  # then residuals are Y itself (or Y - mean(Y) if an intercept was implicitly fit and removed).
  # For an empty X, lm.fit might error or behave unexpectedly. Residuals are simply Y.
  if (ncol(X) == 0) {
    warning("Design matrix X has zero columns. Returning Y as residuals.")
    return(Y)
  }
  
  # Check for rank deficiency, lm.fit handles it by using a pseudo-inverse essentially
  qr_X <- qr(X)
  if (qr_X$rank < ncol(X)) {
    warning(paste("Design matrix is rank deficient. Rank =", qr_X$rank, "Columns =", ncol(X),
                  "OLS estimates will be non-unique for some regressors but residuals should be valid."))
  }

  # stats::lm.fit is efficient for multiple response variables (columns in Y)
  fit <- stats::lm.fit(X, Y)
  return(fit$residuals)
}

#' Calculate Voxel-wise R-squared
#'
#' @param Y_observed Matrix of observed data (timepoints x voxels).
#' @param Y_residuals Matrix of residuals from a model (timepoints x voxels).
#' @return A numeric vector of R-squared values, one for each voxel.
#' @importFrom matrixStats colVars
#' @keywords internal
#' @export
calculate_R2_voxelwise <- function(Y_observed, Y_residuals) {
  if (nrow(Y_observed) != nrow(Y_residuals) || ncol(Y_observed) != ncol(Y_residuals)) {
    stop("Dimensions of Y_observed and Y_residuals must match.")
  }
  
  n_obs_per_voxel <- apply(Y_observed, 2, function(x) sum(!is.na(x)))
  # TSS = Var(X) * (n-1) = Sum of (X_i - mean(X))^2
  TSS <- matrixStats::colVars(Y_observed, na.rm = TRUE) * (n_obs_per_voxel - 1)
  RSS <- colSums(Y_residuals^2, na.rm = TRUE) 
  
  R2 <- 1 - (RSS / TSS)
  R2[TSS < 1e-9] <- 0 # If TSS is effectively zero, R2 is 0 (or undefined, treat as 0 for practical purposes)
  R2[!is.finite(R2)] <- 0 
  R2[R2 < 0] <- 0 
  return(R2)
}
</file>

<file path="R/ndx_whitening.R">
#' AR(2) Pre-whitening for fMRI Data
#'
#' Estimates AR(2) model coefficients voxel-wise from provided residuals and applies
#' the whitening transformation to the fMRI data and the design matrix.
#'
#' @param Y_data A numeric matrix (timepoints x voxels) of fMRI data to be whitened.
#' @param X_design_full A numeric matrix (timepoints x regressors) representing the
#'   full design matrix to be whitened.
#' @param Y_residuals_for_AR_fit A numeric matrix (timepoints x voxels) of residuals
#'   used to estimate the AR(2) coefficients. This should typically be from a model
#'   that accounts for task effects and other known structured noise components.
#' @param order Integer, the order of the AR model. Defaults to 2 for AR(2).
#' @param global_ar_on_design Logical, if TRUE (default), a global AR model (averaged from successful
#'   voxel-wise fits) is used to whiten `X_design_full`. If FALSE, `X_design_full` is not whitened,
#'   and users should handle its whitening if necessary for downstream voxel-wise modeling.
#'
#' @return A list containing:
#'   - `Y_whitened`: The AR(order)-whitened fMRI data (timepoints x voxels).
#'   - `X_whitened`: The AR(order)-whitened design matrix (timepoints x regressors). If `global_ar_on_design` is FALSE,
#'     this will be the original `X_design_full`.
#'   - `AR_coeffs_voxelwise`: A matrix (voxels x order) of the estimated voxel-wise AR coefficients.
#'     Stable coefficients are returned; unstable ones are set to zero. The first column corresponds to phi_1, the second to phi_2, etc.
#'   - `AR_coeffs_global`: A numeric vector of length `order` representing the global AR coefficients used for
#'     whitening `X_design_full` (if `global_ar_on_design` is TRUE). NULL otherwise.
#'   - `var_innovations_voxelwise`: A numeric vector (voxels) of the estimated voxel-wise innovation variances
#'     (i.e., variance of residuals after whitening). NA for voxels where AR fit failed.
#'   - `na_mask`: A logical vector of length `n_timepoints`. TRUE for the initial `order` rows that are NA in
#'     `Y_whitened` and `X_whitened` (if applicable), FALSE otherwise.
#'
#' @details
#' The AR(order) model for a time series `y_t` is: 
#' `y_t = phi_1 * y_{t-1} + ... + phi_order * y_{t-order} + e_t`, where `e_t` is white noise.
#' The whitened value `y*_t` (i.e., the estimate of `e_t`) is `y_t - phi_1 * y_{t-1} - ... - phi_order * y_{t-order}`.
#' This transformation is applied to `Y_data` using voxel-specific coefficients. Unstable AR coefficients are set to zero (no whitening for that voxel).
#' If `global_ar_on_design` is TRUE, `X_design_full` is whitened using averaged AR coefficients (from stable fits).
#' The first `order` rows of the whitened matrices will contain NAs due to the filter initialization (`method="convolution", sides=1`).
#' The `na_mask` in the output identifies these rows.
#'
#' @import stats
#' @export
ndx_ar2_whitening <- function(Y_data, X_design_full, Y_residuals_for_AR_fit, order = 2L, global_ar_on_design = TRUE) {

  if (!is.matrix(Y_data) || !is.numeric(Y_data)) {
    stop("Y_data must be a numeric matrix.")
  }
  if (!is.matrix(X_design_full) || !is.numeric(X_design_full)) {
    stop("X_design_full must be a numeric matrix.")
  }
  if (!is.matrix(Y_residuals_for_AR_fit) || !is.numeric(Y_residuals_for_AR_fit)) {
    stop("Y_residuals_for_AR_fit must be a numeric matrix.")
  }
  if (nrow(Y_data) != nrow(X_design_full) || nrow(Y_data) != nrow(Y_residuals_for_AR_fit)) {
    stop("Y_data, X_design_full, and Y_residuals_for_AR_fit must have the same number of rows (timepoints).")
  }
  if (ncol(Y_data) != ncol(Y_residuals_for_AR_fit)) {
    stop("Y_data and Y_residuals_for_AR_fit must have the same number of columns (voxels).")
  }
  if (!is.numeric(order) || length(order) != 1 || !is.finite(order) || order < 1 || order %% 1 != 0) {
    stop("order must be a single positive integer.")
  }
  order <- as.integer(order)

  n_timepoints <- nrow(Y_data)
  n_voxels <- ncol(Y_data)

  if (n_timepoints <= order) {
    stop(sprintf("Number of timepoints (%d) must be greater than AR order (%d).", n_timepoints, order))
  }

  AR_coeffs_voxelwise <- matrix(NA_real_, nrow = n_voxels, ncol = order)
  var_innovations_voxelwise <- numeric(n_voxels)
  num_phi_zeroed <- 0 # Counter for voxels with phi set to 0 (failed fit or unstable)
  
  message(sprintf("Estimating AR(%d) coefficients for %d voxels...", order, n_voxels))
  for (v_idx in seq_len(n_voxels)) {
    voxel_residuals <- Y_residuals_for_AR_fit[, v_idx]
    ar_fit <- NULL
    current_phi <- rep(0, order) # Initialize to zero for this voxel
    current_var_pred <- NA_real_

    tryCatch({
      # Check for near-zero variance residuals before calling ar.yw
      if (stats::var(voxel_residuals, na.rm=TRUE) > .Machine$double.eps^0.5) {
        ar_fit <- stats::ar.yw(voxel_residuals, aic = FALSE, order.max = order)
      } else {
        ar_fit <- NULL # Treat as failure if variance is too low
      }
    }, error = function(e) {
      ar_fit <<- NULL 
    })

    if (!is.null(ar_fit) && length(ar_fit$ar) == order) {
      phi_candidate <- ar_fit$ar
      # Stability check
      roots <- tryCatch(polyroot(c(1, -phi_candidate)), error = function(e) NULL)
      if (!is.null(roots) && !any(is.na(roots)) && all(Mod(roots) > 1.00001)) { # Check if all roots are outside unit circle (stable)
        current_phi <- phi_candidate
        current_var_pred <- ar_fit$var.pred 
      } else {
        # Roots are on or inside unit circle (unstable), or polyroot failed. Phi remains 0.
        # message(sprintf("Voxel %d: Unstable AR(%d) coeffs (%s) or polyroot issue. Setting to 0.", v_idx, order, paste(round(phi_candidate,3),collapse=", ")))
      }
    }
    
    AR_coeffs_voxelwise[v_idx, ] <- current_phi
    var_innovations_voxelwise[v_idx] <- current_var_pred
    if (all(current_phi == 0)) {
        num_phi_zeroed <- num_phi_zeroed + 1
    }
    
    if (v_idx %% round(n_voxels/10) == 0 && n_voxels > 10) {
        message(sprintf("  ...processed %d/%d voxels (%.0f%%)", v_idx, n_voxels, (v_idx/n_voxels)*100))
    }
  }
  message("AR coefficient estimation complete.")

  # Report on initially NA coefficients (which are now 0 if stability check also failed or fit was null)
  # num_na_initial <- sum(is.na(var_innovations_voxelwise)) # More direct count of actual fit failures before stability
  # if (num_na_initial > 0) {
  #     message(sprintf("AR fitting initially failed for %d/%d voxels (e.g., due to low variance).", num_na_initial, n_voxels))
  # }
  
  if (num_phi_zeroed > 0) {
      message(sprintf("%d/%d voxels had AR coefficients set to zero (due to fit failure or instability). These will not be whitened.", num_phi_zeroed, n_voxels))
  }
  
  if (n_voxels > 0 && (num_phi_zeroed / n_voxels) > 0.3) {
      warning(sprintf("More than 30%% (%d/%d) of voxels had AR coefficients set to zero. Consider checking input Y_residuals_for_AR_fit.", num_phi_zeroed, n_voxels))
  }

  message("Applying voxel-specific AR filter to Y_data...")
  Y_whitened <- .apply_ar_filter_voxelwise(Y_data, AR_coeffs_voxelwise, order)
  message("Y_data whitening complete.")

  AR_coeffs_global <- NULL
  if (global_ar_on_design) {
    message("Calculating global AR coefficients for X_design_full...")
    valid_coeffs_for_global_avg <- AR_coeffs_voxelwise[rowSums(AR_coeffs_voxelwise != 0) > 0 & !is.na(var_innovations_voxelwise), , drop = FALSE]

    if (nrow(valid_coeffs_for_global_avg) > 0) {
      AR_coeffs_global <- colMeans(valid_coeffs_for_global_avg, na.rm = TRUE)
      if(any(is.na(AR_coeffs_global))) {
          warning("Global AR coefficients for design matrix contained NAs after averaging. Design matrix will not be whitened.")
          X_whitened <- X_design_full
          AR_coeffs_global <- NULL
      } else {
          message(sprintf("Applying global AR filter (coeffs: %s) to X_design_full...", paste(round(AR_coeffs_global,3), collapse=", ")))
          X_whitened <- .apply_ar_filter_to_matrix_cols(X_design_full, AR_coeffs_global, order)
          message("X_design_full whitening complete.")
      }
    } else {
      warning("No valid voxel-wise AR coefficients available to compute global AR model for design matrix. Design matrix will not be whitened.")
      X_whitened <- X_design_full
    }
  } else {
    message("Skipping whitening of X_design_full as per global_ar_on_design = FALSE.")
    X_whitened <- X_design_full
  }
  
  na_mask <- seq_len(n_timepoints) <= order
  
  return(list(
    Y_whitened = Y_whitened,
    X_whitened = X_whitened,
    AR_coeffs_voxelwise = AR_coeffs_voxelwise,
    AR_coeffs_global = AR_coeffs_global,
    var_innovations_voxelwise = var_innovations_voxelwise,
    na_mask = na_mask
  ))
}

.apply_ar_filter_to_matrix_cols <- function(M, ar_parameters_single_row, ar_order) {
  if (!is.numeric(M) || !is.matrix(M)) stop(".apply_ar_filter_to_matrix_cols: M must be a numeric matrix.")
  if (ar_order < 1) return(M)
  
  if (is.null(ar_parameters_single_row) || length(ar_parameters_single_row) != ar_order || 
      all(is.na(ar_parameters_single_row)) || all(ar_parameters_single_row == 0)){
      return(M)
  }
  
  filter_coeffs <- c(1, -as.numeric(ar_parameters_single_row))
  n_timepoints_m <- nrow(M)
  
  if (n_timepoints_m <= ar_order) {
    warning(sprintf("Matrix to be filtered has %d rows, AR order is %d. Returning NA matrix.", n_timepoints_m, ar_order))
    return(matrix(NA_real_, nrow = n_timepoints_m, ncol = ncol(M)))
  }
  
  M_whitened <- apply(M, 2, function(col_data) {
    stats::filter(col_data, filter = filter_coeffs, method = "convolution", sides = 1)
  })
  if (is.vector(M_whitened)) {
      M_whitened <- matrix(M_whitened, ncol=1)
  }
  return(M_whitened)
}

.apply_ar_filter_voxelwise <- function(Y_data_matrix, voxel_ar_coeffs_matrix, ar_order) {
  if (!is.numeric(Y_data_matrix) || !is.matrix(Y_data_matrix)) stop(".apply_ar_filter_voxelwise: Y_data_matrix must be a numeric matrix.")
  if (ar_order < 1) return(Y_data_matrix)
  
  n_voxels <- ncol(Y_data_matrix)
  n_timepoints_y <- nrow(Y_data_matrix)
  Y_whitened_matrix <- matrix(NA_real_, nrow = n_timepoints_y, ncol = n_voxels)
  
  if (n_timepoints_y <= ar_order) {
      warning(sprintf("Y_data has %d rows, AR order is %d. Returning NA matrix.", n_timepoints_y, ar_order))
      return(Y_whitened_matrix)
  }

  for (v_idx in seq_len(n_voxels)) {
    voxel_coeffs_row_vec <- voxel_ar_coeffs_matrix[v_idx, ]
    if (all(is.na(voxel_coeffs_row_vec)) || all(voxel_coeffs_row_vec == 0)) {
      Y_whitened_matrix[, v_idx] <- Y_data_matrix[, v_idx]
      next
    }
    filter_coeffs_for_voxel <- c(1, -as.numeric(voxel_coeffs_row_vec))
    Y_whitened_matrix[, v_idx] <- stats::filter(Y_data_matrix[, v_idx],
                                              filter = filter_coeffs_for_voxel,
                                              method = "convolution", sides = 1)
  }
  return(Y_whitened_matrix)
}
</file>

<file path="R/ndx_workflow.R">
#' Run a Single Pass of the ND-X Sprint 1 Denoising Workflow
#'
#' This function orchestrates the core modules of the ND-X pipeline developed in Sprint 1.
#' It performs initial residual generation, FIR HRF estimation, nuisance component
#' identification (RPCA and Spectral), AR(2) pre-whitening, and ridge regression.
#'
#' @param Y_fmri A numeric matrix of fMRI data (total_timepoints x voxels), concatenated across runs if applicable.
#' @param events A data frame describing experimental events. Must contain columns compatible
#'   with `ndx_initial_glm` and `ndx_estimate_initial_hrfs` (e.g., `onsets`, `durations`, `condition`, `blockids`).
#' @param motion_params A numeric matrix of motion parameters (total_timepoints x num_motion_regressors).
#' @param run_idx A numeric vector indicating run membership for each row (timepoint)
#'   in `Y_fmri`, `motion_params`, etc.
#' @param TR Numeric, repetition time in seconds.
#' @param spike_TR_mask Optional. A logical vector of length `nrow(Y_fmri)` where TRUE
#'   indicates a TR to be excluded from HRF estimation and potentially other steps.
#'   If NULL, all TRs are considered valid initially.
#' @param user_options A list containing various sub-lists of user-configurable options for each module:
#'   - `opts_pass0`: List of options for `ndx_initial_glm` (e.g., `poly_degree`). This is also used by `ndx_build_design_matrix` for `poly_degree_val`.
#'   - `opts_hrf`: List of options for `ndx_estimate_initial_hrfs` (e.g., `hrf_fir_taps`, `good_voxel_R2_threshold`, `lambda1_grid`, `lambda2_grid`, `cv_folds`).
#'   - `opts_rpca`: List of options for `ndx_rpca_temporal_components_multirun` (e.g., `k_per_run_target`, `rpca_lambda_auto`).
#'   - `opts_spectral`: List of options for `ndx_spectral_sines` (e.g., `n_sine_candidates`, `nyquist_guard_factor`, `k_tapers`, `nw`).
#'   - `opts_whitening`: List of options for `ndx_ar2_whitening` (e.g., `order`, `global_ar_on_design`, `max_ar_failures_prop`).
#'   - `opts_ridge`: List of options including `lambda_ridge` for `ndx_solve_ridge`.
#'   - `task_regressor_names_for_extraction` (character vector): Names of task regressors to extract betas for.
#' @param verbose Logical, if TRUE, print progress messages. Default: TRUE.
#'
#' @return A list containing key outputs from the workflow, such as:
#'   - `final_task_betas`: Extracted task betas after ridge regression.
#'   - `Y_residuals_whitened`: Residuals after whitening and ridge regression.
#'   - `Y_residuals_pass0`: Residuals from the initial GLM fit.
#'   - `ar_coeffs_voxelwise`: Voxelwise AR(2) coefficients.
#'   - `rpca_components`: Temporal components from RPCA.
#'   - `spectral_sines`: Sine/cosine components from spectral analysis.
#'   - `estimated_hrfs`: Table of estimated FIR HRFs.
#'   - `pass0_vars`: Baseline variance from initial GLM for DES calculation.
#'   - `na_mask_whitening`: Mask of NAs introduced by AR(2) whitening filter.
#'   - `X_full_design`: The constructed design matrix.
#' @importFrom fmrireg event_model design_matrix sampling_frame
#' @importFrom tibble is_tibble
#' @export
ndx_run_sprint1 <- function(Y_fmri,
                              events,
                              motion_params,
                              run_idx,
                              TR,
                              spike_TR_mask = NULL,
                              user_options = list(),
                              verbose = TRUE) {

  if (verbose) message("Starting ND-X Sprint 1 Workflow...")

  # --- 0. Validate inputs and merge default user_options --- 
  # (To be implemented: validate inputs, set up default options for each sub-module if not provided)
  
  # Placeholder for options - real implementation would merge with defaults
  opts_pass0       <- user_options$opts_pass0 %||% list()
  opts_hrf         <- user_options$opts_hrf %||% list()
  opts_rpca        <- user_options$opts_rpca %||% list()
  opts_spectral    <- user_options$opts_spectral %||% list()
  opts_whitening   <- user_options$opts_whitening %||% list()
  opts_ridge       <- user_options$opts_ridge %||% list()
  task_regressor_names <- user_options$task_regressor_names_for_extraction %||% character(0)
  
  # Initialize a list to store results
  results <- list()

  # --- 1. Initial GLM: Residual Generation (NDX-2) ---
  if (verbose) message("Step 1: Running Initial GLM for residual generation...")
  initial_glm_output <- ndx_initial_glm(
    Y_fmri = Y_fmri,
    events = events,
    motion_params = motion_params,
    run_idx = run_idx,
    TR = TR
  )
  results$Y_residuals_pass0 <- initial_glm_output$Y_residuals_current
  results$pass0_vars <- initial_glm_output$VAR_BASELINE_FOR_DES
  
  # --- 2. HRF Estimation (NDX-3) ---
  if (verbose) message("Step 2: Estimating initial FIR HRFs...")
  estimated_hrfs <- ndx_estimate_initial_hrfs(
    Y_fmri = Y_fmri, 
    pass0_residuals = initial_glm_output$Y_residuals_current, 
    events = events, 
    run_idx = run_idx, 
    TR = TR, 
    spike_TR_mask = spike_TR_mask, 
    user_options = opts_hrf
  )
  results$estimated_hrfs <- estimated_hrfs

  # --- 3. RPCA Nuisance Components (NDX-4) ---
  if (verbose) message("Step 3: Identifying RPCA nuisance components...")
  k_rpca_global <- opts_rpca$k_global_target %||% 5 # Example default
  rpca_components <- ndx_rpca_temporal_components_multirun(
    Y_residuals_cat = initial_glm_output$Y_residuals_current,
    run_idx = run_idx,
    k_global_target = k_rpca_global,
    user_options = opts_rpca
  )
  results$rpca_components <- rpca_components

  # --- 4. Spectral Nuisance Components (NDX-5) ---
  if (verbose) message("Step 4: Identifying spectral nuisance components...")
  if (!is.null(initial_glm_output$Y_residuals_current) && ncol(initial_glm_output$Y_residuals_current) > 0) {
    mean_residual_for_spectrum <- rowMeans(initial_glm_output$Y_residuals_current, na.rm = TRUE)
    spectral_sines <- ndx_spectral_sines(
      mean_residual_for_spectrum = mean_residual_for_spectrum,
      TR = TR,
      n_sine_candidates = opts_spectral$n_sine_candidates %||% 10,
      nyquist_guard_factor = opts_spectral$nyquist_guard_factor %||% 0.9,
      k_tapers = opts_spectral$k_tapers %||% 5,
      nw = opts_spectral$nw %||% 3
    )
    results$spectral_sines <- spectral_sines
  } else {
    if (verbose) message("  Skipping spectral analysis due to no Pass0 residuals or no voxels.")
    results$spectral_sines <- NULL
  }

  # --- 5. Construct Full Design Matrix for Whitening/Ridge --- 
  if (verbose) message("Step 5: Constructing full design matrix...")
  
  X_full_design <- ndx_build_design_matrix(
    estimated_hrfs = results$estimated_hrfs,
    events = events,
    motion_params = motion_params,
    rpca_components = results$rpca_components,
    spectral_sines = results$spectral_sines,
    run_idx = run_idx,
    TR = TR,
    poly_degree_val = opts_pass0$poly_degree, # poly_degree comes from opts_pass0
    verbose = verbose
  )
  results$X_full_design <- X_full_design
  
  # --- 6. AR(2) Pre-whitening (NDX-6) ---
  if (verbose) message("Step 6: Performing AR(2) pre-whitening...")
  if (!is.null(X_full_design)) {
    whitening_output <- ndx_ar2_whitening(
      Y_data = Y_fmri,
      X_design_full = X_full_design,
      Y_residuals_for_AR_fit = initial_glm_output$Y_residuals_current,
      order = opts_whitening$order %||% 2L,
      global_ar_on_design = opts_whitening$global_ar_on_design %||% TRUE
      # Removed deprecated max_ar_failures_prop
    )
    results$Y_whitened <- whitening_output$Y_whitened
    results$X_whitened <- whitening_output$X_whitened
    results$ar_coeffs_voxelwise <- whitening_output$ar_coeffs_voxelwise
    results$na_mask_whitening <- whitening_output$na_mask
  } else {
    if (verbose) message("  Skipping AR(2) whitening as X_full_design is NULL.")
    results$Y_whitened <- Y_fmri # Pass through unwhitened for ridge if X_full_design was missing
    results$X_whitened <- X_full_design # Will be NULL
    results$ar_coeffs_voxelwise <- NULL
    results$na_mask_whitening <- rep(FALSE, nrow(Y_fmri))
  }

  # --- 7. Ridge Regression (NDX-7) ---
  if (verbose) message("Step 7: Performing Ridge Regression...")
  if (!is.null(results$X_whitened) && !is.null(results$Y_whitened)) {
    ridge_betas_whitened <- ndx_solve_ridge(
      Y_whitened = results$Y_whitened,
      X_whitened = results$X_whitened,
      lambda_ridge = opts_ridge$lambda_ridge %||% 1.0, # Example default
      na_mask = results$na_mask_whitening
    )
    results$ridge_betas_whitened <- ridge_betas_whitened

    # Extract task betas
    if (!is.null(ridge_betas_whitened) && length(task_regressor_names) > 0) {
      final_task_betas <- ndx_extract_task_betas(
        betas_whitened = ridge_betas_whitened,
        X_whitened_colnames = colnames(results$X_whitened), 
        task_regressor_names = task_regressor_names,
        ar_coeffs_global = NULL # Unwhitening deferred beyond Sprint 1
      )
      results$final_task_betas <- final_task_betas
    } else {
      results$final_task_betas <- NULL
    }
    
    # Placeholder for whitened residuals after ridge
    # Y_residuals_whitened = Y_whitened - X_whitened %*% ridge_betas_whitened
    # results$Y_residuals_whitened <- Y_residuals_whitened 

  } else {
    if (verbose) message("  Skipping Ridge Regression due to missing whitened data/design.")
    results$ridge_betas_whitened <- NULL
    results$final_task_betas <- NULL
  }
  
  # --- 8. Finalize and Return --- 
  if (verbose) message("ND-X Sprint 1 Workflow finished.")
  return(results)
}

# Helper for default options, similar to base R's %||%
`%||%` <- function(a, b) {
  if (is.null(a)) b else a
}
</file>

<file path="tests/testthat/test-design_matrix.R">
context("ndx_build_design_matrix - Design Matrix Construction")

# --- Helper function to create mock estimated_hrfs tibble ---
create_mock_hrfs <- function(conditions = c("TaskA", "TaskB"), taps_per_hrf = 6, TR = 2.0) {
  if (length(conditions) == 0) return(NULL)
  hrf_list <- lapply(conditions, function(cond) {
    list(
      condition = cond,
      hrf_estimate = list(stats::rnorm(taps_per_hrf)), # list-column
      taps = list(1:taps_per_hrf) # list-column, or could be just num_taps
    )
  })
  # Convert list of lists to a tibble more carefully
  # Each element of hrf_list is a row
  df_hrfs <- do.call(rbind, lapply(hrf_list, function(row_list) data.frame(condition=row_list$condition)))
  df_hrfs$hrf_estimate <- lapply(hrf_list, function(row_list) row_list$hrf_estimate[[1]]) # unlist the inner list for hrf_estimate
  df_hrfs$taps <- lapply(hrf_list, function(row_list) row_list$taps[[1]]) # unlist the inner list for taps
  return(tibble::as_tibble(df_hrfs))
}

# --- Basic Test Data Setup ---
TR_test_dm <- 2.0
n_time_per_run_dm <- 30 
n_runs_dm <- 2
total_timepoints_dm <- n_time_per_run_dm * n_runs_dm
run_idx_dm <- rep(1:n_runs_dm, each = n_time_per_run_dm)

events_dm <- data.frame(
  onsets = c(5, 15, 5, 20) * TR_test_dm, # in seconds
  durations = rep(2 * TR_test_dm, 4),
  condition = factor(c("TaskA", "TaskB", "TaskA", "TaskB")),
  blockids = c(1, 1, 2, 2) # ensure blockids align with runs
)

motion_params_dm <- matrix(stats::rnorm(total_timepoints_dm * 3), ncol = 3)
colnames(motion_params_dm) <- paste0("mot", 1:3)

rpca_comps_dm <- matrix(stats::rnorm(total_timepoints_dm * 2), ncol = 2)
# colnames for rpca will be auto-generated by ndx_build_design_matrix

spectral_sines_dm <- matrix(stats::rnorm(total_timepoints_dm * 4), ncol = 4)
colnames(spectral_sines_dm) <- paste0(rep(c("s1", "s2"), each=2), c("_sin", "_cos"))

estimated_hrfs_dm <- create_mock_hrfs(conditions = c("TaskA", "TaskB"), taps_per_hrf = 8, TR = TR_test_dm)

# --- Test Cases ---
test_that("ndx_build_design_matrix runs with all components present (multi-run)", {
  X_full <- NULL
  expect_no_error({
    X_full <- ndx_build_design_matrix(
      estimated_hrfs = estimated_hrfs_dm,
      events = events_dm,
      motion_params = motion_params_dm,
      rpca_components = rpca_comps_dm,
      spectral_sines = spectral_sines_dm,
      run_idx = run_idx_dm,
      TR = TR_test_dm,
      poly_degree_val = 1, # poly0 and poly1
      verbose = TRUE
    )
  })
  
  expect_true(is.matrix(X_full))
  expect_equal(nrow(X_full), total_timepoints_dm)
  
  # Expected columns: 
  # TaskA (1), TaskB (1) = 2
  # Motion (3) = 3
  # RPCA (2) = 2 
  # Spectral (4) = 4
  # Poly (poly0, poly1) = 2
  # Run Intercepts (for run2, since poly0 is overall intercept and 2 runs) = 1 
  # Total = 2 + 3 + 2 + 4 + 2 + 1 = 14
  expect_equal(ncol(X_full), 14)
  
  expected_colnames_structure <- c(
    "task_TaskA", "task_TaskB", 
    paste0("mot", 1:3), 
    paste0("rpca_comp_", 1:2), 
    colnames(spectral_sines_dm), 
    "poly0", "poly1", 
    "run_intercept_2"
  )
  expect_named(X_full, expected_colnames_structure, ignore.order = FALSE) # Order should be predictable from cbind order
})

test_that("ndx_build_design_matrix handles NULL/empty optional components", {
  X_no_nuisance <- NULL
  expect_no_error({
    X_no_nuisance <- ndx_build_design_matrix(
      estimated_hrfs = estimated_hrfs_dm,
      events = events_dm,
      motion_params = NULL,
      rpca_components = NULL,
      spectral_sines = NULL,
      run_idx = run_idx_dm,
      TR = TR_test_dm,
      poly_degree_val = 0, # only poly0 (overall intercept)
      verbose = FALSE
    )
  })
  expect_true(is.matrix(X_no_nuisance))
  expect_equal(nrow(X_no_nuisance), total_timepoints_dm)
  # Task (2) + Poly0 (1) + Run Intercept (1, for run2, as poly0 is global) = 4 columns
  # Run intercept for run2 is dropped if poly0 is the *only* baseline and meant to be global for single run
  # No, poly_degree = 0 + runwise intercept. poly0 is global. run_intercept_2 is added. Total: 2 task + 1 poly0 + 1 run_intercept_2 = 4
  expect_equal(ncol(X_no_nuisance), 4)
  expected_colnames_no_nuisance <- c("task_TaskA", "task_TaskB", "poly0", "run_intercept_2")
  expect_named(X_no_nuisance, expected_colnames_no_nuisance, ignore.order = FALSE)
  
  # Test with 0-column matrices for optional components
  X_zero_col_nuisance <- NULL
  expect_no_error({
    X_zero_col_nuisance <- ndx_build_design_matrix(
      estimated_hrfs = estimated_hrfs_dm,
      events = events_dm,
      motion_params = matrix(numeric(0), nrow=total_timepoints_dm, ncol=0),
      rpca_components = matrix(numeric(0), nrow=total_timepoints_dm, ncol=0),
      spectral_sines = matrix(numeric(0), nrow=total_timepoints_dm, ncol=0),
      run_idx = run_idx_dm,
      TR = TR_test_dm,
      poly_degree_val = -1, # No polynomials, only run intercepts if multi-run
      verbose = FALSE
    )
  })
  expect_true(is.matrix(X_zero_col_nuisance))
  # Task (2) + Run Intercepts (2, for run1 and run2, as no poly0) = 4 columns
  expect_equal(ncol(X_zero_col_nuisance), 4)
  expected_colnames_zero_col_nuisance <- c("task_TaskA", "task_TaskB", "run_intercept_1", "run_intercept_2")
  expect_named(X_zero_col_nuisance, expected_colnames_zero_col_nuisance, ignore.order = FALSE)
})

test_that("ndx_build_design_matrix handles single run correctly", {
  run_idx_single_dm <- rep(1, n_time_per_run_dm)
  events_single_dm <- events_dm[events_dm$blockids == 1,]
  motion_single_dm <- motion_params_dm[1:n_time_per_run_dm, , drop=FALSE]
  rpca_single_dm <- rpca_comps_dm[1:n_time_per_run_dm, , drop=FALSE]
  spectral_single_dm <- spectral_sines_dm[1:n_time_per_run_dm, , drop=FALSE]
  
  X_single_run <- NULL
  expect_no_error({
    X_single_run <- ndx_build_design_matrix(
      estimated_hrfs = estimated_hrfs_dm, # HRFs estimated globally, applied to single run events
      events = events_single_dm,
      motion_params = motion_single_dm,
      rpca_components = rpca_single_dm,
      spectral_sines = spectral_single_dm,
      run_idx = run_idx_single_dm,
      TR = TR_test_dm,
      poly_degree_val = 1, # poly0 and poly1
      verbose = FALSE
    )
  })
  expect_true(is.matrix(X_single_run))
  expect_equal(nrow(X_single_run), n_time_per_run_dm)
  # Task (2) + Motion (3) + RPCA (2) + Spectral (4) + Poly (2, poly0, poly1) = 13. No run-specific intercept as only 1 run and poly0 exists.
  expect_equal(ncol(X_single_run), 13)
  
  # Single run, no polynomials -> should add an overall intercept
  X_single_run_no_poly <- NULL
  expect_no_error({
    X_single_run_no_poly <- ndx_build_design_matrix(
      estimated_hrfs = estimated_hrfs_dm,
      events = events_single_dm,
      motion_params = motion_single_dm,
      rpca_components = NULL,
      spectral_sines = NULL,
      run_idx = run_idx_single_dm,
      TR = TR_test_dm,
      poly_degree_val = -1, # No polys
      verbose = FALSE
    )
  })
  expect_true(is.matrix(X_single_run_no_poly))
  # Task (2) + Motion (3) + Intercept (1) = 6
  expect_equal(ncol(X_single_run_no_poly), 6)
  expect_true("intercept" %in% colnames(X_single_run_no_poly))
})

test_that("ndx_build_design_matrix handles no task HRFs", {
  X_no_task <- NULL
  expect_no_error({
    X_no_task <- ndx_build_design_matrix(
      estimated_hrfs = NULL,
      events = events_dm,
      motion_params = motion_params_dm,
      rpca_components = rpca_comps_dm,
      spectral_sines = spectral_sines_dm,
      run_idx = run_idx_dm,
      TR = TR_test_dm,
      poly_degree_val = 1,
      verbose = FALSE
    )
  })
  expect_true(is.matrix(X_no_task))
  # Expected: Motion (3) + RPCA (2) + Spectral (4) + Poly (2) + Run Intercept (1) = 12
  expect_equal(ncol(X_no_task), 12)
  expect_false(any(startsWith(colnames(X_no_task), "task_")))
  
  # Empty tibble for HRFs
  empty_hrfs <- tibble::tibble(condition=character(), hrf_estimate=list(), taps=list())
  expect_no_error({
    X_no_task_empty_hrf <- ndx_build_design_matrix(
      estimated_hrfs = empty_hrfs,
      events = events_dm,
      motion_params = motion_params_dm,
      rpca_components = rpca_comps_dm,
      spectral_sines = spectral_sines_dm,
      run_idx = run_idx_dm,
      TR = TR_test_dm,
      poly_degree_val = 1,
      verbose = FALSE
    )
  })
  expect_equal(ncol(X_no_task_empty_hrf), 12)
})

test_that("ndx_build_design_matrix generates correct polynomial degrees and intercepts", {
  # poly_degree_val = 0 (intercept only from poly)
  X_poly0 <- ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm, motion_params=NULL, rpca_components=NULL, spectral_sines=NULL, 
                                   run_idx=run_idx_dm, TR=TR_test_dm, poly_degree_val=0, verbose=FALSE)
  # poly0 (1) + run_intercept_2 (1) = 2 columns
  expect_equal(ncol(X_poly0), 2)
  expect_true(all(c("poly0", "run_intercept_2") %in% colnames(X_poly0)))
  
  # poly_degree_val = -1 (no poly, run intercepts only if multi-run)
  X_no_poly_multirun <- ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm, motion_params=NULL, rpca_components=NULL, spectral_sines=NULL, 
                                             run_idx=run_idx_dm, TR=TR_test_dm, poly_degree_val= -1, verbose=FALSE)
  # run_intercept_1, run_intercept_2 = 2 columns
  expect_equal(ncol(X_no_poly_multirun), 2)
  expect_true(all(c("run_intercept_1", "run_intercept_2") %in% colnames(X_no_poly_multirun)))
  
  # poly_degree_val = -1 (no poly, single run -> should add overall intercept)
  run_idx_single_dm_for_poly <- rep(1, n_time_per_run_dm)
  X_no_poly_singlerun <- ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm[events_dm$blockids==1,], motion_params=NULL, rpca_components=NULL, spectral_sines=NULL, 
                                                run_idx=run_idx_single_dm_for_poly, TR=TR_test_dm, poly_degree_val= -1, verbose=FALSE)
  # intercept (1) = 1 column
  expect_equal(ncol(X_no_poly_singlerun), 1)
  expect_true("intercept" %in% colnames(X_no_poly_singlerun))
})

test_that("ndx_build_design_matrix errors on row mismatches for inputs", {
  bad_motion <- motion_params_dm[1:(total_timepoints_dm-1), , drop=FALSE]
  expect_error(ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm, motion_params=bad_motion, rpca_components=NULL, spectral_sines=NULL, 
                                      run_idx=run_idx_dm, TR=TR_test_dm, poly_degree_val=0, verbose=FALSE),
               "Row mismatch: motion_params")
})

test_that("ndx_build_design_matrix returns NULL if no regressors are formed", {
  run_idx_single_dm <- rep(1, n_time_per_run_dm)
  X_null <- ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm, motion_params=NULL, rpca_components=NULL, spectral_sines=NULL, 
                                   run_idx=run_idx_single_dm, TR=TR_test_dm, poly_degree_val= -1, verbose=FALSE)
  # With poly_degree_val = -1 and single run, it should produce an intercept column. 
  # To get NULL, we need a scenario where even that fails or is not applicable.
  # If events is such that no task regressors are made, and other components are NULL, and poly_degree is <0 for single run,
  # it will make an intercept. So, this test condition needs rethinking to truly get NULL.
  # The function is designed to *at least* add an intercept for a single run if no polys specified.
  # It returns NULL if X_full_design ends up NULL after filtering empty components OR if total_timepoints_from_run_idx leads to 0-row matrix (from bad run_idx).

  # Test with run_idx implying 0 timepoints (should error earlier, but good to ensure robustness)
  expect_error(ndx_build_design_matrix(estimated_hrfs=NULL, events=events_dm, motion_params=NULL, rpca_components=NULL, spectral_sines=NULL, 
                                     run_idx=integer(0), TR=2, poly_degree_val=0, verbose=FALSE),
               "run_idx implies one or more runs have zero or negative length" # or similar from sampling_frame
               )

  # If all inputs that could generate columns are NULL or empty, and poly_degree < 0 for single run, result is intercept.
  # To get NULL from `do.call(cbind, all_regressors_filtered)`: all_regressors_filtered must be empty.
  # This means no task, no nuisance, and baseline logic also results in nothing (e.g. poly_degree=-1 and multi-run but run_intercepts fail for some reason - unlikely)
  # The only way for `all_regressors_filtered` to be empty is if no task, no nuisance, and the baseline logic also results in nothing.
  # This is hard to achieve if poly_degree_val isn't <0 or if it's a single run (where an intercept is forced if no polys).

  # Let's make events that don't match any HRF condition (if HRFs are provided)
  hrf_no_match <- create_mock_hrfs(conditions = c("NonExistent"), taps_per_hrf = 8, TR = TR_test_dm)
  X_no_task_match <- ndx_build_design_matrix(
                         estimated_hrfs = hrf_no_match, 
                         events = events_dm, # events_dm has TaskA, TaskB
                         motion_params = NULL, rpca_components = NULL, spectral_sines = NULL,
                         run_idx = run_idx_single_dm, TR = TR_test_dm, poly_degree_val = -1, verbose = FALSE)
  # Should still have 'intercept' for single run, poly=-1. So ncol=1.
  expect_equal(ncol(X_no_task_match), 1)
  expect_true("intercept" %in% colnames(X_no_task_match))
  
  # The most direct way to get NULL is if all inputs are truly empty and poly_degree_val < 0 for multi-run (no forced intercept)
  X_truly_empty <- ndx_build_design_matrix(
                         estimated_hrfs = NULL, 
                         events = events_dm[0,], # Empty events table
                         motion_params = NULL, rpca_components = NULL, spectral_sines = NULL,
                         run_idx = run_idx_dm, # multi-run
                         TR = TR_test_dm, poly_degree_val = -1, verbose = FALSE)
  # This should result in run_intercept_1 and run_intercept_2 for multi-run, poly_degree=-1
  expect_equal(ncol(X_truly_empty), 2)
  expect_true(all(c("run_intercept_1", "run_intercept_2") %in% colnames(X_truly_empty)))
  # Conclusion: It's difficult to make this function return NULL design matrix if run_idx is valid,
  # as it tries hard to at least include intercepts. It primarily returns NULL if a critical error occurs (like row mismatch after formation).
})

# Test specific logic for FIR basis generation if complex conditions arise
test_that("FIR basis generation in ndx_build_design_matrix handles edge cases", {
  run_idx_single_dm <- rep(1, n_time_per_run_dm)
  # Case 1: HRF estimate has zero length
  hrf_zero_len <- create_mock_hrfs(conditions = c("TaskA"), taps_per_hrf = 0, TR = TR_test_dm)
  # This should be caught by: if (is.null(hrf_coeffs) || length(hrf_coeffs) == 0)
  X_fir_zero <- ndx_build_design_matrix(estimated_hrfs = hrf_zero_len, events = events_dm, motion_params = NULL, rpca_components = NULL, 
                                      spectral_sines = NULL, run_idx = run_idx_single_dm, TR = TR_test_dm, poly_degree_val = -1, verbose = FALSE)
  expect_false(any(startsWith(colnames(X_fir_zero), "task_")))
  expect_equal(ncol(X_fir_zero), 1) # Should be just the intercept

  # Case 2: No events for a condition listed in HRF table
  hrf_taskC <- create_mock_hrfs(conditions = c("TaskC"), taps_per_hrf = 6, TR = TR_test_dm)
  X_taskC_no_events <- ndx_build_design_matrix(estimated_hrfs = hrf_taskC, events = events_dm, motion_params = NULL, rpca_components = NULL,
                                             spectral_sines = NULL, run_idx = run_idx_single_dm, TR = TR_test_dm, poly_degree_val = -1, verbose = FALSE)
  expect_false(any(startsWith(colnames(X_taskC_no_events), "task_")))
  expect_equal(ncol(X_taskC_no_events), 1) # Intercept
})
</file>

<file path="tests/testthat/test-initial_glm.R">
context("ndx_initial_glm - Basic Functionality")

# Mock data for testing ndx_initial_glm
# Similar setup to what might be in ndx_run_sprint1 for this step

test_that("ndx_initial_glm runs with minimal valid inputs and returns correct structure", {
  set.seed(123) # For reproducibility
  TR_example <- 2.0
  n_time_per_run <- 10
  n_runs <- 1
  n_voxels <- 3
  total_timepoints <- n_time_per_run * n_runs

  Y_fmri_example <- matrix(rnorm(total_timepoints * n_voxels), nrow = total_timepoints, ncol = n_voxels)
  run_idx_example <- rep(1:n_runs, each = n_time_per_run)
  motion_params_example <- matrix(rnorm(total_timepoints * 6), nrow = total_timepoints, ncol = 6)
  colnames(motion_params_example) <- paste0("mot", 1:6) # Add colnames to motion_params

  events_example <- data.frame(
    onsets = as.numeric(c(2, 5)),
    durations = as.numeric(c(1, 1)),
    condition = factor(c("TaskA", "TaskB")),
    blockids = as.integer(c(1, 1))
  )
  
  # It's good practice to wrap the call in a tryCatch or expect_no_error
  # if the main point is just that it runs and has structure.
  # For now, we just expect it to run.
  output <- NULL
  expect_no_error({
      output <- ndx_initial_glm(Y_fmri_example, events_example, 
                                   motion_params_example, run_idx_example, TR_example)
  })
  
  # Basic checks
  expect_true(is.list(output), "Output should be a list")
  expect_named(output, c("Y_residuals_current", "VAR_BASELINE_FOR_DES"))
  expect_true(is.matrix(output$Y_residuals_current))
  expect_equal(dim(output$Y_residuals_current), dim(Y_fmri_example))
  expect_true(is.numeric(output$VAR_BASELINE_FOR_DES) && length(output$VAR_BASELINE_FOR_DES) == 1)
  expect_false(any(is.na(output$Y_residuals_current))) # OLS residuals should be complete if inputs are
  expect_true(is.finite(output$VAR_BASELINE_FOR_DES))
})

test_that("ndx_initial_glm errors if Y_fmri is not a matrix", {
  set.seed(123)
  TR_example <- 2.0
  n_time_per_run <- 10
  n_runs <- 1
  n_voxels <- 3
  total_timepoints <- n_time_per_run * n_runs

  Y_fmri_example <- matrix(rnorm(total_timepoints * n_voxels), nrow = total_timepoints, ncol = n_voxels)
  run_idx_example <- rep(1:n_runs, each = n_time_per_run)
  motion_params_example <- matrix(rnorm(total_timepoints * 6), nrow = total_timepoints, ncol = 6)
  colnames(motion_params_example) <- paste0("mot", 1:6)

  events_example <- data.frame(
    onsets = as.numeric(c(2, 5)),
    durations = as.numeric(c(1, 1)),
    condition = factor(c("TaskA", "TaskB")),
    blockids = as.integer(c(1, 1))
  )

  Y_fmri_invalid <- as.data.frame(Y_fmri_example)
  
  expect_error(
    ndx_initial_glm(Y_fmri_invalid, events_example,
                    motion_params_example, run_idx_example, TR_example),
    "Y_fmri must be a matrix"
  )
})

test_that("ndx_initial_glm errors if events data frame is missing required columns", {
  set.seed(123)
  TR_example <- 2.0
  n_time_per_run <- 10
  n_runs <- 1
  n_voxels <- 3
  total_timepoints <- n_time_per_run * n_runs

  Y_fmri_example <- matrix(rnorm(total_timepoints * n_voxels), nrow = total_timepoints, ncol = n_voxels)
  run_idx_example <- rep(1, total_timepoints)
  motion_params_example <- matrix(rnorm(total_timepoints * 6), nrow = total_timepoints, ncol = 6)
  colnames(motion_params_example) <- paste0("mot", 1:6)

  events_example <- data.frame(
    onsets = as.numeric(c(2, 5)),
    durations = as.numeric(c(1, 1)),
    condition = factor(c("TaskA", "TaskB")),
    blockids = as.integer(c(1, 1))
  )

  events_invalid <- events_example[, -which(names(events_example) == "onsets")]
  expect_error(
    ndx_initial_glm(Y_fmri_example, events_invalid,
                    motion_params_example, run_idx_example, TR_example),
    "events data frame must contain columns: onsets, durations, condition, blockids"
  )
  
  events_invalid_cond <- events_example
  events_invalid_cond$condition <- NULL
  expect_error(
    ndx_initial_glm(Y_fmri_example, events_invalid_cond,
                    motion_params_example, run_idx_example, TR_example),
    "events data frame must contain columns: onsets, durations, condition, blockids"
  )
})

test_that("ndx_initial_glm handles multiple runs correctly", {
  set.seed(456)
  TR_multirun <- 2.5
  n_time_per_run <- 10
  n_runs <- 2
  n_voxels <- 3
  total_timepoints <- n_time_per_run * n_runs

  Y_fmri_multirun <- matrix(rnorm(total_timepoints * n_voxels), nrow = total_timepoints, ncol = n_voxels)
  run_idx_multirun <- rep(1:n_runs, each = n_time_per_run)
  motion_params_multirun <- matrix(rnorm(total_timepoints * 6), nrow = total_timepoints, ncol = 6)
  colnames(motion_params_multirun) <- paste0("mot", 1:6)

  events_multirun <- data.frame(
    onsets = as.numeric(c(2, 5, 2, 5)), # Events in run 1, then run 2
    durations = as.numeric(c(1, 1, 1, 1)),
    condition = factor(rep(c("TaskA", "TaskB"), 2)),
    blockids = as.integer(c(1, 1, 2, 2)) # Correct blockids for each run
  )
  
  output_multirun <- NULL
  expect_no_error({
    output_multirun <- ndx_initial_glm(Y_fmri_multirun, events_multirun, 
                                         motion_params_multirun, run_idx_multirun, TR_multirun)
  })
  
  # Check structure (same as single run)
  expect_true(is.list(output_multirun), "Output should be a list")
  expect_named(output_multirun, c("Y_residuals_current", "VAR_BASELINE_FOR_DES"))
  expect_true(is.matrix(output_multirun$Y_residuals_current))
  expect_equal(dim(output_multirun$Y_residuals_current), dim(Y_fmri_multirun))
  expect_true(is.numeric(output_multirun$VAR_BASELINE_FOR_DES) && length(output_multirun$VAR_BASELINE_FOR_DES) == 1)
  expect_false(any(is.na(output_multirun$Y_residuals_current)))
  expect_true(is.finite(output_multirun$VAR_BASELINE_FOR_DES))
  
  # Further checks could compare to manual calculation or known results if simple enough.
  # For now, primarily checking it runs without error and structure is okay.
})

# Add more tests as needed: e.g., specific scenarios for VAR_BASELINE_FOR_DES, 
# edge cases with motion parameters, different polynomial degrees if that becomes an option, etc.
</file>

<file path="tests/testthat/test-ridge.R">
context("ndx_solve_ridge - Functionality")

# Helper function to generate some data
.generate_ridge_test_data <- function(n_timepoints, n_regressors, n_voxels, true_betas, noise_sd = 1.0, na_head = 0) {
  X <- matrix(rnorm(n_timepoints * n_regressors), n_timepoints, n_regressors)
  # Ensure true_betas is a matrix of correct dimensions (n_regressors x n_voxels)
  if (is.vector(true_betas)) {
    if (length(true_betas) != n_regressors) stop("Length of true_betas vector must match n_regressors")
    true_betas_matrix <- matrix(rep(true_betas, n_voxels), nrow = n_regressors, ncol = n_voxels)
  } else if (is.matrix(true_betas)) {
    if (nrow(true_betas) != n_regressors || ncol(true_betas) != n_voxels) {
      stop("Dimensions of true_betas matrix are incorrect.")
    }
    true_betas_matrix <- true_betas
  } else {
    stop("true_betas must be a vector or a matrix.")
  }
  
  Y_signal <- X %*% true_betas_matrix
  Y_noise <- matrix(rnorm(n_timepoints * n_voxels, sd = noise_sd), n_timepoints, n_voxels)
  Y <- Y_signal + Y_noise
  
  na_mask_vec <- rep(FALSE, n_timepoints)
  if (na_head > 0 && n_timepoints > na_head) {
    Y[1:na_head, ] <- NA
    # X[1:na_head, ] <- NA # Not strictly needed to make X have NAs for this test, Y is enough
    na_mask_vec[1:na_head] <- TRUE
  }
  
  return(list(Y = Y, X = X, true_betas = true_betas_matrix, na_mask = na_mask_vec))
}

test_that("ndx_solve_ridge computes correct betas for a simple case", {
  set.seed(123)
  n_tp <- 100
  n_reg <- 2
  n_vox <- 1
  true_b <- c(2, -3)
  lambda <- 1.0
  
  test_data <- .generate_ridge_test_data(n_tp, n_reg, n_vox, true_b, noise_sd = 0.1)
  
  # Manual calculation for single voxel
  # beta = (X'X + lambda * I)^(-1) X'Y
  XtX <- crossprod(test_data$X)
  I <- diag(n_reg)
  expected_betas_manual <- solve(XtX + lambda * I) %*% crossprod(test_data$X, test_data$Y[,1,drop=FALSE])
  
  ridge_betas <- ndx_solve_ridge(test_data$Y, test_data$X, lambda_ridge = lambda)
  
  expect_true(is.matrix(ridge_betas))
  expect_equal(nrow(ridge_betas), n_reg)
  expect_equal(ncol(ridge_betas), n_vox)
  expect_equal(ridge_betas[,1], as.vector(expected_betas_manual), tolerance = 1e-6)
})

test_that("ndx_solve_ridge handles lambda_ridge = 0 (OLS-like)", {
  set.seed(456)
  n_tp <- 50
  n_reg <- 3
  n_vox <- 2
  true_b_mat <- matrix(c(1,0.5,-1, -2,1,0.3), nrow=n_reg, ncol=n_vox) 
  
  test_data <- .generate_ridge_test_data(n_tp, n_reg, n_vox, true_b_mat, noise_sd = 0.2)
  
  # OLS solution: (X'X)^-1 X'Y
  # Using lm.fit for robustness against collinearity, though unlikely here
  ols_betas_list <- lapply(1:n_vox, function(v_idx) coef(lm.fit(test_data$X, test_data$Y[,v_idx])))
  ols_betas_manual <- do.call(cbind, ols_betas_list)
  dimnames(ols_betas_manual) <- NULL # Strip dimnames for comparison consistency

  ridge_betas_lambda0 <- ndx_solve_ridge(test_data$Y, test_data$X, lambda_ridge = 0)
  
  expect_equal(ridge_betas_lambda0, ols_betas_manual, tolerance = 1e-6)
})

test_that("ndx_solve_ridge shrinks betas with high lambda", {
  set.seed(789)
  n_tp <- 50
  n_reg <- 2
  n_vox <- 1
  true_b <- c(10, -15)
  test_data <- .generate_ridge_test_data(n_tp, n_reg, n_vox, true_b, noise_sd = 1)

  ridge_betas_low_lambda <- ndx_solve_ridge(test_data$Y, test_data$X, lambda_ridge = 0.1)
  ridge_betas_high_lambda <- ndx_solve_ridge(test_data$Y, test_data$X, lambda_ridge = 10000)
  
  # Check that sum of absolute beta values is much smaller for high lambda
  expect_lt(sum(abs(ridge_betas_high_lambda)), sum(abs(ridge_betas_low_lambda)) * 0.1)
  # Check that high lambda betas are close to zero
  expect_true(all(abs(ridge_betas_high_lambda) < 0.1))
})

test_that("ndx_solve_ridge handles na_mask and NAs in Y_whitened correctly", {
  set.seed(101)
  n_tp <- 60
  n_reg <- 2
  n_vox <- 2
  true_b_mat <- matrix(c(1,2, -1,0.5), n_reg, n_vox)
  na_count = 3
  
  test_data_na <- .generate_ridge_test_data(n_tp, n_reg, n_vox, true_b_mat, noise_sd = 0.1, na_head = na_count)
  Y_with_na <- test_data_na$Y
  X_for_na <- test_data_na$X
  na_mask_provided <- test_data_na$na_mask
  
  # 1. With na_mask provided
  betas_with_mask <- ndx_solve_ridge(Y_with_na, X_for_na, lambda_ridge = 1.0, na_mask = na_mask_provided)
  
  # Manual calculation on clean data
  Y_clean_manual <- Y_with_na[!na_mask_provided, , drop = FALSE]
  X_clean_manual <- X_for_na[!na_mask_provided, , drop = FALSE]
  XtX_clean <- crossprod(X_clean_manual)
  I_clean <- diag(n_reg)
  expected_betas_clean_manual <- solve(XtX_clean + 1.0 * I_clean) %*% crossprod(X_clean_manual, Y_clean_manual)
  
  expect_equal(betas_with_mask, expected_betas_clean_manual, tolerance = 1e-6)

  # 2. Without na_mask (should auto-detect and remove NA rows from Y)
  betas_auto_na <- ndx_solve_ridge(Y_with_na, X_for_na, lambda_ridge = 1.0, na_mask = NULL)
  expect_equal(betas_auto_na, expected_betas_clean_manual, tolerance = 1e-6, 
               label = "Should match manual clean when na_mask is NULL and Y has NAs")
               
  # 3. No NAs present, na_mask=NULL (should run on full data)
  test_data_no_na <- .generate_ridge_test_data(n_tp, n_reg, n_vox, true_b_mat, noise_sd = 0.1, na_head = 0)
  XtX_full <- crossprod(test_data_no_na$X)
  expected_betas_full_manual <- solve(XtX_full + 1.0 * diag(n_reg)) %*% crossprod(test_data_no_na$X, test_data_no_na$Y)
  betas_no_na_null_mask <- ndx_solve_ridge(test_data_no_na$Y, test_data_no_na$X, lambda_ridge = 1.0, na_mask = NULL)
  expect_equal(betas_no_na_null_mask, expected_betas_full_manual, tolerance = 1e-6)
  
  # 4. All Y rows are NA
  Y_all_na <- matrix(NA_real_, nrow=n_tp, ncol=n_vox)
  expect_warning(
    betas_all_na <- ndx_solve_ridge(Y_all_na, X_for_na, lambda_ridge = 1.0, na_mask = NULL),
    "No timepoints remaining after NA removal. Returning NA betas."
  )
  expect_true(all(is.na(betas_all_na)))
  expect_equal(nrow(betas_all_na), n_reg)
  expect_equal(ncol(betas_all_na), n_vox)
})

test_that("ndx_solve_ridge input validation works", {
  Y_good <- matrix(rnorm(20*2), 20, 2)
  X_good <- matrix(rnorm(20*3), 20, 3)
  lambda_good <- 1.0
  na_mask_good <- rep(FALSE, 20)
  
  expect_error(ndx_solve_ridge(as.data.frame(Y_good), X_good, lambda_good), "Y_whitened must be a numeric matrix.")
  expect_error(ndx_solve_ridge(Y_good, as.data.frame(X_good), lambda_good), "X_whitened must be a numeric matrix.")
  expect_error(ndx_solve_ridge(Y_good, X_good[1:10,], lambda_good), "Y_whitened and X_whitened must have the same number of rows")
  expect_error(ndx_solve_ridge(Y_good, X_good, "a"), "lambda_ridge must be a single non-negative numeric value.")
  expect_error(ndx_solve_ridge(Y_good, X_good, -1), "lambda_ridge must be a single non-negative numeric value.")
  expect_error(ndx_solve_ridge(Y_good, X_good, c(1,2)), "lambda_ridge must be a single non-negative numeric value.")
  expect_error(ndx_solve_ridge(Y_good, X_good, lambda_good, na_mask = rep(FALSE, 10)), "Provided na_mask must be a logical vector of length equal to nrows of Y_whitened.")
  expect_error(ndx_solve_ridge(Y_good, X_good, lambda_good, na_mask = as.numeric(na_mask_good)), "Provided na_mask must be a logical vector of length equal to nrows of Y_whitened.")

  # More regressors than timepoints after NA removal
  X_too_many_reg <- matrix(rnorm(5*6), 5, 6)
  Y_short <- matrix(rnorm(5*1), 5, 1)
  expect_warning(
    b_warn <- ndx_solve_ridge(Y_short, X_too_many_reg, lambda_good, na_mask=rep(FALSE,5)),
    "Number of timepoints after NA removal \\(5\\) is less than number of regressors \\(6\\)"
  )
  expect_true(all(is.na(b_warn)))
  
  # Zero regressors or voxels
  expect_warning(b_zero_reg <- ndx_solve_ridge(Y_good, X_good[,0,drop=FALSE], lambda_good), "X_whitened has 0 regressors.")
  expect_equal(dim(b_zero_reg), c(0, ncol(Y_good)))
  expect_warning(b_zero_vox <- ndx_solve_ridge(Y_good[,0,drop=FALSE], X_good, lambda_good), "Y_whitened has 0 voxels.")
  expect_equal(dim(b_zero_vox), c(ncol(X_good), 0))
})

context("ndx_extract_task_betas - Functionality")

test_that("ndx_extract_task_betas extracts specified betas correctly", {
  betas_full <- matrix(1:12, nrow = 4, ncol = 3)
  colnames_x <- paste0("reg", 1:4) # Matches rows of betas_full if rownames were set
  rownames(betas_full) <- colnames_x # Simulate betas from a named X
  
  tasks_to_extract <- c("reg2", "reg4")
  extracted <- ndx_extract_task_betas(betas_full, colnames_x, tasks_to_extract)
  
  expect_true(!is.null(extracted))
  expect_equal(nrow(extracted), length(tasks_to_extract))
  expect_equal(ncol(extracted), ncol(betas_full))
  expect_equal(rownames(extracted), tasks_to_extract)
  expect_equal(extracted["reg2", ], betas_full["reg2", ])
  expect_equal(extracted["reg4", ], betas_full["reg4", ])
  
  # Test with X_whitened_colnames not matching rownames of betas_whitened (should still work using X_whitened_colnames for indexing)
  betas_mismatched_rownames <- matrix(1:12, nrow = 4, ncol = 3)
  rownames(betas_mismatched_rownames) <- paste0("original_beta_name", 1:4) # Give it different rownames
  colnames_x <- paste0("reg", 1:4) # Target names for X
  tasks_to_extract <- c("reg2", "reg4")

  expect_warning(
    extracted_mismatch_rn <- ndx_extract_task_betas(betas_mismatched_rownames, colnames_x, tasks_to_extract),
    "Rownames of betas_whitened do not match X_whitened_colnames"
  )
  expect_true(!is.null(extracted_mismatch_rn))
  # We expect indexing to be based on colnames_x, so reg2 is the 2nd element, reg4 is the 4th
  expect_equal(extracted_mismatch_rn["reg2", ], betas_mismatched_rownames[2, ]) 
  expect_equal(extracted_mismatch_rn["reg4", ], betas_mismatched_rownames[4, ]) 
})

test_that("ndx_extract_task_betas handles missing task regressors", {
  betas_full <- matrix(1:8, nrow = 4, ncol = 2)
  colnames_x <- c("taskA", "noise1", "taskB", "noise2")
  rownames(betas_full) <- colnames_x
  
  # One missing, one present
  tasks_mixed <- c("taskA", "taskC_missing")
  expect_warning(
    extracted_mixed <- ndx_extract_task_betas(betas_full, colnames_x, tasks_mixed),
    "The following task regressors were not found in X_whitened_colnames: taskC_missing"
  )
  expect_true(!is.null(extracted_mixed))
  expect_equal(nrow(extracted_mixed), 1)
  expect_equal(rownames(extracted_mixed), "taskA")
  expect_equal(extracted_mixed["taskA", ], betas_full["taskA", ])
  
  # All missing
  tasks_all_missing <- c("taskX", "taskY")
  expect_warning(
    extracted_all_missing <- ndx_extract_task_betas(betas_full, colnames_x, tasks_all_missing),
    "No specified task regressors were found in X_whitened_colnames. Returning NULL."
  )
  expect_null(extracted_all_missing)
})

test_that("ndx_extract_task_betas input validation works", {
  betas_good <- matrix(1:6, 3, 2)
  colnames_good <- c("r1", "r2", "r3")
  tasks_good <- c("r1")
  
  expect_error(ndx_extract_task_betas(as.data.frame(betas_good), colnames_good, tasks_good), "betas_whitened must be a numeric matrix.")
  expect_error(ndx_extract_task_betas(betas_good, colnames_good[-1], tasks_good), "Number of rows in betas_whitened must match the length of X_whitened_colnames.")
  expect_error(ndx_extract_task_betas(betas_good, as.list(colnames_good), tasks_good), "X_whitened_colnames must be a character vector.")
  expect_error(ndx_extract_task_betas(betas_good, colnames_good, character(0)), "task_regressor_names must be a non-empty character vector.")
  expect_error(ndx_extract_task_betas(betas_good, colnames_good, list("r1")), "task_regressor_names must be a non-empty character vector.")
  
  # Zero row betas
  betas_zero_row <- matrix(numeric(0), ncol=2, nrow=0) # Ensure it's a numeric matrix
  colnames_zero_row <- character(0)
  expect_warning(ndx_extract_task_betas(betas_zero_row, colnames_zero_row, tasks_good), "Input betas_whitened has 0 regressors.")
  expect_null(suppressWarnings(ndx_extract_task_betas(betas_zero_row, colnames_zero_row, tasks_good)))
})
</file>

<file path="tests/testthat/test-rpca.R">
context("ndx_rpca_temporal_components_multirun - Functionality")

# Helper to generate some Y_residuals_cat and run_idx
.generate_rpca_test_data <- function(T_run = 100, V = 50, N_runs = 1) {
  total_T <- T_run * N_runs
  Y_res_cat <- matrix(rnorm(total_T * V), total_T, V) * 0.01
  run_idx_vec <- rep(1:N_runs, each = T_run)
  
  if (V >= 2) { 
      true_V_pattern <- matrix(rnorm(V*2), V, 2) 
      for (r in 1:N_runs) {
        run_rows <- which(run_idx_vec == r)
        # Stronger low-rank signal
        C_r_signal_run1 <- sin((1:T_run)/8 + r/2) * 5 
        C_r_signal_run2 <- cos((1:T_run)/15 - r/3) * 4 
        Y_res_cat[run_rows, ] <- Y_res_cat[run_rows, ] + 
                                   (cbind(C_r_signal_run1, C_r_signal_run2) %*% t(true_V_pattern)) * 5.0 # Increased signal multiplier
      }
  }
  return(list(Y_residuals_cat = Y_res_cat, run_idx = run_idx_vec, T_run=T_run, V=V, N_runs=N_runs, total_T=total_T))
}

test_that("ndx_rpca_temporal_components_multirun runs (single run, concat_svd)", {
  test_data <- .generate_rpca_test_data(N_runs = 1)
  k_target <- 3
  
  user_opts <- list(
    k_per_run_target = 4, 
    rpca_lambda_auto = TRUE, # Revert to auto lambda
    # rpca_lambda_fixed = 0.05, # Try a fixed, possibly smaller lambda
    rpca_mu = 0.3, # Try an explicit mu for test data
    rpca_merge_strategy = "concat_svd",
    rpca_term_delta = 1e-6, # Explicitly use function's default
    rpca_max_iter = 2000    # Explicitly use function's default
  )
  
  components <- NULL
  expect_no_error({
    components <- ndx_rpca_temporal_components_multirun(
      Y_residuals_cat = test_data$Y_residuals_cat,
      run_idx = test_data$run_idx,
      k_global_target = k_target,
      user_options = user_opts
    )
  })
  
  expect_true(!is.null(components), "Components should not be NULL for valid inputs (single run)")
  if (!is.null(components)) {
    expect_true(is.matrix(components), "Output should be a matrix (single run)")
    expect_equal(nrow(components), test_data$total_T, info = "Output rows should match total timepoints (single run)")
    expect_true(ncol(components) <= k_target, info = sprintf("Output columns (%d) should be <= k_target (%d) (single run)", ncol(components), k_target))
    expect_true(ncol(components) > 0, info = "Output should have >0 components if k_target > 0 (single run)")
  }
})

test_that("ndx_rpca_temporal_components_multirun runs (multi-run, concat_svd)", {
  test_data <- .generate_rpca_test_data(N_runs = 2)
  k_target <- 3
  
  user_opts <- list(
    k_per_run_target = 4,
    rpca_lambda_auto = TRUE, # Revert to auto lambda
    # rpca_lambda_fixed = 0.05, # Try a fixed, possibly smaller lambda
    rpca_mu = 0.3, # Try an explicit mu for test data
    rpca_merge_strategy = "concat_svd",
    rpca_term_delta = 1e-6, # Explicitly use function's default
    rpca_max_iter = 2000    # Explicitly use function's default
  )
  
  components <- NULL
  expect_no_error({
    components <- ndx_rpca_temporal_components_multirun(
      Y_residuals_cat = test_data$Y_residuals_cat,
      run_idx = test_data$run_idx,
      k_global_target = k_target,
      user_options = user_opts
    )
  })
  
  expect_true(!is.null(components), "Components should not be NULL for valid inputs (multi-run)")
  if (!is.null(components)) {
    expect_true(is.matrix(components), "Output should be a matrix (multi-run)")
    expect_equal(nrow(components), test_data$total_T, info = "Output rows should match total timepoints (multi-run)")
    expect_true(ncol(components) <= k_target, info = sprintf("Output columns (%d) should be <= k_target (%d) (multi-run)", ncol(components), k_target))
    expect_true(ncol(components) > 0, info = "Output should have >0 components if k_target > 0 (multi-run)")
  }
})
</file>

<file path="tests/testthat/test-spectral.R">
context("ndx_spectral_sines - Functionality")

test_that("ndx_spectral_sines generates correct regressors for a simple signal", {
  set.seed(123)
  TR_val <- 2.0
  n_timepoints <- 200
  time_vector_sec <- (seq_len(n_timepoints) - 1) * TR_val

  # Create a synthetic residual with a clear 0.05 Hz sine wave + some noise
  freq_of_interest_hz <- 0.05 # Hz
  signal_component <- sin(2 * pi * freq_of_interest_hz * time_vector_sec)
  noise_component <- rnorm(n_timepoints, sd = 0.2)
  mean_resid_data <- signal_component + noise_component

  n_candidates <- 1
  spectral_regressors <- ndx_spectral_sines(mean_resid_data, 
                                            TR = TR_val, 
                                            n_sine_candidates = n_candidates,
                                            k_tapers = 5, # Align with function default
                                            nw = 3)       # Align with function default

  expect_true(!is.null(spectral_regressors), "Spectral regressors should not be NULL for a clear signal.")
  expect_equal(ncol(spectral_regressors), 2 * n_candidates, 
               info = "Should generate 2 regressors (sine & cosine) per candidate peak.")
  expect_equal(nrow(spectral_regressors), n_timepoints, 
               info = "Number of rows should match length of input time series.")
  
  identified_freqs_hz <- attr(spectral_regressors, "freq_hz")
  expect_true(!is.null(identified_freqs_hz), "Attribute 'freq_hz' should be present.")
  expect_length(identified_freqs_hz, n_candidates)
  
  # Check if the identified frequency is close to the known signal frequency
  # multitaper::spec.mtm might not hit the exact frequency, so allow tolerance
  expect_true(abs(identified_freqs_hz[1] - freq_of_interest_hz) < 0.01, 
              info = sprintf("Identified frequency (%.4f Hz) should be close to actual (%.4f Hz).", 
                             identified_freqs_hz[1], freq_of_interest_hz))
  
  # Check orthogonality of generated sine/cosine pair for the identified frequency
  if (!is.null(spectral_regressors) && ncol(spectral_regressors) >= 2) {
    correlation_sin_cos <- cor(spectral_regressors[,1], spectral_regressors[,2])
    expect_lt(abs(correlation_sin_cos), 0.01, 
              label = "Correlation between generated sine and cosine for the same frequency should be very low (near orthogonal).")
  } else {
    fail("Spectral regressors not generated or insufficient columns for orthogonality test.")
  }

  # Check if the identified regressors can explain the original signal component
  if (!is.null(spectral_regressors) && ncol(spectral_regressors) >= 2) {
    fit <- lm(signal_component ~ spectral_regressors[,1] + spectral_regressors[,2])
    r_squared <- summary(fit)$r.squared
    expect_gt(r_squared, 0.8, 
              label = "Identified sine/cosine pair should explain a large portion of the original signal variance (R-squared > 0.8)")
  } else {
    fail("Spectral regressors not generated or insufficient columns for lm test.")
  }
})

test_that("ndx_spectral_sines handles no clear peaks", {
  set.seed(456)
  TR_val <- 1.0
  n_timepoints <- 100
  # Pure noise, no strong periodic signal
  mean_resid_data <- rnorm(n_timepoints, sd = 1.0)

  spectral_regressors <- ndx_spectral_sines(mean_resid_data, TR = TR_val, n_sine_candidates = 3)

  # Depending on noise, it might find some peaks or none. 
  # If it finds peaks, check consistency. If NULL, that's also acceptable.
  if (is.null(spectral_regressors)) {
    expect_null(spectral_regressors) # Explicitly state that NULL is okay
  } else {
    expect_true(is.matrix(spectral_regressors))
    expect_true(ncol(spectral_regressors) <= 2 * 3) # At most 2*n_sine_candidates
  }
})

test_that("ndx_spectral_sines handles reasonably short but valid time series", {
  TR_val <- 1.0
  # Time series just long enough for k_tapers=2, nw=1.5
  # Original: k_tapers = 2, nw = 1.5. len = 20
  # Adjusted k_tapers = min(2, 2*1.5-1, 20-1) = min(2, 2, 19) = 2. This is >=1.
  # So spec.mtm should proceed.
  mean_resid_data_ok <- rnorm(20)
  expect_no_warning({
    spectral_regressors_ok <- ndx_spectral_sines(mean_resid_data_ok, TR = TR_val, k_tapers = 2, nw=1.5, n_sine_candidates = 1)
  })
  # We don't strictly require it to find peaks here, just not to error/warn inappropriately on length
  if (is.null(spectral_regressors_ok)) {
    expect_null(spectral_regressors_ok)
  } else {
    expect_true(is.matrix(spectral_regressors_ok))
  }
})

test_that("ndx_spectral_sines handles invalid inputs", {
  expect_warning(ndx_spectral_sines(character(0), TR = 1.0), "mean_residual_for_spectrum must be a non-empty numeric vector.")
  expect_null(suppressWarnings(ndx_spectral_sines(character(0), TR = 1.0)))
  
  expect_warning(ndx_spectral_sines(rnorm(100), TR = 0), "TR must be a positive numeric value.")
  expect_null(suppressWarnings(ndx_spectral_sines(rnorm(100), TR = 0)))
  
  expect_warning(ndx_spectral_sines(rnorm(100), TR = -1), "TR must be a positive numeric value.")
  expect_null(suppressWarnings(ndx_spectral_sines(rnorm(100), TR = -1)))
})

test_that("nyquist_guard_factor works as expected", {
  set.seed(789)
  TR_val <- 1.0
  n_timepoints <- 200
  time_vector_sec <- (seq_len(n_timepoints) - 1) * TR_val
  nyquist <- 1 / (2 * TR_val) # 0.5 Hz

  # Signal very close to Nyquist
  freq_near_nyquist <- nyquist * 0.95 # 0.475 Hz
  signal_near_nyquist <- sin(2 * pi * freq_near_nyquist * time_vector_sec)
  mean_resid_data <- signal_near_nyquist + rnorm(n_timepoints, sd = 0.1)

  # With default guard factor (0.9), freq_near_nyquist (0.475Hz) should be excluded 
  # as 0.9 * 0.5 = 0.45 Hz is the upper limit.
  spectral_regressors_guarded <- ndx_spectral_sines(mean_resid_data, TR = TR_val, n_sine_candidates = 1, nyquist_guard_factor = 0.9)
  if (!is.null(spectral_regressors_guarded)) {
    identified_freqs_guarded <- attr(spectral_regressors_guarded, "freq_hz")
    expect_true(all(identified_freqs_guarded < freq_near_nyquist), 
                "Identified frequencies should be less than the near-Nyquist signal if guarded.")
  } else {
    expect_null(spectral_regressors_guarded, "Expected no peaks or NULL due to guard factor excluding the main peak.")
  }

  # With guard factor = 1.0 (or > 0.95), it should be found.
  spectral_regressors_unguarded <- ndx_spectral_sines(mean_resid_data, TR = TR_val, n_sine_candidates = 1, nyquist_guard_factor = 1.0)
  expect_true(!is.null(spectral_regressors_unguarded), "Should find the peak when guard factor is 1.0.")
  if (!is.null(spectral_regressors_unguarded)) {
    identified_freqs_unguarded <- attr(spectral_regressors_unguarded, "freq_hz")
    expect_true(any(abs(identified_freqs_unguarded - freq_near_nyquist) < 0.01), 
                "The near-Nyquist frequency should be identified when guard factor is 1.0.")
  }
})

test_that("ndx_spectral_sines handles short time series that cause spec.mtm to fail", {
  short_ts <- rnorm(5) # Length 5, spec.mtm might fail with k_tapers adjusted but still too high for series
  # Default k_tapers=5, nw=3. Adjusted k_tapers will be min(5, 2*3-1, 5-1) = min(5,5,4) = 4.
  # spec.mtm with k=4 on length 5 series is likely to fail or produce unusable output.
  expect_warning(
    res <- ndx_spectral_sines(short_ts, TR = 1, n_sine_candidates = 1, k_tapers = 5, nw = 3),
    "Spectrum estimation via spec.mtm did not yield valid spec or freq."
  )
  expect_null(res)
})

test_that("ndx_spectral_sines warns if k_tapers becomes < 1 after adjustment", {
  # To make k_tapers < 1: use short series and/or small nw.
  # Example: k_tapers=2 (initial), nw=1. len=2.
  # Adjusted k_tapers = min(2, 2*1-1, 2-1) = min(2, 1, 1) = 1. Not < 1.
  # Example: k_tapers=1 (initial), nw=1. len=1.
  # Adjusted k_tapers = min(1, 2*1-1, 1-1) = min(1, 1, 0) = 0.
  very_short_ts <- rnorm(1)
  expect_warning(
    res <- ndx_spectral_sines(very_short_ts, TR = 1, n_sine_candidates = 1, k_tapers = 1, nw = 1),
    "k_tapers became 0 after adjustment"
  )
  expect_null(res)
})
</file>

<file path="tests/testthat/test-utils.R">
context("Utility functions from R/ndx_utils.R")

test_that("calculate_residuals_ols computes correct residuals", {
  Y <- matrix(c(1,2,3, 2,4,6, 3,6,9), ncol=3, byrow=TRUE)
  X <- matrix(c(1,1, 1,2, 1,3), ncol=2, byrow=TRUE)
  
  # Manually calculate residuals for a simple case
  # Y = X %*% beta + E
  # beta_hat = solve(t(X) %*% X) %*% t(X) %*% Y
  # residuals = Y - X %*% beta_hat
  
  # For first column of Y: y1 = c(1,2,3)
  # beta1_hat = solve(t(X)%*%X) %*% t(X) %*% y1
  XtX <- t(X) %*% X
  XtY1 <- t(X) %*% Y[,1,drop=FALSE]
  beta1_hat <- solve(XtX, XtY1)
  residuals1_manual <- Y[,1,drop=FALSE] - X %*% beta1_hat
  
  # For second column of Y: y2 = c(2,4,6) (which is 2*y1)
  # beta2_hat should be 2*beta1_hat
  # residuals2_manual should be 2*residuals1_manual
  XtY2 <- t(X) %*% Y[,2,drop=FALSE]
  beta2_hat <- solve(XtX, XtY2)
  residuals2_manual <- Y[,2,drop=FALSE] - X %*% beta2_hat
  
  # For third column of Y: y3 = c(3,6,9) (which is 3*y1)
  XtY3 <- t(X) %*% Y[,3,drop=FALSE]
  beta3_hat <- solve(XtX, XtY3)
  residuals3_manual <- Y[,3,drop=FALSE] - X %*% beta3_hat
  
  expected_residuals <- cbind(residuals1_manual, residuals2_manual, residuals3_manual)
  colnames(expected_residuals) <- NULL # lm.fit residuals don't have names by default
  rownames(expected_residuals) <- NULL # lm.fit residuals don't have names by default

  # Test with calculate_residuals_ols
  res_ols <- calculate_residuals_ols(Y, X)
  
  expect_equal(res_ols, expected_residuals, tolerance = 1e-8)
  expect_true(is.matrix(res_ols))
  expect_equal(dim(res_ols), dim(Y))
})

test_that("calculate_residuals_ols handles rank-deficient X and gives warning", {
  Y <- matrix(rnorm(10), ncol=2)
  X_rankdef <- matrix(c(1,1, 1,1, 1,1, 1,1, 1,1), ncol=2) # Rank 1, 2 cols
  
  expect_warning(
    res_ols_rankdef <- calculate_residuals_ols(Y, X_rankdef),
    "Design matrix is rank deficient. Rank = 1 Columns = 2"
  )
  
  # Residuals should still be calculable
  # Fit with lm to compare
  lm_fit_col1 <- lm(Y[,1] ~ X_rankdef - 1) # No intercept, as X includes it effectively
  lm_fit_col2 <- lm(Y[,2] ~ X_rankdef - 1)
  expected_residuals_rankdef <- cbind(residuals(lm_fit_col1), residuals(lm_fit_col2))
  rownames(expected_residuals_rankdef) <- NULL
  colnames(expected_residuals_rankdef) <- NULL
  
  expect_equal(res_ols_rankdef, expected_residuals_rankdef, tolerance = 1e-8)
})

test_that("calculate_residuals_ols handles X with zero columns and gives warning", {
  Y <- matrix(rnorm(10), ncol=2)
  X_zero_cols <- matrix(numeric(0), nrow=5, ncol=0)
  
  expect_warning(
    res_ols_zerocols <- calculate_residuals_ols(Y, X_zero_cols),
    "Design matrix X has zero columns. Returning Y as residuals."
  )
  expect_equal(res_ols_zerocols, Y)
})

test_that("calculate_residuals_ols errors with mismatched rows in Y and X", {
  Y <- matrix(rnorm(10), ncol=2) # 5 rows
  X <- matrix(rnorm(12), ncol=2) # 6 rows
  expect_error(
    calculate_residuals_ols(Y, X),
    "Number of rows in Y and X must match for OLS."
  )
})

test_that("calculate_R2_voxelwise computes correct R2 values", {
  Y_obs <- matrix(c(1,2,3,4, 2,4,6,8, 10,20,30,40), ncol=3, byrow=FALSE)
  # Col1: linear trend, perfect fit expected if model captures it.
  # Col2: 2*Col1
  # Col3: 10*Col1
  
  # Case 1: Perfect fit (residuals are zero)
  Y_res_perfect <- matrix(0, nrow=4, ncol=3)
  expected_R2_perfect <- c(1, 1, 1)
  expect_equal(calculate_R2_voxelwise(Y_obs, Y_res_perfect), expected_R2_perfect, tolerance = 1e-9)
  
  # Case 2: No fit (residuals are Y_obs - mean(Y_obs) if model is just intercept, or Y_obs if model is null)
  # If Y_residuals are Y_obs (model explains nothing beyond what Y_obs itself is, relative to 0)
  # and Y_obs has non-zero variance, R2 should be < 1. If Y_obs is centered, R2 would be 0.
  # calculate_R2_voxelwise assumes Y_residuals are from a model fit to Y_observed.
  # TSS is based on Y_observed. If RSS = TSS (i.e., model explains nothing beyond mean), R2=0.
  # If model makes things worse (RSS > TSS), R2 < 0, which is then clamped to 0.

  # Test with residuals = Y_obs (implies model predicted zero everywhere)
  # This should lead to R2 = 1 - sum(Y_obs^2) / sum((Y_obs - mean(Y_obs))^2)
  # This isn't standard R2, usually residuals are Y_obs - Y_hat.
  # Let's create more meaningful residuals.
  
  # Model Y_hat = mean(Y_obs) for each voxel
  Y_hat_mean <- apply(Y_obs, 2, function(col) rep(mean(col), length(col)))
  Y_res_mean <- Y_obs - Y_hat_mean
  expected_R2_mean <- c(0,0,0) # Model only explains the mean, so R2=0 conventionally.
  expect_equal(calculate_R2_voxelwise(Y_obs, Y_res_mean), expected_R2_mean, tolerance = 1e-9)
  
  # Case 3: Partial fit
  # For Y_obs[,1] = c(1,2,3,4), mean=2.5, TSS = (1-2.5)^2+(2-2.5)^2+(3-2.5)^2+(4-2.5)^2 = 2.25+0.25+0.25+2.25 = 5
  # Say Y_hat is c(1.5, 2, 2.5, 3)
  Y_hat_partial_col1 <- c(1.5, 2, 2.5, 3)
  Y_res_partial_col1 <- Y_obs[,1] - Y_hat_partial_col1 # c(-0.5, 0, 0.5, 1)
  RSS_col1 <- sum(Y_res_partial_col1^2) # 0.25 + 0 + 0.25 + 1 = 1.5
  R2_col1 <- 1 - (RSS_col1 / 5) # 1 - 1.5/5 = 1 - 0.3 = 0.7
  
  Y_res_partial <- cbind(Y_res_partial_col1, 2*Y_res_partial_col1, 10*Y_res_partial_col1)
  expected_R2_partial <- c(R2_col1, R2_col1, R2_col1) # R2 is scale invariant
  expect_equal(calculate_R2_voxelwise(Y_obs, Y_res_partial), expected_R2_partial, tolerance = 1e-9)
  
  # Case 4: Residuals make R2 negative (clamped to 0)
  Y_res_worse <- Y_obs * 2 # Residuals are much larger than original data variance from mean
  expected_R2_worse <- c(0,0,0)
  expect_equal(calculate_R2_voxelwise(Y_obs, Y_res_worse), expected_R2_worse, tolerance = 1e-9)
  
  # Case 5: Y_observed has zero variance (TSS = 0)
  Y_obs_flat <- matrix(rep(c(2,4,20), each=4), ncol=3, byrow=FALSE) # Each col is constant
  Y_res_flat <- matrix(0, nrow=4, ncol=3)
  expected_R2_flat <- c(0,0,0) # TSS is 0, R2 should be 0
  expect_equal(calculate_R2_voxelwise(Y_obs_flat, Y_res_flat), expected_R2_flat, tolerance = 1e-9)

  Y_res_flat_noise <- matrix(rnorm(12), ncol=3) # Non-zero residuals
  expect_equal(calculate_R2_voxelwise(Y_obs_flat, Y_res_flat_noise), expected_R2_flat, tolerance = 1e-9)
})

test_that("calculate_R2_voxelwise handles NA values correctly", {
  Y_obs_na <- matrix(c(1,2,NA,4, 2,NA,6,8, 10,20,30,NA), ncol=3, byrow=FALSE)
  Y_res_na <- matrix(rnorm(12), ncol=3) # Assume residuals are complete for simplicity of R2 calc
  
  # For col1: Y_obs=c(1,2,NA,4), Y_res=Y_res_na[,1]. n_obs=3. mean_obs=(1+2+4)/3 = 7/3.
  # TSS1 = (1-7/3)^2 + (2-7/3)^2 + (4-7/3)^2 = (-4/3)^2 + (-1/3)^2 + (5/3)^2 = (16+1+25)/9 = 42/9 = 14/3
  # RSS1 = sum(Y_res_na[c(1,2,4),1]^2)
  # R2_1 = 1 - RSS1/TSS1
  
  # Manual calculation for first column with NAs
  y_obs1_valid <- Y_obs_na[!is.na(Y_obs_na[,1]), 1]
  y_res1_valid <- Y_res_na[!is.na(Y_obs_na[,1]), 1] # Align residuals with valid observed data
  tss1_manual <- sum((y_obs1_valid - mean(y_obs1_valid))^2)
  rss1_manual <- sum(y_res1_valid^2)
  r2_1_manual <- if (abs(tss1_manual) < 1e-9) 0 else max(0, 1 - rss1_manual / tss1_manual)
  
  # Manual calculation for second column with NAs
  y_obs2_valid <- Y_obs_na[!is.na(Y_obs_na[,2]), 2]
  y_res2_valid <- Y_res_na[!is.na(Y_obs_na[,2]), 2]
  tss2_manual <- sum((y_obs2_valid - mean(y_obs2_valid))^2)
  rss2_manual <- sum(y_res2_valid^2)
  r2_2_manual <- if (abs(tss2_manual) < 1e-9) 0 else max(0, 1 - rss2_manual / tss2_manual)
  
  # Manual calculation for third column with NAs
  y_obs3_valid <- Y_obs_na[!is.na(Y_obs_na[,3]), 3]
  y_res3_valid <- Y_res_na[!is.na(Y_obs_na[,3]), 3]
  tss3_manual <- sum((y_obs3_valid - mean(y_obs3_valid))^2)
  rss3_manual <- sum(y_res3_valid^2)
  r2_3_manual <- if (abs(tss3_manual) < 1e-9) 0 else max(0, 1 - rss3_manual / tss3_manual)
  
  expected_R2_na <- c(r2_1_manual, r2_2_manual, r2_3_manual)
  expect_equal(calculate_R2_voxelwise(Y_obs_na, Y_res_na), expected_R2_na, tolerance = 1e-9)
  
  # Test where residuals also have NAs (should align with Y_obs_na for RSS calculation)
  Y_res_na_aligned <- Y_res_na
  Y_res_na_aligned[is.na(Y_obs_na)] <- NA # Make residuals NA where Y_obs is NA
  
  rss1_manual_aligned <- sum(Y_res_na_aligned[!is.na(Y_obs_na[,1]), 1]^2, na.rm=TRUE)
  r2_1_manual_aligned <- if (abs(tss1_manual) < 1e-9) 0 else max(0, 1 - rss1_manual_aligned / tss1_manual)
  rss2_manual_aligned <- sum(Y_res_na_aligned[!is.na(Y_obs_na[,2]), 2]^2, na.rm=TRUE)
  r2_2_manual_aligned <- if (abs(tss2_manual) < 1e-9) 0 else max(0, 1 - rss2_manual_aligned / tss2_manual)
  rss3_manual_aligned <- sum(Y_res_na_aligned[!is.na(Y_obs_na[,3]), 3]^2, na.rm=TRUE)
  r2_3_manual_aligned <- if (abs(tss3_manual) < 1e-9) 0 else max(0, 1 - rss3_manual_aligned / tss3_manual)
  
  expected_R2_na_aligned <- c(r2_1_manual_aligned, r2_2_manual_aligned, r2_3_manual_aligned)
  expect_equal(calculate_R2_voxelwise(Y_obs_na, Y_res_na_aligned), expected_R2_na_aligned, tolerance = 1e-9)
})

test_that("calculate_R2_voxelwise errors on mismatched dimensions", {
  Y_obs <- matrix(rnorm(10), ncol=2)
  Y_res_wrong_rows <- matrix(rnorm(8), ncol=2)
  Y_res_wrong_cols <- matrix(rnorm(10), ncol=1)
  expect_error(calculate_R2_voxelwise(Y_obs, Y_res_wrong_rows), "Dimensions of Y_observed and Y_residuals must match.")
  expect_error(calculate_R2_voxelwise(Y_obs, Y_res_wrong_cols), "Dimensions of Y_observed and Y_residuals must match.")
})
</file>

<file path="tests/testthat/test-whitening.R">
context("ndx_ar2_whitening - Functionality")

# Helper function to generate AR(order) data
.generate_ar_data <- function(n_timepoints, ar_coeffs, innov_sd = 1.0, burn_in = 100) {
  order <- length(ar_coeffs)
  total_points <- n_timepoints + burn_in
  innovations <- rnorm(total_points, mean = 0, sd = innov_sd)
  series <- numeric(total_points)
  
  for (i in (order + 1):total_points) {
    ar_part <- sum(ar_coeffs * series[(i - 1):(i - order)])
    series[i] <- ar_part + innovations[i]
  }
  return(list(series = series[(burn_in + 1):total_points], innovations = innovations[(burn_in + 1):total_points]))
}

test_that("ndx_ar2_whitening estimates AR(2) coeffs and whitens Y_data correctly", {
  set.seed(123)
  n_voxels <- 2
  n_timepoints <- 200
  ar_order <- 2

  # Voxel 1: Known AR(2) process
  true_ar1_coeffs <- c(0.6, -0.3)
  innov_sd1 <- 1.5
  ar_data1 <- .generate_ar_data(n_timepoints, true_ar1_coeffs, innov_sd1)
  
  # Voxel 2: Different AR(2) process
  true_ar2_coeffs <- c(0.4, 0.2)
  innov_sd2 <- 0.8
  ar_data2 <- .generate_ar_data(n_timepoints, true_ar2_coeffs, innov_sd2)

  Y_data_sim <- cbind(ar_data1$series, ar_data2$series)
  # For AR fitting, use the data itself if it's already supposed to be residuals
  # Or use actual residuals from a model fit if Y_data contains signal + noise
  Y_residuals_for_AR_fit_sim <- Y_data_sim 

  # Dummy design matrix (will be whitened by global AR)
  X_design_sim <- matrix(rnorm(n_timepoints * 3), n_timepoints, 3)
  colnames(X_design_sim) <- paste0("reg", 1:3)

  whitening_results <- NULL
  expect_no_error({
    whitening_results <- ndx_ar2_whitening(Y_data_sim, X_design_sim, Y_residuals_for_AR_fit_sim, order = ar_order)
  })
  
  expect_true(is.list(whitening_results))
  expect_named(whitening_results, c("Y_whitened", "X_whitened", "AR_coeffs_voxelwise", "AR_coeffs_global", "var_innovations_voxelwise", "na_mask"))

  # Check AR_coeffs_voxelwise
  coeffs_est <- whitening_results$AR_coeffs_voxelwise
  expect_equal(nrow(coeffs_est), n_voxels)
  expect_equal(ncol(coeffs_est), ar_order)
  # Check if estimated coefficients are reasonably close to true ones
  expect_true(all(abs(coeffs_est[1,] - true_ar1_coeffs) < 0.15), label = "Voxel 1 AR coeffs close to true")
  expect_true(all(abs(coeffs_est[2,] - true_ar2_coeffs) < 0.15), label = "Voxel 2 AR coeffs close to true")

  # Check var_innovations_voxelwise
  var_innov_est <- whitening_results$var_innovations_voxelwise
  expect_length(var_innov_est, n_voxels)
  expect_true(abs(var_innov_est[1] - innov_sd1^2) < innov_sd1^2 * 0.5, label = "Voxel 1 innov var close to true") # Wider tolerance for variance
  expect_true(abs(var_innov_est[2] - innov_sd2^2) < innov_sd2^2 * 0.5, label = "Voxel 2 innov var close to true")
  
  # Check Y_whitened
  Y_w <- whitening_results$Y_whitened
  expect_equal(dim(Y_w), dim(Y_data_sim))
  expect_true(all(is.na(Y_w[1:ar_order, ])), label = "First 'order' rows of Y_whitened should be NA")
  
  # Whitened series should approximate the original innovations (scaled)
  # Check acf of whitened series (should be low for lags > 0)
  na_mask_from_output <- whitening_results$na_mask # or simply use 1:ar_order
  
  # Voxel 1 ACF check
  if(any(whitening_results$AR_coeffs_voxelwise[1, ] != 0)) {
    acf_y_w1 <- acf(Y_w[!na_mask_from_output, 1], plot = FALSE, lag.max = 5)
    expect_true(all(abs(acf_y_w1$acf[-1]) < 0.25), label = "ACF of whitened Y_data (Voxel 1) should be low if coeffs are non-zero")
  } else {
    # message for testthat output if skipped
    skip("ACF check for Voxel 1 skipped as AR coefficients were zeroed out.")
  }
  
  # Voxel 2 ACF check
  if(any(whitening_results$AR_coeffs_voxelwise[2, ] != 0)) {
    acf_y_w2 <- acf(Y_w[!na_mask_from_output, 2], plot = FALSE, lag.max = 5)
    expect_true(all(abs(acf_y_w2$acf[-1]) < 0.25), label = "ACF of whitened Y_data (Voxel 2) should be low if coeffs are non-zero")
  } else {
    skip("ACF check for Voxel 2 skipped as AR coefficients were zeroed out.")
  }
  
  # Check X_whitened (whitened by global AR model)
  X_w <- whitening_results$X_whitened
  expect_equal(dim(X_w), dim(X_design_sim))
  if (!is.null(whitening_results$AR_coeffs_global) && any(whitening_results$AR_coeffs_global != 0)) {
    expect_true(!is.null(whitening_results$AR_coeffs_global), label = "Global AR coeffs for X should exist if used.")
    expect_length(whitening_results$AR_coeffs_global, ar_order)
    expect_true(all(is.na(X_w[1:ar_order, ])), label = "First 'order' rows of X_whitened should be NA if whitened")
    # Check if X_w is different from X_design_sim (unless global AR coeffs are ~0)
    expect_false(isTRUE(all.equal(X_w[!na_mask_from_output, ], X_design_sim[!na_mask_from_output, ])), 
                 label = "X_whitened should differ from X_design_sim if global AR is non-zero (excluding initial NA rows)")
  } else {
    # If global AR coeffs are NULL or all zero, X_whitened should be X_design_sim
    expect_identical(X_w, X_design_sim, label = "X_whitened should be original X if global AR coeffs are null or zero.")
  }
})

test_that("ndx_ar2_whitening handles failed AR fits gracefully", {
  set.seed(456)
  n_voxels <- 2
  n_timepoints <- 100
  ar_order <- 2

  # Voxel 1: Normal AR data
  true_ar1_coeffs <- c(0.5, 0.1)
  ar_data1 <- .generate_ar_data(n_timepoints, true_ar1_coeffs, 1.0)
  
  # Voxel 2: Zero variance residuals (should cause AR fit to fail or produce NAs/zeros)
  zero_var_residuals <- rep(0, n_timepoints)

  Y_data_sim <- cbind(ar_data1$series, rnorm(n_timepoints)) # Y_data can be anything
  Y_residuals_for_AR_fit_sim <- cbind(ar_data1$series, zero_var_residuals)
  X_design_sim <- matrix(rnorm(n_timepoints * 2), n_timepoints, 2)

  whitening_results <- ndx_ar2_whitening(Y_data_sim, X_design_sim, Y_residuals_for_AR_fit_sim, order = ar_order)

  # Check AR_coeffs_voxelwise for the failed voxel
  expect_equal(whitening_results$AR_coeffs_voxelwise[2, ], c(0,0), 
               label = "AR coeffs for failed fit (zero var resid) should be c(0,0)")
  expect_true(is.na(whitening_results$var_innovations_voxelwise[2]), 
              label = "Innovation variance for failed fit should be NA")

  # Y_whitened for the failed voxel should be same as original Y_data for that voxel
  # (after accounting for NA rows if global_ar_on_design also resulted in non-filtering for X)
  # Current implementation means Y_whitened[,2] will be Y_data_sim[,2] as AR coeffs are 0
  na_mask_failed_fit <- whitening_results$na_mask
  expect_equal(whitening_results$Y_whitened[!na_mask_failed_fit, 2], Y_data_sim[!na_mask_failed_fit, 2], 
               label = "Y_whitened for failed AR fit voxel should be original data (excluding initial NA rows)")
  
  # Global AR coeffs should be based only on Voxel 1
  expect_true(!is.null(whitening_results$AR_coeffs_global))
  expect_equal(whitening_results$AR_coeffs_global, whitening_results$AR_coeffs_voxelwise[1,], tolerance = 1e-6,
               label = "Global AR coeffs should be based on the successful voxel fit")
})


test_that("ndx_ar2_whitening with global_ar_on_design = FALSE", {
  set.seed(789)
  n_voxels <- 1
  n_timepoints <- 50
  ar_order <- 1
  true_ar_coeffs <- c(0.7)
  ar_data <- .generate_ar_data(n_timepoints, true_ar_coeffs, 1.0)
  
  Y_data_sim <- matrix(ar_data$series, ncol = 1)
  Y_residuals_for_AR_fit_sim <- Y_data_sim
  X_design_sim <- matrix(rnorm(n_timepoints * 2), n_timepoints, 2)

  whitening_results <- ndx_ar2_whitening(Y_data_sim, X_design_sim, Y_residuals_for_AR_fit_sim, 
                                        order = ar_order, global_ar_on_design = FALSE)
  
  expect_true(is.list(whitening_results))
  expect_null(whitening_results$AR_coeffs_global, label = "AR_coeffs_global should be NULL when global_ar_on_design is FALSE")
  expect_identical(whitening_results$X_whitened, X_design_sim, 
                   label = "X_whitened should be identical to X_design_full when global_ar_on_design is FALSE")
  expect_true(!is.null(whitening_results$Y_whitened)) # Y_whitened should still be processed
})

test_that("Input validation for ndx_ar2_whitening", {
    Y_good <- matrix(rnorm(100*2), 100, 2)
    X_good <- matrix(rnorm(100*3), 100, 3)
    Y_res_good <- matrix(rnorm(100*2), 100, 2)

    expect_error(ndx_ar2_whitening(as.data.frame(Y_good), X_good, Y_res_good), "Y_data must be a numeric matrix.")
    expect_error(ndx_ar2_whitening(Y_good, as.data.frame(X_good), Y_res_good), "X_design_full must be a numeric matrix.")
    expect_error(ndx_ar2_whitening(Y_good, X_good, as.data.frame(Y_res_good)), "Y_residuals_for_AR_fit must be a numeric matrix.")

    Y_short_row <- matrix(rnorm(90*2), 90, 2)
    expect_error(ndx_ar2_whitening(Y_short_row, X_good, Y_res_good), "Y_data, X_design_full, and Y_residuals_for_AR_fit must have the same number of rows")
    
    Y_res_wrong_col <- matrix(rnorm(100*1), 100, 1)
    expect_error(ndx_ar2_whitening(Y_good, X_good, Y_res_wrong_col), "Y_data and Y_residuals_for_AR_fit must have the same number of columns")

    expect_error(ndx_ar2_whitening(Y_good, X_good, Y_res_good, order = 0.5), "order must be a single positive integer.")
    expect_error(ndx_ar2_whitening(Y_good, X_good, Y_res_good, order = 0), "order must be a single positive integer.")
    expect_error(ndx_ar2_whitening(Y_good, X_good, Y_res_good, order = c(1,2)), "order must be a single positive integer.")
    
    Y_too_short <- matrix(rnorm(2*2), 2, 2)
    X_too_short <- matrix(rnorm(2*3), 2, 3)
    Y_res_too_short <- matrix(rnorm(2*2), 2, 2)
    expect_error(ndx_ar2_whitening(Y_too_short, X_too_short, Y_res_too_short, order = 2L), 
                 regexp = "Number of timepoints \\(2\\) must be greater than AR order \\(2\\)\\.")
})
</file>

<file path="tests/testthat/test-workflow.R">
context("ndx_run_sprint1 - Workflow Integration Tests")

# Mock data and parameters needed for ndx_run_sprint1
# This will be more involved as it requires setting up inputs for several modules.

# Basic setup parameters
TR_test <- 2.0
n_time_per_run_test <- 50 # Shorter for faster tests
n_runs_test <- 1
total_timepoints_test <- n_time_per_run_test * n_runs_test
n_voxels_test <- 5 # Small number of voxels

# Y_fmri
Y_fmri_test <- matrix(rnorm(total_timepoints_test * n_voxels_test), 
                      nrow = total_timepoints_test, 
                      ncol = n_voxels_test)

# run_idx
run_idx_test <- rep(1:n_runs_test, each = n_time_per_run_test)

# motion_params
motion_params_test <- matrix(rnorm(total_timepoints_test * 3), 
                             nrow = total_timepoints_test, ncol = 3)
colnames(motion_params_test) <- paste0("mot", 1:3)

# events data frame
events_test <- data.frame(
  onsets = as.numeric(c(10, 30) * TR_test), # Onsets in seconds
  durations = as.numeric(c(5, 5) * TR_test),   # Durations in seconds
  condition = factor(c("TaskA", "TaskB")),
  blockids = as.integer(rep(1, 2)) # All in the first run
)
if (n_runs_test > 1) {
  events_run2_test <- data.frame(
    onsets = as.numeric(c(10, 30) * TR_test),
    durations = as.numeric(c(5, 5) * TR_test),
    condition = factor(c("TaskA", "TaskB")),
    blockids = as.integer(rep(2, 2))
  )
  events_test <- rbind(events_test, events_run2_test)
}


# User options (minimal for now, can be expanded)
user_options_test <- list(
  opts_pass0 = list(
    poly_degree = 1 # This is used by .construct_final_design_matrix
  ),
  opts_hrf = list(
    hrf_fir_taps = 6,
    good_voxel_R2_threshold = -Inf, # Use all voxels for HRF for simplicity
    lambda1_grid = c(0.1), # Minimal grid for speed
    lambda2_grid = c(0.1),
    cv_folds = 2 # Minimal folds
  ),
  opts_rpca = list(
    k_global_target = 2, # Small number of components
    rpca_lambda_auto = FALSE,
    lambda = 0.1 # Provide a small lambda if auto is FALSE
  ),
  opts_spectral = list(
    n_sine_candidates = 2, # Small number
    nyquist_guard_factor = 0.1
  ),
  opts_whitening = list(
    global_ar_on_design = FALSE,
    max_ar_failures_prop = 0.5
  ),
  opts_ridge = list(
    lambda_ridge = 0.5
  ),
  task_regressor_names_for_extraction = c("task_TaskA", "task_TaskB")
)

test_that("ndx_run_sprint1 runs with minimal valid inputs and returns correct structure", {
  skip_on_cran() # Potentially long-running test
  
  workflow_output <- NULL
  expect_no_error({
    workflow_output <- ndx_run_sprint1(
      Y_fmri = Y_fmri_test,
      events = events_test,
      motion_params = motion_params_test,
      run_idx = run_idx_test,
      TR = TR_test,
      user_options = user_options_test,
      verbose = FALSE
    )
  })
  
  expect_true(is.list(workflow_output), "Workflow output should be a list")
  
  expected_names <- c(
    "Y_residuals_pass0", "pass0_vars", "estimated_hrfs", 
    "rpca_components", "spectral_sines", "X_full_design",
    "Y_whitened", "X_whitened", "ar_coeffs_voxelwise", "na_mask_whitening",
    "ridge_betas_whitened", "final_task_betas"
  )
  expect_named(workflow_output, expected = expected_names, ignore.order = TRUE)
  
  # Basic dimension checks for key matrix outputs
  expect_equal(dim(workflow_output$Y_residuals_pass0), dim(Y_fmri_test))
  expect_true(is.numeric(workflow_output$pass0_vars) && length(workflow_output$pass0_vars) == 1)
  
  if (!is.null(workflow_output$X_full_design)) {
      expect_equal(nrow(workflow_output$X_full_design), total_timepoints_test)
  }
  
  # Check dimensions of whitened data if X_full_design was created
  if (!is.null(workflow_output$X_whitened)) {
    expect_equal(dim(workflow_output$Y_whitened), dim(Y_fmri_test))
    expect_equal(nrow(workflow_output$X_whitened), total_timepoints_test)
    expect_equal(ncol(workflow_output$X_whitened), ncol(workflow_output$X_full_design))
    expect_true(is.logical(workflow_output$na_mask_whitening))
    expect_length(workflow_output$na_mask_whitening, total_timepoints_test)
  }
  
  # Check ar_coeffs if present
  if (!is.null(workflow_output$ar_coeffs_voxelwise)) {
      expect_true(is.matrix(workflow_output$ar_coeffs_voxelwise))
      expect_equal(ncol(workflow_output$ar_coeffs_voxelwise), n_voxels_test)      
      # Expect 2 rows for AR(2) coefficients, or 3 if intercept is included by ar.yw
      # ndx_ar2_whitening stores only the 2 AR coefficients. 
      expect_equal(nrow(workflow_output$ar_coeffs_voxelwise), 2)
  }

  # Add more specific checks as needed, e.g., for dimensions of rpca/spectral components,
  # and type/structure of estimated_hrfs and final_task_betas.
  # For now, primarily checking it runs and returns expected named elements.
})

# Add more tests: e.g. with spike_TR_mask, different option combinations, edge cases.
</file>

<file path="DESCRIPTION">
Package: ndx
Title: ND-X: Next-Generation fMRI Denoising
Version: 0.0.0.9000
Author: Your Name [aut, cre]
Maintainer: Your Name <your.email@example.com>
Authors@R: person("Your Name", email = "your.email@example.com", role = c("aut", "cre"),
                  comment = c(ORCID = "YOUR-ORCID-ID"))
Description: Implements the ND-X fMRI denoising pipeline, designed to
    surpass existing methods by integrating advanced data-adaptive
    techniques.
License: MIT + file LICENSE
Encoding: UTF-8
LazyData: false
Remotes:
    bbuchsbaum/fmrireg
Imports:
    fmrireg,
    glmgen,
    genlasso,
    Rcpp (>= 1.0.0),
    neuroim2,
    oro.nifti,
    multitaper,
    psd,
    rpca,
    rsvd,
    stats,
    utils,
    matrixStats,
    tibble,
    pracma
Suggests:
    testthat (>= 3.0.0)
RoxygenNote: 7.3.2.9000
</file>

</files>
